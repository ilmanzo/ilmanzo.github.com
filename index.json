[{"content":"An old find I found an old cubieboard3 (cubietruck) collecting dust in a drawer, so I took the chance to try out Rust cross compilation and collect here some notes about the process. Here\u0026rsquo;s the baby:\nGive it a penguin First of all, I installed an ARM linux distro on a MicroSD card and started the device:\n[user@arm ~]$ cat /proc/cpuinfo processor\t: 0 model name\t: ARMv7 Processor rev 4 (v7l) BogoMIPS\t: 50.52 Features\t: half thumb fastmult vfp edsp thumbee neon vfpv3 tls vfpv4 idiva idivt vfpd32 lpae evtstrm CPU implementer\t: 0x41 CPU architecture: 7 CPU variant\t: 0x0 CPU part\t: 0xc07 CPU revision\t: 4 processor\t: 1 model name\t: ARMv7 Processor rev 4 (v7l) BogoMIPS\t: 50.52 Features\t: half thumb fastmult vfp edsp thumbee neon vfpv3 tls vfpv4 idiva idivt vfpd32 lpae evtstrm CPU implementer\t: 0x41 CPU architecture: 7 CPU variant\t: 0x0 CPU part\t: 0xc07 CPU revision\t: 4 Hardware\t: Allwinner sun7i (A20) Family Revision\t: 0000 So our device is ARM model v7l ; this means is a 32bit CPU, if you are curious there\u0026rsquo;s also a reference manual around. Now we will work from a development machine.\nGet Rusty Let\u0026rsquo;s check rust support:\n[x86]$ rustup target list | grep armv7 armv7-linux-androideabi armv7-unknown-linux-gnueabi armv7-unknown-linux-gnueabihf armv7-unknown-linux-musleabi armv7-unknown-linux-musleabihf armv7a-none-eabi armv7r-none-eabi armv7r-none-eabihf Plenty of options! I\u0026rsquo;d leave out android and musl variants for now.\n[x86]$ cargo init tryarm Created binary (application) package [x86]$ cd tryarm [x86]$ cargo build --target armv7-unknown-linux-gnueabihf error: could not compile `tryarm` (bin \u0026#34;tryarm\u0026#34;) due to 1 previous error Please retry Seems not sufficient \u0026hellip; Let\u0026rsquo;s try cross tool from the rust embedded team\n[x86]$ cargo install cross [x86]$ /home/andrea/.cargo/bin/cross build --target armv7-unknown-linux-gnueabihf Trying to pull ghcr.io/cross-rs/armv7-unknown-linux-gnueabihf:0.2.5... Getting image source signatures Copying blob 5b4afa60d436 [===============================\u0026gt;------] 146.3MiB / 172.0MiB | 6.6 M Copying blob 5b4afa60d436 done | Copying blob 58690f9b18fc done | Copying blob da8ef40b9eca done | Copying blob b51569e7c507 done | Copying blob 6c052f8b0b21 done | Copying blob fb15d46c38dc done | Copying blob 5afa4c181482 done | Copying blob b9d42a766612 done | Copying blob cc716323c93e done | Copying blob fe4038eab07b done | Copying blob 4accd797f995 done | Copying blob 3db4794ce9a5 done | Copying blob 8b1f228d2fc0 done | Copying blob 05f315b1fff9 done | Copying blob c0190749220c done | Copying blob 55483985fe64 done | Copying blob df8b7a9f8281 done | Copying blob 9de25b0c2608 done | Copying config 32cf786140 done | Writing manifest to image destination Compiling tryarm v0.1.0 (/project) Finished dev [unoptimized + debuginfo] target(s) in 0.26s This tool pulls a container with the right compiler toolchain and use it to build your project. Seems our program is in place, and it\u0026rsquo;s compiled!\n[x86]$ file target/armv7-unknown-linux-gnueabihf/debug/tryarm target/armv7-unknown-linux-gnueabihf/debug/tryarm: ELF 32-bit LSB pie executable, ARM, EABI5 version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux-armhf.so.3, for GNU/Linux 3.2.0, BuildID[sha1]=7ff3fc41deb8b4820cc64ff2857cddbfa577111c, with debug_info, not stripped [x86]$ objdump -d target/armv7-unknown-linux-gnueabihf/debug/tryarm 3428: e59d300c ldr r3, [sp, #12] 342c: e0802080 add r2, r0, r0, lsl #1 3430: e08b108b add r1, fp, fp, lsl #1 3434: e1a09003 mov r9, r3 3438: e1a00003 mov r0, r3 343c: e7b91181 ldr r1, [r9, r1, lsl #3]! 3440: e7b02182 ldr r2, [r0, r2, lsl #3]! 3444: e5993004 ldr r3, [r9, #4] 3448: e5904004 ldr r4, [r0, #4] 344c: e0521001 subs r1, r2, r1 3450: e0d41003 sbcs r1, r4, r3 Run baby run So, let\u0026rsquo;s transfer our binary to the device and run it\n[x86]$ scp target/armv7-unknown-linux-gnueabihf/debug/tryarm user@cubietruck:/home/user user@cubietruck\u0026#39;s password: tryarm 100% 3443KB 5.3MB/s 00:00 Switching to the device shell:\n[user@arm ~]$ ./tryarm Hello, world! [user@arm ~]$ ldd tryarm linux-vdso.so.1 (0xbefbd000) libgcc_s.so.1 =\u0026gt; /usr/lib/libgcc_s.so.1 (0xb6e40000) librt.so.1 =\u0026gt; /usr/lib/librt.so.1 (0xb6e20000) libpthread.so.0 =\u0026gt; /usr/lib/libpthread.so.0 (0xb6e00000) libdl.so.2 =\u0026gt; /usr/lib/libdl.so.2 (0xb6de0000) libc.so.6 =\u0026gt; /usr/lib/libc.so.6 (0xb6c40000) /lib/ld-linux-armhf.so.3 =\u0026gt; /usr/lib/ld-linux-armhf.so.3 (0xb6eda000) It\u0026rsquo; working \u0026#x1f604;\nFuture awaits We are able to compile and run Rust code on our little device, so this Proof of Concept is over. In the future we will use it to develop and test software on a foreign architecture.\nSome resources for further reference:\nhttps://www.modio.se/cross-compiling-rust-binaries-to-armv7.html ","permalink":"https://ilmanzo.github.io/post/experiments_with_rust_on_arm_architecture/","summary":"An old find I found an old cubieboard3 (cubietruck) collecting dust in a drawer, so I took the chance to try out Rust cross compilation and collect here some notes about the process. Here\u0026rsquo;s the baby:\nGive it a penguin First of all, I installed an ARM linux distro on a MicroSD card and started the device:\n[user@arm ~]$ cat /proc/cpuinfo processor\t: 0 model name\t: ARMv7 Processor rev 4 (v7l) BogoMIPS\t: 50.","title":"Playing with Rust on ARM architecture"},{"content":"üïµÔ∏è Intro The Linux Test Project is a joint project started years ago by SGI, OSDL and Bull developed and now maintained by IBM, Cisco, Fujitsu, SUSE, Red Hat, Oracle and many others. The project goal is to deliver tests to the open source community that validate the reliability, robustness, and stability of Linux.\nIn these days I\u0026rsquo;m having a journey on the project so with this article I want to show step by step how to setup the project, how tests are actually written and give you a quick and dirty guide to write your first one.\nüß∞ Let\u0026rsquo;s start NOTE: Since some tests manipulate operating system settings, if you plan to run the entire testsuite it is advisable to keep your workstation clean and setup a separate environment, like a spare pc or a development virtual machine.\nFirst thing is to install development tools and clone the repository:\n# zypper in -t pattern devel_basis or # zypper install gcc git make pkg-config autoconf automake bison flex m4 linux-glibc-devel glibc-devel $ git clone https://github.com/linux-test-project/ltp.git \u0026amp;\u0026amp; cd ltp $ make autotools $ ./configure [...omitted output...] Now you can continue either with compiling and running a single test or with compiling and installing the whole testsuite. Lets\u0026rsquo; do one baby step:\n‚öóÔ∏è One sample test If you want to just execute a single test you actually do not need to compile the whole LTP project, so we pick up an example test for the open() syscall . To find this specific test,\n$ cd testcases/kernel/syscalls/open $ cat open03.c What\u0026rsquo;s inside ‚ÅâÔ∏è 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // SPDX-License-Identifier: GPL-2.0-or-later /* * Copyright (c) Linux Test Project, 2001-2024 * Copyright (c) 2000 Silicon Graphics, Inc. All Rights Reserved. */ /*\\ * [Description] * * Testcase to check open() with O_RDWR | O_CREAT. */ #include \u0026#34;tst_test.h\u0026#34; #define TEST_FILE \u0026#34;testfile\u0026#34; static void verify_open(void) { TST_EXP_FD(open(TEST_FILE, O_RDWR | O_CREAT, 0700)); SAFE_CLOSE(TST_RET); SAFE_UNLINK(TEST_FILE); } static struct tst_test test = { .needs_tmpdir = 1, .test_all = verify_open, }; This test is pretty simple, as actual code is less than 10 lines. A brief line-by-line overview:\n1-12: standard comments, license and doc header. This project has more than 20 years of history! 13: include the mandatory LTP library header 15: a sample filename we\u0026rsquo;ll try to create calling the open() syscall 17-19: the real test function: using the macros provided by the framework, send to the kernel an open() syscall and ensure the operation succeeds ; if by any means the syscall should return an error, the error gets automatically reported and the test result marked as failed. In any case, the value returned is stored in the variable TST_RET 20-22: SAFE_* macros let us to close and delete the file just opened in a clean way 24-27: definition for the test metadata: which options does it need to run and which is the function that the framework will execute for us. LTP framework will look for this structure and use the informations inside. If you are curious about all the available options, you can find a good description here, but since it\u0026rsquo;s a big topic, it deserves a future dedicated post The Linux Test Project, like the Linux Kernel itself, makes heavy use of C macros, in order to keep the tests clean, mainteinable and readable. Of course all the macros and library functions are documented and explained in the project documentation.\nFor a reference of the syscalls, just consult your system\u0026rsquo;s man pages. As a tip, it\u0026rsquo;s recommended to clone the upstream man repository because sometimes the man pages packaged by distributions can be sometimes lacking behind.\nüëü How to run the test Thanks to the build system setup, we can just make our single testcase and run the standalone executable. LTP will add lots of useful information to our little program:\n$ make open03 [... compiler messages omitted...] $ ./open03 tst_test.c:1741: TINFO: LTP version: 20240129 tst_test.c:1625: TINFO: Timeout per run is 0h 00m 30s open03.c:19: TPASS: open(TEST_FILE, O_RDWR | O_CREAT, 0700) returned fd 3 Summary: passed 1 failed 0 broken 0 skipped 0 warnings 0 The compiled executable is also accepting some options, again courtesy of the LTP framework:\n$ ./open03 -h Environment Variables --------------------- KCONFIG_PATH Specify kernel config file KCONFIG_SKIP_CHECK Skip kernel config check if variable set (not set by default) LTPROOT Prefix for installed LTP (default: /opt/ltp) LTP_COLORIZE_OUTPUT Force colorized output behaviour (y/1 always, n/0: never) LTP_DEV Path to the block device to be used (for .needs_device) LTP_DEV_FS_TYPE Filesystem used for testing (default: ext2) LTP_SINGLE_FS_TYPE Testing only - specifies filesystem instead all supported (for .all_filesystems) LTP_TIMEOUT_MUL Timeout multiplier (must be a number \u0026gt;=1) LTP_RUNTIME_MUL Runtime multiplier (must be a number \u0026gt;=1) LTP_VIRT_OVERRIDE Overrides virtual machine detection (values: \u0026#34;\u0026#34;|kvm|microsoft|xen|zvm) TMPDIR Base directory for template directory (for .needs_tmpdir, default: /tmp) Timeout and runtime ------------------- Test timeout (not including runtime) 0h 0m 30s Options ------- -h Prints this help -i n Execute test n times -I x Execute test for n seconds -D Prints debug information -V Prints LTP version -C ARG Run child process with ARG arguments (used internally) you can also check your source code against project best practices:\n$ make check-open03 You will receive hints and errors about code quality, formatting and possible deviations from the projects\u0026rsquo; coding standards.\nüóø Hello, new test So if you want to write a new LTP test, you can just choose a testcases/kernel/ subfolder and create a new .c file using a template like this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #include \u0026lt;tst_test.h\u0026gt; static void setup(void) { // your setup code goes here tst_res(TINFO, \u0026#34;example setup\u0026#34;); } static void cleanup(void) { // your cleanup code goes here tst_res(TINFO, \u0026#34;example cleanup\u0026#34;); } static void run(void) { // your test code goes here tst_res(TPASS, \u0026#34;Doing hardly anything is easy\u0026#34;); } static struct tst_test test = { .test_all = run, .setup = setup, .cleanup = cleanup, }; In this example it\u0026rsquo;s important to notice that the functions setup() and cleanup() are meant to create/dispose test resources (like buffers, files, sockets, child processes and so on) and they get executed only once, while the run() is the real test code and can be repeated many times.\nAfter saving your source code with a name like mynewtest01.c, you just need to run\n$ make mynewtest01 CC testcases/kernel/syscalls/open/mynewtest01 $ ls -l mynewtest* -rwxr-xr-x 1 andrea andrea 738064 Feb 10 11:46 mynewtest01 -rw-r--r-- 1 andrea andrea 475 Feb 10 11:46 mynewtest01.c $ ./mynewtest01 tst_test.c:1741: TINFO: LTP version: 20240129 tst_test.c:1625: TINFO: Timeout per run is 0h 00m 30s mynewtest01.c:5: TINFO: example setup mynewtest01.c:15: TPASS: Doing hardly anything is easy mynewtest01.c:10: TINFO: example cleanup Summary: passed 1 failed 0 broken 0 skipped 0 warnings 0 It doesn\u0026rsquo;t do anything yet but seems working, now you need only to actually implement your test logic.\nOnce finished and debugged, if you want the new test executed as part of the testsuite, you need to add it in one of the runtest subfolders, where each text file defines a group of tests AKA test suite.\n‚úÖ Conclusion If you are interested in the project, check out the project\u0026rsquo;s Wiki for other documentation and Writing Guidelines; you can also subscribe to the LTP Mailing List. Enjoy!\n","permalink":"https://ilmanzo.github.io/post/first_steps_of_ltp_linux_test_project/","summary":"üïµÔ∏è Intro The Linux Test Project is a joint project started years ago by SGI, OSDL and Bull developed and now maintained by IBM, Cisco, Fujitsu, SUSE, Red Hat, Oracle and many others. The project goal is to deliver tests to the open source community that validate the reliability, robustness, and stability of Linux.\nIn these days I\u0026rsquo;m having a journey on the project so with this article I want to show step by step how to setup the project, how tests are actually written and give you a quick and dirty guide to write your first one.","title":"First steps with Linux Test Project"},{"content":"ü¶Ä Intro As an exercise, today we are going to package a game named battleship-rs developed by Orhun Parmaksƒ±z. We will also use the power of OpenSUSE build service to do most of the heavy work.\nBefore starting, let\u0026rsquo;s check out the project: it\u0026rsquo;s hosted on github and if you want to try it out before packaging, it\u0026rsquo;s a nice game where two people can play in the terminal over a TCP network connection. The initial ship placement, shot tracking, player turns and game state itself is managed from a single Rust process.\nFor the actual packaging, we will follow the reference documentation on openSUSE wiki.\nüì¶ Prerequisites Following the OBS guidelines, let\u0026rsquo;s setup our osc client with a minimal configuration:\n$ grep -v \u0026#39;^#\u0026#39; /home/andrea/.config/osc/oscrc [general] apiurl = https://api.opensuse.org ccache = 1 extra-pkgs = vim gdb strace less unzip procps psutils psmisc show_download_progress = 0 [https://api.opensuse.org] user=YOURUSERNAME pass=YOURPASSWORD üõ†Ô∏è OBS project setup Now we can switch to our development directory and create a subproject inside our home folder:\n$ cd osc $ cd home:amanzini $ osc mkpac battleship-rs A battleship-rs $ cd battleship-rs üç≤ Configure build system To properly build a Rust package, we need three items:\na .spec file a _service file a cargo_config file The first one is the classic RPM .spec, the recipe we need for cooking any rpm package. We leverage some macros to make the process smooth and easy. This also makes me notice there isn\u0026rsquo;t yet a syntax highlighter for spec files\u0026hellip;ü§®\n$ cat battleship-rs.spec Name: battleship-rs # This will be set by osc services, that will run after this. Version: 0.1.1~0 Release: 0 Summary: Battleship game implemented in Rust. License: MIT Url: https://github.com/orhun/battleship-rs Source0: %{name}-%{version}.tar.zst Source1: vendor.tar.zst Source2: cargo_config BuildRequires: cargo-packaging # Disable this line if you wish to support all platforms. # In most situations, you will likely only target tier1 arches for user facing components. ExclusiveArch: %{rust_tier1_arches} # the name of the actual binary program when differs from the project %define bin_name battleship %description A Battleship game implemented in Rust. Mainly for package practice %prep # The number passed to -a (a stands for \u0026#34;after\u0026#34;) should be equivalent to the Source tag number # of the vendor tarball, 1 in this case (from Source1). %autosetup -p1 -a1 install -D -m 644 %{SOURCE2} .cargo/config # Remove exec bits to prevent an issue in fedora shebang checking. Uncomment only if required. # find vendor -type f -name \\*.rs -exec chmod -x \u0026#39;{}\u0026#39; \\; %build %{cargo_build} %install # using cargo_install (only supports bindir) # %{cargo_install} # manual process install -D -d -m 0755 %{buildroot}%{_bindir} install -m 0755 %{_builddir}/%{name}-%{version}/target/release/%{bin_name} %{buildroot}%{_bindir}/%{bin_name} # this is useful if you want to run the program internal test suite %check %{cargo_test} %files %{_bindir}/%{bin_name} %license LICENSE %doc README.md %changelog The second one is where the real magic happens. Using this configuration file, OBS is able to run many services on our project. First of all, it can checkout the exact version from git and generate for us a .changes file with the commit messages. Then it can build a compressed archive of the sources and run a special cargo vendor task that manages to make all our dependencies available for an offline build:\n$ cat _service \u0026lt;services\u0026gt; \u0026lt;service mode=\u0026#34;disabled\u0026#34; name=\u0026#34;obs_scm\u0026#34;\u0026gt; \u0026lt;param name=\u0026#34;url\u0026#34;\u0026gt;https://github.com/orhun/battleship-rs.git\u0026lt;/param\u0026gt; \u0026lt;param name=\u0026#34;versionformat\u0026#34;\u0026gt;@PARENT_TAG@~@TAG_OFFSET@\u0026lt;/param\u0026gt; \u0026lt;param name=\u0026#34;scm\u0026#34;\u0026gt;git\u0026lt;/param\u0026gt; \u0026lt;param name=\u0026#34;revision\u0026#34;\u0026gt;v0.1.1\u0026lt;/param\u0026gt; \u0026lt;param name=\u0026#34;match-tag\u0026#34;\u0026gt;*\u0026lt;/param\u0026gt; \u0026lt;param name=\u0026#34;versionrewrite-pattern\u0026#34;\u0026gt;v(\\d+\\.\\d+\\.\\d+)\u0026lt;/param\u0026gt; \u0026lt;param name=\u0026#34;versionrewrite-replacement\u0026#34;\u0026gt;\\1\u0026lt;/param\u0026gt; \u0026lt;param name=\u0026#34;changesgenerate\u0026#34;\u0026gt;enable\u0026lt;/param\u0026gt; \u0026lt;param name=\u0026#34;changesauthor\u0026#34;\u0026gt;andrea.manzini@suse.com\u0026lt;/param\u0026gt; \u0026lt;/service\u0026gt; \u0026lt;service mode=\u0026#34;disabled\u0026#34; name=\u0026#34;tar\u0026#34; /\u0026gt; \u0026lt;service mode=\u0026#34;disabled\u0026#34; name=\u0026#34;recompress\u0026#34;\u0026gt; \u0026lt;param name=\u0026#34;file\u0026#34;\u0026gt;*.tar\u0026lt;/param\u0026gt; \u0026lt;param name=\u0026#34;compression\u0026#34;\u0026gt;zst\u0026lt;/param\u0026gt; \u0026lt;/service\u0026gt; \u0026lt;service mode=\u0026#34;disabled\u0026#34; name=\u0026#34;set_version\u0026#34;/\u0026gt; \u0026lt;service name=\u0026#34;cargo_vendor\u0026#34; mode=\u0026#34;disabled\u0026#34;\u0026gt; \u0026lt;param name=\u0026#34;src\u0026#34;\u0026gt;battleship-rs\u0026lt;/param\u0026gt; \u0026lt;param name=\u0026#34;compression\u0026#34;\u0026gt;zst\u0026lt;/param\u0026gt; \u0026lt;param name=\u0026#34;update\u0026#34;\u0026gt;true\u0026lt;/param\u0026gt; \u0026lt;/service\u0026gt; \u0026lt;/services\u0026gt; The last item we need is a small file that instructs Rust build system to use vendored dependencies, instead of downloading from the internet.\n$ cat cargo_config [source.crates-io] replace-with = \u0026#34;vendored-sources\u0026#34; [source.vendored-sources] directory = \u0026#34;vendor\u0026#34; üö¢ Fetch upstream source and check in to OBS The following commands will\nrun the services to execute the tasks (this will create two .zst archives) add all the files, included the configuration, to OBS versioning send everything to the build server $ osc service runall $ osc addremove $ osc checkin Potentially we are done, build will start on a OBS worker and we can check the build log; If we want to try everything locally, we are ready to\nüèóÔ∏è Local build $ osc build Building battleship-rs.spec for openSUSE_Tumbleweed/x86_64 ... [lots of output omitted] ... build: extracting built packages... RPMS/x86_64/battleship-rs-0.1.1~0-0.x86_64.rpm SRPMS/battleship-rs-0.1.1~0-0.src.rpm OTHER/_statistics OTHER/rpmlint.log üéÆ Let\u0026rsquo;s test installation Since we just packaged a game, why not give it a try ?\n$ sudo zypper in battleship-rs-0.1.1~0-0.x86_64.rpm Refreshing service \u0026#39;openSUSE\u0026#39;.................................................[done] Loading repository data... Reading installed packages... Resolving package dependencies... The following NEW package is going to be installed: battleship-rs 1 new package to install. Overall download size: 223.4 KiB. Already cached: 0 B. After the operation, additional 574.3 KiB will be used. Continue? [y/n/v/...? shows all options] (y): Retrieving: battleship-rs-0.1.1~0-0.x86_64 (Plain RPM files cache) (1/1), 223.4 KiB battleship-rs-0.1.1~0-0.x86_64.rpm: Package header is not signed! battleship-rs-0.1.1~0-0.x86_64 (Plain RPM files cache): Signature verification failed [6-File is unsigned] Abort, retry, ignore? [a/r/i] (a): i Checking for file conflicts: .................................................[done] (1/1) Installing: battleship-rs-0.1.1~0-0.x86_64 .............................[done] Running post-transaction scripts .............................................[done] now the package is installed, we can try it out; on the \u0026lsquo;server\u0026rsquo; we will see the battlefield and client connections:\n$ battleship [+] Server is listening on 127.0.0.1:1234 [+] New connection: 127.0.0.1:33692 [+] New connection: 127.0.0.1:41104 [#] Andrea\u0026#39;s grid: A B C D E F G H I J 1 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ 2 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚ñ≠ ‚ñ≠ ‚Ä¢ ‚Ä¢ 3 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚ñ≠ ‚ñ≠ ‚Ä¢ 4 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ 5 ‚Ä¢ ‚ñß ‚ñß ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ 6 ‚Ä¢ ‚ñß ‚ñß ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ 7 ‚Ä¢ ‚ñß ‚ñß ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ 8 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ 9 ‚Ä¢ ‚Ä¢ ‚ñ≥ ‚ñ≥ ‚ñ≠ ‚ñ≠ ‚ñ≠ ‚ñ≠ ‚Ä¢ ‚Ä¢ 10 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ [#] ilmanzo\u0026#39;s grid: A B C D E F G H I J 1 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ 2 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚ñØ 3 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚ñØ 4 ‚ñ≠ ‚ñ≠ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ 5 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚ñØ ‚Ä¢ 6 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚ñØ ‚Ä¢ 7 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚ñ≠ ‚ñ≠ ‚Ä¢ ‚Ä¢ 8 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ 9 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ 10 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ [#] Game is starting. [#] Andrea\u0026#39;s turn. to actually play the game, we need to spawn two different terminals and contact the server, no cheating allowed :)\n$ nc 127.0.0.1 1234 _ _ __|_|__|_|__ _|____________|__ |o o o o o o o o / ~\u0026#39;`~\u0026#39;`~\u0026#39;`~\u0026#39;`~\u0026#39;`~\u0026#39;`~\u0026#39;`~ Welcome to Battleship! Please enter your name: ilmanzo Your opponent is Andrea Game starts in 3... Game starts in 2... Game starts in 1... A B C D E F G H I J 1 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ 2 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ 3 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ 4 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ 5 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ 6 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ 7 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ 8 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ 9 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ 10 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ A B C D E F G H I J 1 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ 2 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚ñØ 3 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚ñØ 4 ‚ñ≠ ‚ñ≠ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ 5 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚ñØ ‚Ä¢ 6 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚ñØ ‚Ä¢ 7 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚ñ≠ ‚ñ≠ ‚Ä¢ ‚Ä¢ 8 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ 9 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ 10 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ Andrea\u0026#39;s turn. üéá Final toughts First of all, thanks to Orhun Parmaksƒ±z for writing an awesome terminal game!\nIf you want to get better as packager be sure to read this excellent guide from Michael Vetter.\nMore details on the history and choices behind Rust packaging in openSUSE are in William Brown\u0026rsquo;s talk on RustConf 2022 You can find all the files and the project in my home folder on the openSUSE build service. Happy hacking!\n","permalink":"https://ilmanzo.github.io/post/introduction_to_packaging_rust_applications/","summary":"ü¶Ä Intro As an exercise, today we are going to package a game named battleship-rs developed by Orhun Parmaksƒ±z. We will also use the power of OpenSUSE build service to do most of the heavy work.\nBefore starting, let\u0026rsquo;s check out the project: it\u0026rsquo;s hosted on github and if you want to try it out before packaging, it\u0026rsquo;s a nice game where two people can play in the terminal over a TCP network connection.","title":"Introduction to packaging Rust application"},{"content":"Prelude This is a followup from my previous post and a sort of continuation on the series of the topic, where we are exploring ways to make our test system more \u0026ldquo;unreliable\u0026rdquo; in order to observe if our applications behave nicely under challenging and not-ideal environments.\nIn this article we are going to explore some linux technologies:\nNetwork Namespaces (netns) Virtual Ethernet Devices (veth) Network Emulation (netem) scheduling policy The goal is to setup a virtual network link inside our system, make the two network devices talk each other and then simulate a bad/slow/glitchy/flaky communication to test how applications behave under difficult conditions.\nReady to play and break something ?\nImage credits: Abdulvahap Demir\nSetup netns Network namespaces represent a core technology essential for containers, enabling the establishment of segregated network environments within a Linux system. They facilitate the creation of distinct network stacks for processes, including interfaces, routing tables, and firewall rules. This segregation guarantees that processes within one network namespace remain separate and insulated from those in other namespaces.\nto create and manage netns we just need the ip command:\n$ ip netns add ns_1 $ ip netns add ns_2 With this commands we just configured an empty space, now we need to place something inside.\nSetup virtual ethernet Veth devices, abbreviated from virtual Ethernet devices, are dual virtual network interfaces employed to link network namespaces. Each pair comprises two endpoints: one within a specific namespace and the other in a separate namespace. These virtual interfaces mimic Ethernet cables, enabling seamless communication between the interconnected namespaces. Traffic can traverse this veth pair bidirectionally, facilitating two-way transmission.\n$ ip link add veth_1 type veth peer name veth_2 $ ip link set veth_1 netns ns_1 $ ip link set veth_2 netns ns_2 $ ip netns exec ns_1 ip link set dev veth_1 up $ ip netns exec ns_2 ip link set dev veth_2 up note: ip netns ns_1 exec COMMAND is an handy shorthand for executing a single command in a specific namespace.\nInside your machine, there now will be two new independent namespaces, each with its own virtual network card, totally separate from the host environment:\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Linux machine ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ ‚îÇ ns_1 ‚îÇ ‚îÇ ns_2 ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ veth_1 ‚îÇ ‚îÇ veth_2 ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò Addressing So far your virtual devices does not yet have any IP address, even loopback is down:\n$ ip -all netns exec ip link show netns: ns_1 1: lo: \u0026lt;LOOPBACK\u0026gt; mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 9: veth_1@if8: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000 link/ether 52:69:cf:de:7d:10 brd ff:ff:ff:ff:ff:ff link-netns ns_2 netns: ns_2 1: lo: \u0026lt;LOOPBACK\u0026gt; mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 8: veth_2@if9: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000 link/ether 6e:19:3c:20:e0:9a brd ff:ff:ff:ff:ff:ff link-netns ns_1 let\u0026rsquo;s give them a random IPV4 on the same subnet:\n$ ip netns exec ns_1 ip addr add 10.1.1.1/24 dev veth_1 $ ip netns exec ns_2 ip addr add 10.1.1.2/24 dev veth_2 The cool thing now is that we can reach the other end only via namespace. Just to be clear, this is not going to work:\n$ ping -c 3 10.1.1.2 PING 10.1.1.2 (10.1.1.2) 56(84) bytes of data. --- 10.1.1.2 ping statistics --- 3 packets transmitted, 0 received, 100% packet loss, time 2020ms Why ? Because we need to run ping command from the proper namespace:\n$ ip netns exec ns_1 ping -c 3 10.1.1.2 PING 10.1.1.2 (10.1.1.2) 56(84) bytes of data. 64 bytes from 10.1.1.2: icmp_seq=1 ttl=64 time=0.040 ms 64 bytes from 10.1.1.2: icmp_seq=2 ttl=64 time=0.044 ms 64 bytes from 10.1.1.2: icmp_seq=3 ttl=64 time=0.057 ms --- 10.1.1.2 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2021ms rtt min/avg/max/mdev = 0.040/0.047/0.057/0.007 ms Looking at those rtt numbers, this virtual network seems working fast and smooth, so it\u0026rsquo;s time to break something\u0026hellip; üòà\nFault injection Let\u0026rsquo;s add a 50ms ¬± 25ms random delay to each packet on one side:\n$ ip netns exec ns_1 tc qdisc add dev veth_1 root netem delay 50ms 25ms on the other side, we also simulate a 50% chance of a dropped packed, with a 25% chance of subsequent packet loss (to emulate packet burst losses)\n$ ip netns exec ns_2 tc qdisc add dev veth_2 root netem loss 50% 25% How the ping will do ? Pretty bad indeed: üëé\n$ ip netns exec ns_1 ping -c 10 10.1.1.2 PING 10.1.1.2 (10.1.1.2) 56(84) bytes of data. 64 bytes from 10.1.1.2: icmp_seq=1 ttl=64 time=66.6 ms 64 bytes from 10.1.1.2: icmp_seq=3 ttl=64 time=34.6 ms 64 bytes from 10.1.1.2: icmp_seq=4 ttl=64 time=41.6 ms 64 bytes from 10.1.1.2: icmp_seq=6 ttl=64 time=28.0 ms 64 bytes from 10.1.1.2: icmp_seq=9 ttl=64 time=51.6 ms 64 bytes from 10.1.1.2: icmp_seq=10 ttl=64 time=50.8 ms --- 10.1.1.2 ping statistics --- 10 packets transmitted, 6 received, 40% packet loss, time 9081ms rtt min/avg/max/mdev = 28.031/45.522/66.569/12.561 ms Another couple cool features of netem are Packet corruption, which simulates a single bit error at a random offset in the packet, and Packet Re-ordering, which causes a certain percentage of the packets to arrive in a wrong order. For any detail, you can consult the tc-netem(8) man page.\nWrap and clean up We ended with a simulated network where we can control packet loss and delay / jitter , we can do any experiment we need by running our services in the proper namespace.\nWhen we are finished, if we don\u0026rsquo;t have any other namespace defined, it\u0026rsquo;s simple to remove every track from our system with a single command:\n$ ip --all netns del ","permalink":"https://ilmanzo.github.io/post/faulty_network_simulation/","summary":"Prelude This is a followup from my previous post and a sort of continuation on the series of the topic, where we are exploring ways to make our test system more \u0026ldquo;unreliable\u0026rdquo; in order to observe if our applications behave nicely under challenging and not-ideal environments.\nIn this article we are going to explore some linux technologies:\nNetwork Namespaces (netns) Virtual Ethernet Devices (veth) Network Emulation (netem) scheduling policy The goal is to setup a virtual network link inside our system, make the two network devices talk each other and then simulate a bad/slow/glitchy/flaky communication to test how applications behave under difficult conditions.","title":"Fault Injection in Network Namespace and Veth Environments"},{"content":"Work Experience 2022-now: QE Automation Engineer, SUSE\nAutomated test development and quality assurance for SUSE product release. Became maintainer of some RPM package. Opensource contributor\n2017-2022: cloud \u0026amp; automation senior sw engineer, Value Transformation Services\nWorked on a fully automated hybrid cloud implementation. Deliver and manage, with DevOps best practices, a custom platform that customer uses to request IaaS and PaaS solutions\n2013-2016: linux senior system engineer, Value Transformation Services\nManaged and introduced full automation on a multi-datacenter fleet of approx 18.000 linux servers\n2011-2013: linux system engineer, Unicredit\n2005-2011: developer of remote payments and remote banking product for Unicredit group\nWorked on remote banking products, both on desktop and POS technologies\n2001-2005: network \u0026amp; security administrator in Quercia Software spa\nAdministration of LAN and WAN devices, security and implementation of VoIP infrastructure\n2000-2001: sysadmin, network administrator in a local Internet Service Provider Netbusiness spa\nManaged ISP services, network and operations\n1999-2000: developer, DBA Oracle and VAX/VMS sysadmin\nImplemented customizations and migrations on world largest library management software\nstarted working in IT industry since 1993; first Linux server installed on 1995\nCertifications 2022: AZ-204 Microsoft Azure Developer Associate 2021: AZ-900 Microsoft Azure Fundamentals 2021: Red Hat Certified Engineer (certificate number 140-219-585) 2018: Red Hat Certified Specialist in Ansible Automation (certificate number 140-219-585) 2018: Certified Openstack Administrator Linux Foundation Certificate id COA-1800-001215-0100 2018: SUSE Certified Engineer in Enterprise Linux - SLES 12 (certificate id 10170115) 2017: SUSE Certified Administrator in Enterprise Linux - SLES 12 (certificate id 10170115) 2016: RHCVA: RedHat Certified Virtualization Administrator (certificate number 140-219-585) 2015: RHCE: RedHat Certified Engineer in Red Hat Enterprise Linux 7 (certificate number 140-219-585) 2015: RedHat Certified System Administrator in Red Hat Enterprise Linux 7 (certificate number 140-219-585) 2014: RedHat Certified System Administrator in Red Hat Openstack (certificate number 140-219-585) 2012: Novell CLA certification with score 791/800 Published writings 2004: Linux\u0026amp;C, magazine features on PAM subsystem (Pluggable Authentication Modules) 2005: Linux\u0026amp;C, magazine features on Unicode and its Linux implementation 2006: Linux\u0026amp;C, series on SNMP, MRTG and network monitoring 2008: Linux\u0026amp;C, features on gnome desklets 2010: Linux\u0026amp;C, wiki MoinMoin, how to extend it with python 2010: Linux\u0026amp;C, features on imagemagick (command line graphics) Training 2023: Schr√∂dinger Session: Learning Rust, one step at the time from Schr√∂dinger Hat community 2022: Ultimate Rust Crash Course, udemy 2021: Learn Rust by Building Real Application, udemy 2021: Building Modern Python Applications on AWS, Coursera 2021: Data Center Automation with vRealize Orchestrator and vSphere PowerCLI 2021: Red Hat Linux Automation with Ansible (RH294) 2019: DevOps Engineering on AWS 2018: Systems Operations on AWS 2018: Developing on AWS 2018: Red Hat Automation with Ansible (DO407) 2017: Red Hat JBoss Application Administration I (JB248) 2017: Suse Linux 12 academy, SUSE OpenStack Cloud Academy 2016: Red Hat Enterprise Virtualization (RH318) 2015: RHCE Certification lab with RHCSA and RHCE exams (RH300) 2014: Red Hat OpenStack Administration with Expertise Exam (CL211) 2011: RH442 Red Hat Enterprise Performance Tuning 2011: RH346 Red Hat Enterprise Clustering and Storage Management 2010: MIE3520 Win32 System Programming presso Mondadori Informatica 2010: MIE3510 Programming in ANSI C++ presso Mondadori Informatica 2009: Java Fundamentals, the Java programming language presso Overnet Education 2008: Cisco BCMSN - Building Cisco Multilayer Switched Networks 2007: Microsoft MOC 2159 Deploying and Managing Microsoft Internet Security and Acceleration (ISA) Server 2007: Microsoft MOC 2150 Designing a Secure Microsoft Windows 2000 Network 2006: Microsoft MOC 2153 Implementing a Microsoft Windows 2000 Network Infrastructure 2006: Microsoft MOC 2087 Implementing Windows 2000 clustering 2005: ES-331 Sun Enterprise Cluster Administration Veritas Volume Other experiences 2023: speaker at Google Developer Group Trento DevFest 2023: became Ambassador for the Crystal Programming Language 2022: became maintainer of openSUSE rpm packages on Open Build Service 2022: workshop about web application testing for a private company 2021: held c# training for young students doing internship in a private company 2021: held an IoT server security webinar for Verona FabLab 2020: held a Cryptography / security (blockchain) training course for Verona FabLab 2019: held Linux and Python and training courses 2018: gave a talk for FEVR about chatbots and Go Programming language. Slides linked here 2017: held a linux training course in FabLab Verona 2016: started contributing to open source projects see github profile 2016: held a Python training course in FabLab Verona 2016: held a linux training course in FabLab Verona ","permalink":"https://ilmanzo.github.io/curriculum/","summary":"Work Experience 2022-now: QE Automation Engineer, SUSE\nAutomated test development and quality assurance for SUSE product release. Became maintainer of some RPM package. Opensource contributor\n2017-2022: cloud \u0026amp; automation senior sw engineer, Value Transformation Services\nWorked on a fully automated hybrid cloud implementation. Deliver and manage, with DevOps best practices, a custom platform that customer uses to request IaaS and PaaS solutions\n2013-2016: linux senior system engineer, Value Transformation Services","title":"my resume"},{"content":"\u0026ldquo;You sound like a broken record\u0026rdquo; Is something we complain when someone repeats again and again the same concepts. But even broken disks can sometime be useful\nDISCLAIMER: No filesystem or device were harmed in the making of this experiment üòâ\nImage credits: Mick Haupt\nIn this article I would like to explore the powerful tools we have in Linux to simulate dealing with broken disks, that is, drives that more or less randomly report errors. Why is this important ? Because by simulating errors that will also happen sooner or later in the real world, we are able to create software that is more robust and can withstand any problems on the infrastructure.\nSetup In order not to have troubles in our development system, and to make the process as portable as possible, we start by creating a dummy 1GB disk based on the loop device.\n# dd if=/dev/zero of=/myfakedisk.bin bs=1M count=1024 1024+0 records in 1024+0 records out 1073741824 bytes (1.1 GB, 1.0 GiB) copied, 0.446898 s, 2.4 GB/s # losetup /dev/loop0 /myfakedisk.bin Now we can use the loop device just like any other block device: we can create a filesystem and mount it\n# mkfs.ext4 /dev/loop0 mke2fs 1.46.4 (18-Aug-2021) Discarding device blocks: done Creating filesystem with 262144 4k blocks and 65536 inodes Filesystem UUID: bcba505c-54fa-49e5-852c-b5ea3faa53d0 Superblock backups stored on blocks: 32768, 98304, 163840, 229376 Allocating group tables: done Writing inode tables: done Creating journal (8192 blocks): done Writing superblocks and filesystem accounting information: done # mkdir /mnt/good \u0026amp;\u0026amp; mount /dev/loop0 /mnt/good \u0026amp;\u0026amp; echo \u0026#34;test\u0026#34; \u0026gt; /mnt/good/test.txt \u0026amp;\u0026amp; umount /mnt/good our working \u0026ldquo;virtual disk\u0026rdquo; is ready, now we can create a faulty one using linux\u0026rsquo;s device mapper features.\nWhat\u0026rsquo;s device mapper ? Image credits: Monstera Production\nThe Linux Device Mapper is a kernel-level framework that enables the creation of virtual block devices by mapping physical storage devices or logical volumes to these virtual devices. It operates within the Linux kernel, providing a layer for creating, managing, and manipulating storage devices through various mapping techniques such as mirroring, striping, encryption, and snapshots. This framework allows for the implementation of advanced storage features like volume management, RAID, and thin provisioning, offering greater flexibility, scalability, and reliability in managing storage resources within the Linux operating system.\nBasically we are going to create a \u0026ldquo;map\u0026rdquo; between our working device and a \u0026ldquo;new\u0026rdquo; one, with this rough schema:\nfrom sector 0 to 2047, get the data from the underlying device (because we don\u0026rsquo;t want to mess with partition table and metadata) from sector 2048 to half disk size, return an error, or the original data, with 20% odds of failure from half size to the end, return again the data from the underlying device Disk size can be found with a simple check:\n# cat /sys/block/loop0/size 2097152 This kind of mapping is expressed in the dmsetup create command:\n# dmsetup create bad_disk \u0026lt;\u0026lt; EOF 0 2048 linear /dev/loop0 0 2048 1047552 flakey /dev/loop0 2048 4 1 1049600 1047552 linear /dev/loop0 1049600 EOF # ls -l /dev/mapper/bad_disk lrwxrwxrwx 1 root root 7 Nov 19 17:51 /dev/mapper/bad_disk -\u0026gt; ../dm-0 For each table entry, we need to specify:\nstart sector/offset of mapping size of the mapping which mapper is being used options of the mapper (for details refer to the documentation) In this setup we are using the linear mapper and the flakey one. Another useful one can be delay to simulate very slow disks or dust that emulates the behavior of bad sectors at arbitrary locations, and the ability to enable the emulation of the failures at an arbitrary time.\nLet\u0026rsquo;s try it out Our backing disk is already formatted, so it\u0026rsquo;s time to try out the bad one, by mounting and writing some stuff:\n# mkdir /mnt/bad \u0026amp;\u0026amp; mount /dev/mapper/bad_disk /mnt/bad \u0026amp;\u0026amp; cd /mnt/bad # df -h | grep -E \u0026#39;(^Filesystem|bad)\u0026#39; Filesystem Size Used Avail Use% Mounted on /dev/mapper/bad_disk 974M 28K 907M 1% /mnt/bad # while sleep 1 ; do dd if=/dev/zero of=trytowrite.bin bs=1M count=500 ; done 500+0 records in 500+0 records out 524288000 bytes (524 MB, 500 MiB) copied, 0.595353 s, 881 MB/s 500+0 records in 500+0 records out 524288000 bytes (524 MB, 500 MiB) copied, 0.637194 s, 823 MB/s Message from syslogd@localhost at Nov 19 18:09:15 ... kernel:[ 8017.117593][T23594] EXT4-fs (dm-0): failed to convert unwritten extents to written extents -- potential data loss! (inode 13, error -30) Message from syslogd@localhost at Nov 19 18:09:15 ... kernel:[ 8017.118445][T23976] EXT4-fs (dm-0): failed to convert unwritten extents to written extents -- potential data loss! (inode 13, error -30) dd: error writing \u0026#39;trytowrite.bin\u0026#39;: Read-only file system 481+0 records in 480+0 records out 503865344 bytes (504 MB, 481 MiB) copied, 0.549939 s, 916 MB/s dd: failed to open \u0026#39;trytowrite.bin\u0026#39;: Read-only file system dd: failed to open \u0026#39;trytowrite.bin\u0026#39;: Read-only file system dd: failed to open \u0026#39;trytowrite.bin\u0026#39;: Read-only file system dd: failed to open \u0026#39;trytowrite.bin\u0026#39;: Read-only file system dd: failed to open \u0026#39;trytowrite.bin\u0026#39;: Read-only file system Disk failure is a success! As we can see, at first some I/O operations succeeds, then the disk fails and in dmesg log we can find more details:\n[ 7962.645178] EXT4-fs (dm-0): error loading journal [ 7979.334186] EXT4-fs (dm-0): mounted filesystem with ordered data mode. Opts: (null). Quota mode: none. [ 8016.759602] EXT4-fs warning (device dm-0): ext4_end_bio:347: I/O error 10 writing to inode 13 starting block 129024) [ 8016.759641] EXT4-fs warning (device dm-0): ext4_end_bio:347: I/O error 10 writing to inode 13 starting block 129280) [ 8016.759685] EXT4-fs warning (device dm-0): ext4_end_bio:347: I/O error 10 writing to inode 13 starting block 129536) [ 8016.759802] EXT4-fs warning (device dm-0): ext4_end_bio:347: I/O error 10 writing to inode 13 starting block 129870) [ 8016.760119] EXT4-fs warning (device dm-0): ext4_end_bio:347: I/O error 10 writing to inode 13 starting block 130625) [ 8016.760122] Buffer I/O error on device dm-0, logical block 130625 [ 8016.760129] Buffer I/O error on device dm-0, logical block 130626 [ 8016.760131] Buffer I/O error on device dm-0, logical block 130627 [ 8016.760132] Buffer I/O error on device dm-0, logical block 130628 [ 8016.760133] Buffer I/O error on device dm-0, logical block 130629 [ 8016.760134] Buffer I/O error on device dm-0, logical block 130630 [ 8016.760135] Buffer I/O error on device dm-0, logical block 130631 [ 8016.760136] Buffer I/O error on device dm-0, logical block 130632 [ 8016.760137] Buffer I/O error on device dm-0, logical block 130633 [ 8016.760138] Buffer I/O error on device dm-0, logical block 130634 [ 8016.923667] EXT4-fs warning (device dm-0): ext4_end_bio:347: I/O error 10 writing to inode 13 starting block 54272) [ 8016.923731] EXT4-fs warning (device dm-0): ext4_end_bio:347: I/O error 10 writing to inode 13 starting block 54783) [ 8016.924020] EXT4-fs warning (device dm-0): ext4_end_bio:347: I/O error 10 writing to inode 13 starting block 55296) [ 8016.924335] EXT4-fs warning (device dm-0): ext4_end_bio:347: I/O error 10 writing to inode 13 starting block 60416) [ 8016.924394] EXT4-fs warning (device dm-0): ext4_end_bio:347: I/O error 10 writing to inode 13 starting block 61803) [ 8016.961108] Buffer I/O error on dev dm-0, logical block 131103, lost sync page write [ 8016.961125] Aborting journal on device dm-0-8. [ 8016.961127] Buffer I/O error on dev dm-0, logical block 131072, lost sync page write [ 8016.961128] JBD2: Error -5 detected when updating journal superblock for dm-0-8. [ 8016.961142] EXT4-fs error (device dm-0): ext4_journal_check_start:83: comm kworker/u2:3: Detected aborted journal [ 8016.966200] EXT4-fs error (device dm-0): ext4_journal_check_start:83: comm dd: Detected aborted journal In a more general sense, these concepts fall under the principle of \u0026ldquo;chaos engineering\u0026rdquo;. This can be also a good practice for junior sysadmins that wants to learn how to cope with a damaged filesystem and try to recover data.\nCleanup To remove the tracks of our experiments, it\u0026rsquo;s sufficient to unmount the \u0026ldquo;bad\u0026rdquo; disk, remove the mapping and unassociate the loop device with the backing file.\n# umount /mnt/bad \u0026amp;\u0026amp; rmdir /mnt/bad # dmsetup remove bad_disk # losetup -d /dev/loop0 ","permalink":"https://ilmanzo.github.io/post/faulty_disk_simulation/","summary":"\u0026ldquo;You sound like a broken record\u0026rdquo; Is something we complain when someone repeats again and again the same concepts. But even broken disks can sometime be useful\nDISCLAIMER: No filesystem or device were harmed in the making of this experiment üòâ\nImage credits: Mick Haupt\nIn this article I would like to explore the powerful tools we have in Linux to simulate dealing with broken disks, that is, drives that more or less randomly report errors.","title":"Expect the unexpected"},{"content":"Intro üöå D-Bus is a message bus system and standard for inter-process communication, mostly used in Linux desktop applications. Both Qt and GLib have high-level abstractions for D-Bus communication, and many of the desktop services we rely on export D-Bus protocols. Also the omnipresent systemd can be only interfaced via D-Bus API. However, D-Bus has its shortcomings ‚Äî namely a lack of documentation. In this article we\u0026rsquo;ll explore how to write our own D-Bus Service in Rust and connect it to our D-Bus client.\nAs as starter, if you want to get some practice on D-Bus, I recommend this tutorial and here you may like to refresh some D-Bus naming and concepts.\nAll the code lives in its own GitHub repository, so you can follow along and try yourself. Enjoy the trip!\nImage credits to: Nubia Navarro\nThe Service Our exposed service will be very simple: once called, it will keep track of how many times it has been called and last date/time. We can also pass our name as parameter, just to show how parameter passing works.\nThanks to a wonderful Rust crate, creating D-Bus service is rather easy. We opt to make it async, because\u0026hellip; Why not ?\nThe core function is the trait implementation:\nstruct MyService { call_count: u64, call_timestamp: Option\u0026lt;DateTime\u0026lt;Local\u0026gt;\u0026gt;, } #[dbus_interface(name = \u0026#34;org.zbus.MyService\u0026#34;)] impl MyService { async fn call_me(\u0026amp;mut self, name: \u0026amp;str) -\u0026gt; String { let msg = match self.call_count { 0 =\u0026gt; format!(\u0026#34;Hi {}, this is the first time you call me!\u0026#34;, name), _ =\u0026gt; format!( \u0026#34;Hello {}, I have been called {} times, last was at {}\u0026#34;, name, self.call_count, self.call_timestamp .expect(\u0026#34;unable to get local time\u0026#34;) .to_rfc2822() ), }; self.call_count += 1; self.call_timestamp = Some(Local::now()); msg } } Let\u0026rsquo;s try it out Compile the whole project with\n$ cargo build --release Then you can run the service binary, which will block waiting for connections\n$ target/release/service With the service running, we can inspect and probe it using any D-Bus client, such as D-Feet or busctl\n$ SVC=org.zbus.MyService $ busctl --user call $SVC /org/zbus/MyService $SVC CallMe s \u0026#34;Andrea\u0026#34; s \u0026#34;Hi Andrea, this is the first time you call me!\u0026#34; $ busctl --user call $SVC /org/zbus/MyService $SVC CallMe s \u0026#34;Andrea\u0026#34; s \u0026#34;Hello Andrea, I have been called 1 times, last was at Tue, 3 Oct 2023 18:08:16 +0200\u0026#34; $ busctl --user call $SVC /org/zbus/MyService $SVC CallMe s \u0026#34;Andrea\u0026#34; s \u0026#34;Hello Andrea, I have been called 2 times, last was at Tue, 3 Oct 2023 18:09:43 +0200\u0026#34; You can notice the small s character before the name parameter. This is the parameter type declaration, following the D-Bus type system\nWell, our service seems working, we could stop here but let\u0026rsquo;s also implement \u0026hellip;\nThe Client A simple client is nice to have and will help a lot when we want to add functional testing to our project. Also it makes us exercise a nice Cargo feature named workspaces to host multiple binaries inside the same project.\nSince source code is short we can paste as a whole:\nuse zbus::{dbus_proxy, Connection, Result}; #[dbus_proxy( interface = \u0026#34;org.zbus.MyService\u0026#34;, default_service = \u0026#34;org.zbus.MyService\u0026#34;, default_path = \u0026#34;/org/zbus/MyService\u0026#34; )] trait MyService { async fn call_me(\u0026amp;self, name: \u0026amp;str) -\u0026gt; Result\u0026lt;String\u0026gt;; } #[tokio::main] async fn main() -\u0026gt; Result\u0026lt;()\u0026gt; { let connection = Connection::session().await?; // `dbus_proxy` macro creates `MyServiceProxy` based on `Notifications` trait. let proxy = MyServiceProxy::new(\u0026amp;connection).await?; let reply = proxy.call_me(\u0026#34;Andrea\u0026#34;).await?; println!(\u0026#34;{reply}\u0026#34;); Ok(()) } You should have it already compiled, so with the service running, just issue a\n$ target/release/client \u0026#34;Hello Andrea, I have been called 3 times, last was at Tue, 3 Oct 2023 18:19:26 +0200\u0026#34; Looks like we can park the bus for now and stop our journey here üòä\nImage credits to Hans Middendorp\nConclusion The D-Bus low-level API reference implementation and the D-Bus protocol have been heavily tested in the real world over several years, and are now \u0026ldquo;set in stone.\u0026rdquo; Future changes will either be compatible or versioned appropriately.\nD-Bus is ~15y old technology, but still in use. Unfortunately many documents out there are sometime aging or misleading so it can be helpful to refresh it a bit and play with this message bus system. Happy Hacking!\n","permalink":"https://ilmanzo.github.io/post/a_trip_on_the_rusty_dbus/","summary":"Intro üöå D-Bus is a message bus system and standard for inter-process communication, mostly used in Linux desktop applications. Both Qt and GLib have high-level abstractions for D-Bus communication, and many of the desktop services we rely on export D-Bus protocols. Also the omnipresent systemd can be only interfaced via D-Bus API. However, D-Bus has its shortcomings ‚Äî namely a lack of documentation. In this article we\u0026rsquo;ll explore how to write our own D-Bus Service in Rust and connect it to our D-Bus client.","title":"A trip on the rusty D-Bus"},{"content":"Intro The Thinkpad P15 laptop is a nice linux machine, but there is an annoying detail, as Arch wiki writes: \u0026ldquo;The default operation of fans is noisy, as they are basically at medium power all the time. The thinkfan program can be used to create a quieter operation, while retaining reasonable temperatures.\u0026rdquo; . Let\u0026rsquo;s make it quieter.\nPrerequisite Install thinkfan rpm package and enable the daemon:\n# zypper in thinkfan \u0026amp;\u0026amp; systemctl enable --now thinkfan Make sure modules are loaded at startup with the options to override fan control and enable experimental features:\n$ cat /etc/modules-load.d/thinkpad.conf thinkpad_acpi coretemp $ cat /etc/modprobe.d/thinkpad_acpi.conf options thinkpad_acpi fan_control=1 experimental=1 Configuration The daemon configuration consists in a single and short file. On the first part we need to specify the virtual file containing the temperatures; then the file which controls the fan speed, and a third section wich maps the fan level to the temperature range:\n$ cat /etc/thinkfan.conf sensors: - tpacpi: /proc/acpi/ibm/thermal # Some of the temperature entries in /proc/acpi/ibm/thermal may be # irrelevant or unused, so individual ones can be selected: indices: [1, 2, 4, 5, 6] fans: - tpacpi: /proc/acpi/ibm/fan levels: - [0, 0, 60] - [2, 60, 65] - [3, 65, 70] - [5, 70, 75] - [6, 75, 80] - [7, 80, 85] - [\u0026#34;level disengaged\u0026#34;, 85, 255] Conclusion Depending on your system, you can use many other programs to control fan speed in linux; thinkfan has the advantage to be lightweight and very configurable.\n","permalink":"https://ilmanzo.github.io/post/quiet_thinkpad_fans/","summary":"Intro The Thinkpad P15 laptop is a nice linux machine, but there is an annoying detail, as Arch wiki writes: \u0026ldquo;The default operation of fans is noisy, as they are basically at medium power all the time. The thinkfan program can be used to create a quieter operation, while retaining reasonable temperatures.\u0026rdquo; . Let\u0026rsquo;s make it quieter.\nPrerequisite Install thinkfan rpm package and enable the daemon:\n# zypper in thinkfan \u0026amp;\u0026amp; systemctl enable --now thinkfan Make sure modules are loaded at startup with the options to override fan control and enable experimental features:","title":"Quiet fans on Thinkpad P15"},{"content":"Intro Unit testing of Bash functions involves the process of systematically verifying the correctness and reliability of individual functions within a Bash script. While Bash is primarily used for scripting and automation, it\u0026rsquo;s important to ensure that the functions within your scripts work as expected, especially as scripts become more complex. Unit testing in Bash can help catch bugs and prevent unexpected behavior.\nFixing bugs Working on a bugfix for an internal shell script, I wanted to add some unit tests to ensure correctness. After a quick search, I found this single-file \u0026ldquo;framework\u0026rdquo; (thanks, Ryan) that provides xUnit-style assertions. So we can use it as a starting point.\nThe main problem with the script under test is that it contains functions that directly manipulates the host filesystem, so it can be hard to extract and mock those interactions for proper testing.\nSo I decided to use a simple container to run the script in an isolated environment. While we are at, no need for daemons, just use rootless podman. This is the main script, the only to be executed and which runs all the testsuites:\n#!/bin/bash # This script will run unit test for functions in file \u0026#34;mylib\u0026#34;. # the tests are run in a container to ensure isolation from host system if [ \u0026#34;$EUID\u0026#34; -eq 0 ] then echo \u0026#34;Please don\u0026#39;t run this script as root\u0026#34; exit fi # optionally, you can use different distro images here podman run -v ..:/mnt registry.opensuse.org/opensuse/leap:latest bash /mnt/unit_tests/test_mylib.ut Run your test without damaging your system Inside the test_mylib.ut itself, which is not executable, I added another safety check, so the user is aware that test script is safe to be run only inside a container:\n#!/bin/bash source \u0026#34;/mnt/unit_tests/bunit.shl\u0026#34; source \u0026#34;/mnt/mylib.sh\u0026#34; function testSetup() { [...] } function test_single() { [...] assertEquals 0 $? } function test_duplicate() { [...] local output=$( ... ) assertNull \u0026#34;$output\u0026#34; } ## safety check if [ \u0026#34;$container\u0026#34; != \u0026#34;podman\u0026#34; ]; then echo \u0026#34;ERROR: this is script is not intended to be run directly.\u0026#34; echo \u0026#34;Don\u0026#39;t run this script standalone/outside a container, it will break your system\u0026#34; exit 0 else echo \u0026#34;Starting test...\u0026#34; runUnitTests fi Outro In conclusion, unit testing of Bash functions is an essential practice to ensure the reliability, correctness, and maintainability of your scripts. By creating comprehensive test suites and employing testing frameworks, developers can catch bugs early, improve code quality, and confidently make changes to their scripts. While testing Bash scripts might require additional considerations due to their interactions with external resources, the benefits of unit testing far outweigh the challenges, leading to more robust and predictable scripting solutions.\n","permalink":"https://ilmanzo.github.io/post/unit_testing_bash_functions/","summary":"Intro Unit testing of Bash functions involves the process of systematically verifying the correctness and reliability of individual functions within a Bash script. While Bash is primarily used for scripting and automation, it\u0026rsquo;s important to ensure that the functions within your scripts work as expected, especially as scripts become more complex. Unit testing in Bash can help catch bugs and prevent unexpected behavior.\nFixing bugs Working on a bugfix for an internal shell script, I wanted to add some unit tests to ensure correctness.","title":"Using containers for unit testing of bash functions"},{"content":"The problem When we write our programs or libraries, usually we ship to the end user a packaged binary. If a user wants to report a bug or ask for a feature, one of the most important information to have is \u0026ldquo;which version of the software are you using ?\u0026rdquo;\nSince as any good programmer you likely use a source code control system, you should not rely only on the numeric version, but it\u0026rsquo;s practical to include also the git commit hash of the software you are actually shipping.\nIncluding the Git commit hash into an executable program can be a helpful practice in various scenarios, especially during the development and deployment process. The Git commit hash is a unique identifier for a specific version of the source code, and it offers several advantages:\nVersion Identification: The Git commit hash uniquely identifies a specific version of the source code. By embedding it in the executable, you can easily determine which exact version of the code was used to build the executable. This is useful for tracking issues, debugging, and providing accurate information to support teams.\nReproducibility: When an issue or bug arises in the deployed executable, having the Git commit hash helps in reproducing the problem. With the exact source code version, developers can check out the codebase to the same state, ensuring consistent behavior for debugging and fixing the issue.\nAuditing and Compliance: In certain industries or projects, it\u0026rsquo;s essential to maintain strict control over the code used in production. Including the Git commit hash provides an audit trail, helping to ensure compliance with specific requirements or regulations.\nContinuous Integration and Continuous Deployment (CI/CD): In CI/CD pipelines, it\u0026rsquo;s crucial to maintain a clear association between the deployed executable and the source code version. The Git commit hash enables better tracking and management of the pipeline\u0026rsquo;s flow.\nCollaboration and Communication: When developers collaborate on a project, sharing executables built from specific Git commit hashes ensures that everyone is using the same version of the code. This consistency helps in debugging and ensures that everyone is working on a common base.\nRollbacks and Hotfixes: In case an issue is discovered in the deployed version of the executable, having the Git commit hash allows for quick rollbacks to a previous stable version or creating hotfixes based on a specific commit.\nTesting and QA: By including the Git commit hash in the executable, testers and quality assurance teams can quickly identify the version being tested, making it easier to report bugs and issues accurately.\nOverall, including the Git commit hash in an executable program improves traceability, accountability, and collaboration throughout the development and deployment lifecycle, making it an important best practice for software development teams. While it\u0026rsquo;s a mostly documented practice for mainstream languages, I\u0026rsquo;d like to show and promote solutions also on other languages.\nCrystal Solution In Crystal this is rather easy to achieve, thanks to compile time macros:\nVERSION = \u0026#34;0.1.0\u0026#34; GITCOMMIT = {{ `git rev-parse --short HEAD`.stringify.strip }} puts \u0026#34;This is MyProgram v#{VERSION} [##{GITCOMMIT}]\u0026#34; What\u0026rsquo;s happening ? Basically during compilation the command inside the backticks is being executed by the compiler, and output is inserted into a string variable. So convenient! So let\u0026rsquo;s built and check :\n$ shards build Dependencies are satisfied Building: myprogram $ bin/myprogram This is MyProgram v0.1.0 [#cfd90a9] To have an evidence, it\u0026rsquo;s easy to inspect the actual binary and find the string embedded:\n$ strings bin/myprogram | grep MyProgram This is MyProgram v0.1.0 [#cfd90a9] Nim Solution Also Nim Language has powerful compile time evaluation features:\n# This is just an example to get you started. A typical binary package # uses this file as the main entry point of the application. import std/strformat proc getCommitHash(): auto = staticExec(\u0026#34;git rev-parse --short HEAD\u0026#34;) const gitCommitHash: string = getCommitHash() programVersion: string = \u0026#34;0.1.0\u0026#34; when isMainModule: echo fmt\u0026#34;This is MyProgram v{programVersion}#[{gitCommitHash}]\u0026#34; let\u0026rsquo;s build and try out:\n$ nimble build -d:release --opt:size Verifying dependencies for myprogram@0.1.0 Building myprogram/myprogram using c backend $ ll total 112 drwxr-xr-x 1 andrea andrea 64 Jul 1 11:38 ./ drwxr-xr-x 1 andrea andrea 1186 Jul 1 11:09 ../ drwxr-xr-x 1 andrea andrea 144 Jul 1 11:31 .git/ -rwxr-xr-x 1 andrea andrea 39104 Jul 1 11:38 myprogram* -rw-r--r-- 1 andrea andrea 233 Jul 1 11:09 myprogram.nimble drwxr-xr-x 1 andrea andrea 26 Jul 1 11:09 src/ $ ./myprogram This is MyProgram v0.1.0 [#3416678] If you are interested in the topic, be sure to check out also Andre von Houck excellent fosdem talk: Nim Metaprogramming in the real world\n","permalink":"https://ilmanzo.github.io/post/embed_git_commit_hash_in_build/","summary":"The problem When we write our programs or libraries, usually we ship to the end user a packaged binary. If a user wants to report a bug or ask for a feature, one of the most important information to have is \u0026ldquo;which version of the software are you using ?\u0026rdquo;\nSince as any good programmer you likely use a source code control system, you should not rely only on the numeric version, but it\u0026rsquo;s practical to include also the git commit hash of the software you are actually shipping.","title":"Embed git commit hash into an executable"},{"content":"Nostalgia time! Today I decided to play with Raylib and the Crystal Programming Language.\nTechnically speaking, the \u0026ldquo;plasma\u0026rdquo; effect is just a two variables noise function. Some used Perlin Noise, others the Diamond-square algorithm. A more interesting pattern can be obtained with trigonometrical functions, as explained here.\nThe interesting part here is the easyness of graphics programming in a Linux environment with a high level, yet performant and statically typed programming language.\nThe code is straightforward and a simple port of the original \u0026lsquo;C\u0026rsquo; source, I got surprised how the Crystal Language is easy to use and produces a quite fast native binary. If you want to check it out, you can find on my github account; in the meantime enjoy the mandatory video/screenshot :)\nstatic: video: There should have been a video here but your browser does not seem to support it. p.s. Thanks to Ian Rash who created the awesome bindings!\n","permalink":"https://ilmanzo.github.io/post/crystal-demo-effects/","summary":"Nostalgia time! Today I decided to play with Raylib and the Crystal Programming Language.\nTechnically speaking, the \u0026ldquo;plasma\u0026rdquo; effect is just a two variables noise function. Some used Perlin Noise, others the Diamond-square algorithm. A more interesting pattern can be obtained with trigonometrical functions, as explained here.\nThe interesting part here is the easyness of graphics programming in a Linux environment with a high level, yet performant and statically typed programming language.","title":"Old-School demo effects with Crystal"},{"content":"Once in a while I like to play with Advent Of Code problems \u0026#x1f384;. Today I decided to tackle an easy one and, since the answer was almost trivial to find, I wanted to go deeper and understand how to measure and improve the performance of the solution.\nSomething About Us In this first problem, they give you a long list of numbers; you need to find the two entries that sum to 2020 and then multiply those two numbers together.\nFor example, if numbers are the following:\n1721 979 366 299 675 1456 The two entries that sum to 2020 are 1721 and 299. Multiplying them together produces 1721 * 299 = 514579.\nOnce solved in a brute-force way, I thought to take the occasion to learn how you can benchmark code in Rust \u0026#x1f980;.\nGet Lucky First of all, I wrote a quick and dirty solution directly in the main.rs file:\npub fn part1_1(input: \u0026amp;[usize]) -\u0026gt; usize { for i in input { for j in input { if i+j==2020 { return i*j; } } } 0 } fn main() { let input=include_str!(\u0026#34;../../input.txt\u0026#34;) .lines() .map(|i| i.parse::\u0026lt;usize\u0026gt;().unwrap()) .collect(); println!(\u0026#34;{}\u0026#34;, part1_1(\u0026amp;input)); } Ugh\u0026hellip; Quadratic complexity! Well, cargo run gives us a correct answer, which won\u0026rsquo;t reveal here \u0026#x1f609; So we could call it a day and move to the next problem, or not ?\nTechnologic While it works as expected, that code isn\u0026rsquo;t easily measurable. So we\u0026rsquo;d need to take out our function in a separate crate and edit our Cargo.toml accordingly:\n[package] name = \u0026#34;day01_rust\u0026#34; version = \u0026#34;0.1.0\u0026#34; edition = \u0026#34;2021\u0026#34; [lib] name = \u0026#34;day01\u0026#34; path = \u0026#34;src/lib.rs\u0026#34; # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html [dependencies] [dev-dependencies] criterion = \u0026#34;0.4.0\u0026#34; [[bench]] name = \u0026#34;benchmark\u0026#34; harness = false With this setup, we can also factor out the code we want to measure in src/lib.rs:\npub fn part1_1(input: \u0026amp;[usize]) -\u0026gt; usize { for i in input { for j in input { if i+j==2020 { return i*j; } } } 0 } pub fn get_input() -\u0026gt; Vec\u0026lt;usize\u0026gt; { include_str!(\u0026#34;../../input.txt\u0026#34;) .lines() .map(|i| i.parse::\u0026lt;usize\u0026gt;().unwrap()) .collect() } While our src/main.rs will contain simply importing external functions and invocation:\nuse day01::{get_input, part1}; fn main() { let input=get_input(); println!(\u0026#34;{}\u0026#34;, part1_1(\u0026amp;input)); } Now we can use the very popular Criterion crate to write our benches/benchmark.rs\nuse criterion::{black_box, criterion_group, criterion_main, Criterion}; use day01::{part1_1, get_input}; pub fn criterion_benchmark(c: \u0026amp;mut Criterion) { let input=get_input(); c.bench_function(\u0026#34;part1\u0026#34;, |b| b.iter(|| part1_1(black_box(\u0026amp;input)))); } criterion_group!(benches, criterion_benchmark); criterion_main!(benches); The Game Has Changed With this setup, we are able to run cargo benchmark and get cool statistics and measurements of a significant number of executions of our code \u0026#x1f60e;.\nRunning benches/benchmark.rs (target/release/deps/benchmark-8bdc3718c6c81796) part1_1 time: [9.5933 ¬µs 9.5953 ¬µs 9.5974 ¬µs] Found 20 outliers among 100 measurements (20.00%) 5 (5.00%) low mild 8 (8.00%) high mild 7 (7.00%) high severe Not bad at all for our first try! Well, Rust is a fast, compiled language and our input is small, less than 200 lines. Can we do better ? Let\u0026rsquo;s measure a second implementation, will include here only the changed part:\nOne More Time pub fn part1_2(input: \u0026amp;[usize]) -\u0026gt; usize { for n in input { if input.contains(\u0026amp;(2020 - n)) { return n * (2020 - n); } } 0 } Turns out our \u0026lsquo;smart\u0026rsquo; implementation has slightly better performance, as Criterion is able to detect:\nRunning benches/benchmark.rs (target/release/deps/benchmark-8bdc3718c6c81796) part1_2 time: [8.9454 ¬µs 8.9482 ¬µs 8.9505 ¬µs] change: [-6.9929% -6.8888% -6.7959%] (p = 0.00 \u0026lt; 0.05) Performance has improved. Found 14 outliers among 100 measurements (14.00%) 3 (3.00%) low severe 1 (1.00%) low mild 3 (3.00%) high mild 7 (7.00%) high severe Harder, Better, Faster, Stronger With the help of a Set Data Structure we can write a better solution:\npub fn part1_3(input: \u0026amp;[usize]) -\u0026gt; usize { let mut seen = std::collections::HashSet::new(); for n in input { if seen.contains(\u0026amp;(2020-n)) { return n * (2020 - n); } seen.insert(n); } 0 } We simply keep track of the number already passed, and for each number we check if we already seen its complementary. When yes, we are done! How much we gain from this trick ?\npart1_3 time: [6.7853 ¬µs 6.7900 ¬µs 6.7947 ¬µs] change: [-0.2564% -0.1246% +0.0135%] (p = 0.08 \u0026gt; 0.05) Found 5 outliers among 100 measurements (5.00%) 3 (3.00%) low mild 1 (1.00%) high mild 1 (1.00%) high severe Doin‚Äô It Right Our new function is ~30% faster, and the most important thing is that it runs in O(n) time since it iterates over the original data only once. I don\u0026rsquo;t want to keep this post too long, also because the main purpose of this exercise isn\u0026rsquo;t abount finding the absolute fastest implementation, but rather to show how to set up a proper benchmark to measure your Rust code.\nAs a little spoiler, Part2 of the daily problem requires us to find 3 numbers which sum up to 2020. Can you think of a solution ? A fast one ? \u0026#x1f385;\nAround the World Benchmarking is not only about pure CPU performance, but we should consider also memory usage, I/O, caching, thermal efficiency, parallellism and lots of other topics. Some of them are handly collected in the Rust Performance Book, written by Nicholas Nethercote and others, which is a must read, together with the Criterion Documentation. Happy hacking!\n","permalink":"https://ilmanzo.github.io/post/advent_of_benchmark/","summary":"\u003cp\u003eOnce in a while I like to play with \u003ca href=\"https://adventofcode.com/\"\u003eAdvent Of Code\u003c/a\u003e problems \u0026#x1f384;. Today I decided to tackle an \u003ca href=\"https://adventofcode.com/2020/day/1\"\u003eeasy one\u003c/a\u003e and, since the answer  was almost trivial to find, I wanted to go deeper and understand how to measure and improve the performance of the solution.\u003c/p\u003e","title":"Benchmarking a Rust function"},{"content":"The Good \u0026#x1f607; Today I decided to submit an openSUSE package update for the nim compiler. It went almost all well but unfortunately I faced a problem: on the i586 platform it fails to build.\nIn this particolar situation, Open Build Service logs were not so useful. They only says that the vm running the build was terminated after 5400 seconds of inactivity, meaning that something got stuck and the system kindly waited a lot before terminating the process:\nThe Bad \u0026#x1f613; [ 6748s] qemu-kvm: terminating on signal 15 from pid 14593 (\u0026lt;unknown process\u0026gt;) [ 6748s] ### VM INTERACTION END ### [ 6748s] No buildstatus set, either the base system is broken (kernel/initrd/udev/glibc/bash/perl) [ 6748s] or the build host has a kernel or hardware problem... Job seems to be stuck here, killed. (after 5400 seconds of inactivity) So as a first move, I try to reproduce the problem on my local system:\n$ osc build openSUSE_Factory i586 (You may need to change the openSUSE_Factory parameter with one of the repositories you are building for, configured at project level)\nAfter some output, it hangs running the unit test suite; good news because means it\u0026rsquo;s a reproducible issue, but still we don\u0026rsquo;t know the reason.\nThe Ugly \u0026#x1f626; Build happens inside a qemu-kvm virtual machine, which is spawned and killed on demand; can we break inside this vm ? Well, we could leverage the QEMU Monitor to send commands via an Unix Socket, but there\u0026rsquo;s another solution: osc has a cool option to start a telnet server in the build system.\n$ osc build openSUSE_Factory i586 --vm-telnet 8023 now finalizing build dir... ... running 01-add_abuild_user_to_trusted_group ... running 02-set_timezone_to_utc ... running 03-set-permissions-secure ... running 11-hack_uname_version_to_kernel_version ERROR: neither /sbin/ifconfig nor /sbin/ip is installed, please specify correct package via -x option [ 6.402979][ T1] sysrq: Power Off [ 6.414858][ T165] reboot: Power down Close enough, seems we only need to add some missing packages to the build virtual machine.\n$ osc build openSUSE_Factory i586 --clean -x procps -x psmisc -x psutils -x iproute2 -x telnet-server --shell-after-fail --vm-telnet 8023 I added the luxury of running top in the virtual machine; I mean, why not ? \u0026#x1f63a; After running the build command, we are free to telnet localhost 8023 and get a root shell inside our building environment.\nWe are inside! \u0026#x1f601; Once here, it\u0026rsquo;s simple to make the build reach the hanging step, detect the problem from inside and solve with a simple fix in the .spec file. In this instance we need to exclude two GC test cases because they seems not running in a 32 bit networkless system, which is also worth to report upstream.\nPost Scriptum: Today it\u0026rsquo;s PI Day; Enjoy!\n","permalink":"https://ilmanzo.github.io/post/inspect-obs-vm-during-build/","summary":"\u003ch1 id=\"the-good--innocent\"\u003eThe Good  \u0026#x1f607;\u003c/h1\u003e\n\u003cp\u003eToday I decided to submit an openSUSE package update for the \u003ca href=\"https://nim-lang.org/\"\u003enim compiler\u003c/a\u003e.\nIt went almost all well but unfortunately I faced a problem: on the i586 platform it fails to build.\u003c/p\u003e","title":"Debugging a problematic build"},{"content":"On this February I decided to participate with a project to the SUSE Hackweek.\nHack Week is the time SUSE employees experiment, innovate \u0026amp; learn interruption-free for a whole week! Across teams or alone, but always without limits. A SUSE tradition since 2007, Hack Week has brought together hundreds of hackers around the globe to collaborate on open source. Learn more about Hack Week here\nMy project has four main purposes:\nplay with the Nim programming language advanced features like templates and macros experiment with container generation practice Test Driven Development/Design Have fun So I decided to write a simple library that lets you describe a container image with a DSL (Domain Specific Language) that reflects the standard, declarative style standard for Dockerfile and Containerfile. The benefits of this approach are multiple: you have the compiler checking for any errors and you can use a proper programming language to add any logic you need.\nNim is a statically typed compiled systems programming language. It compiles to small native binary but can also generate javascript, see these beautiful generative art examples.\nThe library usage is straightforward: you can basically mix Containerfile syntax with powerful Nim language contructs: variables, loops, arrays and anything else.\nimport containertools let my_app=\u0026#34;program.py\u0026#34; let image = container: FROM \u0026#34;opensuse/leap\u0026#34; WORKDIR \u0026#34;/opt\u0026#34; COPY my_app my_app CMD @[\u0026#34;python3\u0026#34;, my_app] image.save \u0026#34;Containerfile\u0026#34; image.build I implemented everything using TDD (Test Driven Development/Design) and this approach made me rethink a lot of design decisions and refactoring, which maybe are evident in the source code repository history, but I loved how the incremental process of adding tests drives you towards a clean design.\nThe library also can work in the opposite way: you can feed it with a Dockerfile and it will check for errors or suggest some possible optimizations, but this feature is only at the early stage. Further ideas can be to check the container for secret leaks or check at runtime for issues like wrong image names or dangerous commands. We could also generate different kind of declarative files formats, as yaml for kubernetes, CI/CD workflows, and so on.\nIf you are curious about the inner working or want to take part in the development, feel free to get in contact.\nI enjoyed HackWeek and this first Proof-of-concept implementation, looking forward to future improvements!\n","permalink":"https://ilmanzo.github.io/post/suse-hackweek-2023-recap/","summary":"\u003cp\u003eOn this February I decided to participate with a project to the \u003ca href=\"https://hackweek.opensuse.org/22/projects/containerfile-slash-dockerfile-generator-library\"\u003eSUSE Hackweek\u003c/a\u003e.\u003c/p\u003e","title":"a SUSE hackweek22 report"},{"content":"TLDR: This script now answers the question \u0026ldquo;Do some of my openSUSE packages have newer versions in other distros?\u0026rdquo;\nAs a following on previous post, I added an useful feature in order to have more information about a package. Since I maintain some openSUSE packages, I want to be informed if they gets outdated and if other packagers have released newer versions.\nYou can still find the project repository on my github, but we can comment some parts here.\nOther than collecting the package version from Open Build Service, we need to find out how the same packages in other distro are doing. We could scrape major distros public repositories but turns out there\u0026rsquo;s already an excellent service named repology that exposes some API that can easily be queried:\nREPOLOGY_APIURL = \u0026#39;https://repology.org/api/v1/project/\u0026#39; # return a package info when its version is different than the reference one def get_repology_version(package, refversion): try: response = requests.get(f\u0026#34;{REPOLOGY_APIURL}/{package}\u0026#34;) return [r for r in response.json() if r[\u0026#39;status\u0026#39;] == \u0026#39;newest\u0026#39; and r[\u0026#39;version\u0026#39;] != refversion] except: return None A companion shell script gets the info for all the packages I\u0026rsquo;m in charge of; I run it on every morning login so I won\u0026rsquo;t risk to forget something.\n#!/bin/sh for p in $(osc -A https://api.opensuse.org my packages | cut -d \u0026#39;/\u0026#39; -f 2) ; do ./last_update $p ; done which outputs:\n- rang last version on openSUSE:Factory is 3.2 changed on Dec 17 2022 Other 7 repos may have newer versions, consider updating! - pgn-extract last version on openSUSE:Factory is 22.11 changed on Dec 23 2022 - flacon last version on openSUSE:Factory is 9.5.1 changed on Dec 26 2022 - goodvibes last version on openSUSE:Factory is 0.7.5 changed on Oct 16 2022 - openconnect last version on openSUSE:Factory is 9.01 changed on Dec 15 2022 - oidentd last version on openSUSE:Factory is 3.0.0 changed on Oct 21 2022 - pgbackrest last version on openSUSE:Factory is 2.43 changed on Dec 07 2022 There are of course tons of possible improvements. For example use directly osc-tiny by Andreas Hasenkopf and improve the OBS version detection. At this stage for example it does not yet support rpm macros. Pull requests are welcome!\nHave fun ;)\n","permalink":"https://ilmanzo.github.io/post/compare_package_versions_across_distros/","summary":"\u003cp\u003eTLDR: This script now answers the question \u0026ldquo;Do some of my openSUSE packages have newer versions in other distros?\u0026rdquo;\u003c/p\u003e\n\u003cp\u003eAs a following on \u003ca href=\"https://ilmanzo.github.io/post/check-last-update-on-packages/\"\u003eprevious post\u003c/a\u003e, I added an useful feature in order to have more information about a package.\nSince I maintain some openSUSE packages, I want to be informed if they gets outdated and if other packagers have released newer versions.\u003c/p\u003e","title":"compare package version across distros"},{"content":"being lazy, I made a small utility to check last pkgs update date on Open Build Service.\nYou can find the project repository on my github, but it\u0026rsquo;s so simple I can paste also here.\nThe usage is pretty simple: just run the command giving it a package name, and then it will tell you when it was last updated. With this information, you can decide/check if the package needs some work on!\n#!/usr/bin/python3 import subprocess import argparse APIURL = \u0026#34;https://api.opensuse.org\u0026#34; MAINPROJECT = \u0026#34;openSUSE:Factory\u0026#34; ### OSC_CMD = [\u0026#39;osc\u0026#39;, \u0026#39;--apiurl\u0026#39;, APIURL] def exec_process(cmdline): return subprocess.Popen(cmdline, stdout=subprocess.PIPE, stderr=subprocess.PIPE, encoding=\u0026#39;utf8\u0026#39;) def get_last_changes(package): try: proc = exec_process( OSC_CMD+[\u0026#34;ls\u0026#34;, \u0026#34;-l\u0026#34;, f\u0026#34;{MAINPROJECT}/{package}\u0026#34;]) for line in proc.stdout.readlines(): if f\u0026#34;{package}.changes\u0026#34; not in line: continue return line.split()[3:6] except: return None def main(): parser = argparse.ArgumentParser( prog=\u0026#39;last update\u0026#39;, description=\u0026#39;tells you when a package was last updated\u0026#39;, ) parser.add_argument( \u0026#39;package\u0026#39;, help=\u0026#39;the package name to check (ex bash, vim ...)\u0026#39;) args = parser.parse_args() changes = get_last_changes(args.package) if changes: print(args.package, \u0026#34;was last updated on\u0026#34;, MAINPROJECT, \u0026#39; \u0026#39;.join(get_last_changes(args.package))) else: print(\u0026#34;Error in getting information. Does this package exist?\u0026#34;) main() Have fun!\n","permalink":"https://ilmanzo.github.io/post/check-last-update-on-packages/","summary":"\u003cp\u003ebeing lazy, I made a small utility to check last pkgs update date on \u003ca href=\"https://build.opensuse.org/\"\u003eOpen Build Service\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eYou can find the project repository \u003ca href=\"https://github.com/ilmanzo/package_last_update\"\u003eon my github\u003c/a\u003e, but it\u0026rsquo;s so simple I can paste also here.\u003c/p\u003e\n\u003cp\u003eThe \u003ca href=\"https://github.com/ilmanzo/package_last_update/blob/master/README.md\"\u003eusage\u003c/a\u003e is pretty simple: just run the command giving it a package name, and then it will tell you when it was last updated. With this information, you can decide/check if the package needs some work on!\u003c/p\u003e","title":"get update info about packages"},{"content":"I got bored of \u0026lsquo;waiting\u0026rsquo; for an OpenQA openSUSE job to complete, so I wrote this quick and dirty script\u0026hellip;\nFor the same purpose there\u0026rsquo;s also the excellent and full-fledged openqa-mon, but I took the chance to learn something by implementing a simpler version myself.\n#!/bin/sh JOB=$1 if [ -z \u0026#34;$JOB\u0026#34; ]; then echo \u0026#34;please provide job number as parameter\u0026#34; exit fi MESSAGE=\u0026#39;Your job is ready!\u0026#39; JOBURL=https://openqa.opensuse.org/tests/$JOB while : do STATE=$(openqa-cli api -o3 jobs/$JOB | jq .job.state) if [ $STATE != \\\u0026#34;scheduled\\\u0026#34; ]; then notify-send $MESSAGE $JOBURL echo $MESSAGE $JOBURL exit fi sleep 5 done To use it, simply run the script with the job number as first and only parameter, and you\u0026rsquo;ll get both a console and desktop notification when the status changes, so you can easily start to follow it with the browser, debug, download assets and so on.\nAs requirement, you\u0026rsquo;ll need to have some packages installed:\nopenqa-cli installed and configured (package: openQA-client in openSUSE) packages: jq, notify-send (packages: jq and libnotify-tools in openSUSE) Have fun!\n","permalink":"https://ilmanzo.github.io/post/openqa-jobs-notifier/","summary":"\u003cp\u003eI got bored of \u003cem\u003e\u0026lsquo;waiting\u0026rsquo;\u003c/em\u003e for an \u003ca href=\"http://open.qa/\"\u003eOpenQA\u003c/a\u003e \u003ca href=\"https://openqa.opensuse.org/\"\u003eopenSUSE\u003c/a\u003e job to complete, so I wrote this quick and dirty script\u0026hellip;\u003c/p\u003e\n\u003cp\u003eFor the same purpose there\u0026rsquo;s also the excellent and full-fledged \u003ca href=\"https://openqa-bites.github.io/posts/2021-02-25-openqa-mon/\"\u003eopenqa-mon\u003c/a\u003e, but I took the chance to learn something by implementing a simpler version myself.\u003c/p\u003e","title":"get notifications about openQA job status"},{"content":"Inspired by a tweet from a fellow developer, I decided to take a look at Karax, a nifty framework for developing single page applications in Nim.\nAfter following the basic tutorials and examples, I searched for something more complex and found very sparse documentation, so I\u0026rsquo;ll write my findings here.\nAs usual, the complete source code is on my github repo, where you can find also a working live demo.\nIn this example I wanted to experiment with the component pattern, and create a stateful module that can be reused. So I modeled a nim clock object, here the source:\n# source for the Clock component import karax/[karax, karaxdsl, vdom] import std/times import std/dom import sugar type KClock* = ref object of VComponent currentTime: DateTime offset: TimeInterval timer: TimeOut prefix: string # return a VNode with the html rendered for the component proc render(c: VComponent): VNode = let self = KClock(c) buildHtml(tdiv): let value = format(self.currentTime+self.offset, \u0026#34;HH:mm:ss\u0026#34;) p: text \u0026#34;Local Time \u0026#34; \u0026amp; self.prefix \u0026amp; \u0026#34; =\u0026gt; \u0026#34; \u0026amp; value # update the clock value and re-triggers a timer proc update(self: KClock) = self.currentTime = now() self.timer = setTimeout( () =\u0026gt; self.update, 100) markDirty(self) # need to be re-rendered redraw() # create, initialize and return a new Clock object proc new*(T: type KClock, tzoffset = 0): KClock = let self = newComponent(KClock, render) self.currentTime = now() self.offset = initTimeInterval(hours = tzoffset) self.timer = setTimeout(() =\u0026gt; self.update, 100) self.prefix = if tzoffset \u0026gt;= 0: \u0026#34;+\u0026#34; else: \u0026#34;\u0026#34; self.prefix.add $tzoffset return self this lives in a separate file and can be imported from the main page.\nSome attention point goes in the constructor, that requires special newComponent call, and the update() function that contains a Timeout callback in order to re-render itself after some time.\nlet\u0026rsquo;s use the component in the main page, and sprinkle some interactivity just for fun:\nimport karax / [kbase, vdom, kdom, karax, karaxdsl, jstrutils] import kclock var clocks: seq[KClock] # keep a list of clocks offset: kstring # value entered in the input box proc render(): VNode = buildHtml(tdiv): h2: label(`for` = \u0026#34;offset\u0026#34;): text \u0026#34;Please enter Timezone offset (-12 .. +12)\u0026#34; input(type = \u0026#34;number\u0026#34;, id = \u0026#34;offset\u0026#34;): proc oninput(ev: Event; n: VNode) = offset = n.value button: text \u0026#34;Add a new Clock\u0026#34; proc onclick(ev: Event; n: VNode) = let tzofs = parseInt(offset) if tzofs \u0026gt;= -12 and tzofs \u0026lt;= 12: clocks.add(KClock.new(tzofs)) button: text \u0026#34;Remove last Clock\u0026#34; proc onclick(ev: Event; n: VNode) = discard clocks.pop() for clock in clocks: h1: clock setRenderer render for Nim lovers, Karax looks promising, and programming web pages without writing a single Javascript line sounds very interesting; but currently it needs some polish, more documentation and a larger user base. So try and contribute to the development community!\n","permalink":"https://ilmanzo.github.io/post/nim-frontend-web-development-with-karax/","summary":"Inspired by a tweet from a fellow developer, I decided to take a look at Karax, a nifty framework for developing single page applications in Nim.\nAfter following the basic tutorials and examples, I searched for something more complex and found very sparse documentation, so I\u0026rsquo;ll write my findings here.\nAs usual, the complete source code is on my github repo, where you can find also a working live demo.","title":"web components with Nim and Karax"},{"content":"Background: I work with one or more terminal command-line always opened and having to pick up my phone to generate an OTP breaks my flow; also it\u0026rsquo;s always nice to have an alternate source of multi-factor authentication if something bad happens, one day you could lose or break your trusty mobile device.\nTherefore I was looking for a way to login through Okta portals without a phone. You may argument that this defeats the whole meaning of MFA, but let\u0026rsquo;s say it\u0026rsquo;s only an hack for research and fun purpose \u0026hellip;\nDISCLAIMER: This setup should be used only on ANOTHER trusted device, so use it at your own risk, and be sure to always properly protect your credentials: security is a very serious topic.\nTLDR: With this setup, every time you write :okta in any text entry field, it will be replaced with a properly generated OTP!\nRequirements: Install pass-otp.\nfor openSUSE Tumbleweed users like me, it\u0026rsquo;s just a matter of\n# zypper install pass-otp Steps: If you already have multifactor authentication set up, start with step 1.\nOtherwise, login up to the point where it asks you to \u0026ldquo;Set up (two-|multi)factor authentication\u0026rdquo;, and go to step 4.\nLogin to your organisation\u0026rsquo;s Okta settings. The url is typically of the form https://OKTA_HOME_PAGE/enduser/settings. For example,\nThe University of Sydney: https://sso.sydney.edu.au/enduser/settings Garvan: https://garvan.okta.com/enduser/settings Linkedin: https://linkedin.okta.com/enduser/settings Docusign: https://docusign.okta.com/enduser/settings Groupon: https://groupon.okta.com//enduser/settings Scroll to \u0026ldquo;Extra Verification\u0026rdquo;. This is typically at the bottom on the right.\nIf you already have Okta Verify or Google Authenticator set up with your organisation, remove it.\nNow you need to retrieve the secret one-time password (OTP) key.\nClick \u0026ldquo;Set up\u0026rdquo; next to \u0026ldquo;Okta Verify\u0026rdquo;.\nIf a button appears, click it. It may say \u0026ldquo;Configure factor\u0026rdquo; or \u0026ldquo;Set up\u0026rdquo;.\nClick \u0026ldquo;iPhone\u0026rdquo; or \u0026ldquo;Android\u0026rdquo;. It doesn\u0026rsquo;t matter which one you pick, you won\u0026rsquo;t be needing a phone.\nClick \u0026ldquo;Next\u0026rdquo;.\nClick \u0026ldquo;Can\u0026rsquo;t scan?\u0026rdquo;.\nClick the first dropdown menu and select \u0026ldquo;Setup manually without push notification\u0026rdquo;.\nCopy the secret key to your clipboard.\nCreate the OTP generator by running the following command, replacing OTP_NAME with a name of your choosing. Paste the secret key when prompted.\n$ pass otp insert -esi byebyeokta OTP_NAME Generate the OTP by running the following command. $ pass otp OTP_NAME Copy the output. Alternatively, use the -c option to copy it directly.\n$ pass otp -c OTP_NAME Enter the OTP.\nClick \u0026ldquo;Next\u0026rdquo;.\nPaste the number in the \u0026ldquo;Enter Code\u0026rdquo; text box.\nClick \u0026ldquo;Verify\u0026rdquo; to finish the setup.\nYou may have to click \u0026ldquo;Finish\u0026rdquo; as well.\nNow, whenever you are required to enter the OTP code in the future, simply generate it by following step 6.\nAuthenticator App Add the secret key to a OTP authenticator app. This is useful if you need to use a different computer and don\u0026rsquo;t have access to one which you set up pass-otp with.\nFind a way to add a new account by entering the secret key manually into the app. For the Okta Verify app, do the following. The steps are similar for the Google Authenticator app.\nPress the \u0026ldquo;+\u0026rdquo; button in the top-right corner.\nPress \u0026ldquo;Other\u0026rdquo;.\nPress \u0026ldquo;Enter Key Manually\u0026rdquo;.\nType an Account Name of your choosing.\nType in the secret key. If you have lost the key, run the following command to retrieve it.\n$ pass OTP_NAME | awk -F \u0026#39;[=\u0026amp;]\u0026#39; \u0026#39;{print $2}\u0026#39; Press \u0026ldquo;Done\u0026rdquo;. Confirm you get the same codes on your phone as when following step 6. If not, you may have misspelled the secret key, in which case try again.\nIf you have an old account on a OTP authenticator app which you removed in step 3 you can remove it from the app.\nAutomating The goal is to auto fill and submit once prompted to enter the OTP code.\nThe original author used qutebrowser, binding a key chain to a submit_otp_qute.sh userscript; so you can follow that\nFor other purposes, and many reasons, personally I\u0026rsquo;m already using a tool like Espanso, but also AutoKey and any other \u0026ldquo;text-expander\u0026rdquo; that is able run external commands can meet the requirements.\nYou can use an Espanso configuration snippet like this:\n- trigger: \u0026#34;:okta\u0026#34; replace: \u0026#34;{{output}}\u0026#34; vars: - name: output type: shell params: cmd: /usr/local/bin/submit_otp.sh OTP_NAME be sure to replace OTP_NAME with the one you chose before.\nThe script executed is quite easy, simply retrieve the code and echoes to stdout:\n#!/bin/sh # user script that enters the otp code # designed to be used when prompted with the Okta Verify \u0026#34;Enter Code\u0026#34; form if [ \u0026#34;$#\u0026#34; -ne 1 ]; then echo \u0026#34;usage: $0 OTP_NAME\u0026#34; exit 1 fi OTP_NAME=\u0026#34;$1\u0026#34; # retrieve the otp otp=$(pass otp \u0026#34;$OTP_NAME\u0026#34;) if [ -z \u0026#34;$otp\u0026#34; ]; then echo \u0026#34;Unknown OTP_NAME \u0026#39;$OTP_NAME\u0026#39;\u0026#34; exit 1 fi # insert the otp at the focussed text box and submit it echo \u0026#34;$otp\u0026#34; have fun,\nCredits Kudos to Sasha for most of detailed instructions\n","permalink":"https://ilmanzo.github.io/post/otp-generation-from-command-line/","summary":"Background: I work with one or more terminal command-line always opened and having to pick up my phone to generate an OTP breaks my flow; also it\u0026rsquo;s always nice to have an alternate source of multi-factor authentication if something bad happens, one day you could lose or break your trusty mobile device.\nTherefore I was looking for a way to login through Okta portals without a phone. You may argument that this defeats the whole meaning of MFA, but let\u0026rsquo;s say it\u0026rsquo;s only an hack for research and fun purpose \u0026hellip;","title":"automate OTP credentials for multi-factor authentication"},{"content":"intro Resource isolation is an hot topic these days, and it\u0026rsquo;s a problem excellently solved by containerization. However, we can achieve isolation between internal tasks of an operating system by leveraging a technology exposed by the kernel: cgroups. This component is also used by Docker, and other Linux container technologies.\nCgroups are the Linux way of organizing groups of processes: roughly speaking a cgroup is to a process what a process is to a thread: one can have many threads belonging to the same process, and in the same way one can join many processes inside the same cgroup.\nthe problem Suppose we have an already busy server, maybe a database; and we want to run on the same machine a periodical job which is short but quite intensive. Of course we don\u0026rsquo;t want an huge impact on the service performance. Let\u0026rsquo;s say our cpu-bound process is represented by this script:\n#!/bin/bash #dosomework.sh { sleep 30 kill $$ } \u0026amp; while true; do true; done we can define a slice to control the resource sharing of our services and model the relative weight that the system should assign:\n#mydatabase-extrajob.slice [Unit] Description=Slice used to run companion programs. Memory, CPU and IO restricted Before=slices.target [Slice] MemoryAccounting=true IOAccounting=true CPUAccounting=true CPUWeight=10 IOWeight=10 MemoryHigh=4% MemoryLimit=5% CPUShares=10 BlockIOWeight=10 while the db service will have another resource definition:\n#mydatabase-server.slice [Unit] Description=Slice used to run DB. Maximum priority for IO and CPU Before=slices.target [Slice] MemoryAccounting=true IOAccounting=true CPUAccounting=true MemorySwapMax=1 CPUShares=1000 CPUWeight=1000 and we need to apply this slice to the .service\n[Service] ... Slice=mydatabase-server.slice By saying that the DB service has weight=1000 and the other program has weight=10, we tell the operating system that DB is 100 times more important when any CPU contention occurs.\nad hoc commands Systemd slices are a powerful way to protect services that are managed by systemd from each other. But what if I just want to run some command, and am too worried that it may use up precious resources from the main service?\nThankfully, systemd provides a way to run ad-hoc commands inside an existing slice. So the cautious admin can use that too:\nsudo systemd-run --uid=$(id -u dbuser) --gid=$(id -g dbgroup) -t --slice=mydatabase-extrajob.slice /path/to/my/tool Conclusion Systemd slices exposes the cgroups interface ‚Äî which underpins the isolation infrastructure used by Docker and other Linux container technologies ‚Äî in an elegant and powerful way. Services managed by Systemd, like databases, can use this infrastructure to isolate their main components from other auxiliary helper tools that may use too much resources. For other reference, SystemD documentation is quite extensive.\ncredits Glauber Costa\u0026rsquo;s Isolating workloads with Systemd slices\n","permalink":"https://ilmanzo.github.io/post/linux-resource-control-with-cgroups/","summary":"intro Resource isolation is an hot topic these days, and it\u0026rsquo;s a problem excellently solved by containerization. However, we can achieve isolation between internal tasks of an operating system by leveraging a technology exposed by the kernel: cgroups. This component is also used by Docker, and other Linux container technologies.\nCgroups are the Linux way of organizing groups of processes: roughly speaking a cgroup is to a process what a process is to a thread: one can have many threads belonging to the same process, and in the same way one can join many processes inside the same cgroup.","title":"linux resource control with cgroups"},{"content":"In this post we are going to write a new module for python: a very simple function exported from Rust that we can consume in the Python interpreter. We\u0026rsquo;ll leverage the PyO3 Rust bindings for the Python interpreter.\nLet\u0026rsquo;s start with a new Cargo project:\n$ cargo init --lib demo_rust_lib and insert the required settings in Cargo.toml:\n[package] name = \u0026#34;rusty\u0026#34; version = \u0026#34;0.1.0\u0026#34; edition = \u0026#34;2021\u0026#34; [lib] name=\u0026#34;rusty\u0026#34; crate-type = [\u0026#34;cdylib\u0026#34;] [dependencies.pyo3] version = \u0026#34;*\u0026#34; [features] extension-module = [\u0026#34;pyo3/extension-module\u0026#34;] default = [\u0026#34;extension-module\u0026#34;] now it\u0026rsquo;s a matter to write our library; luckily the PyO3 library exposes a lot of useful types for python interop; the only thing we need to add is an extra fn named as our module that \u0026ldquo;exports\u0026rdquo; the functions we want to make available in the Python layer:\n// this file is: src/lib.rs use pyo3::prelude::*; #[allow(dead_code)] #[pymodule] fn librusty(_py: Python, m: \u0026amp;PyModule) -\u0026gt; PyResult\u0026lt;()\u0026gt; { m.add_wrapped(wrap_pyfunction!(list_prod))?; Ok(()) } /// calc the product of N numbers in a list. #[pyfunction] fn list_prod(a: Vec\u0026lt;isize\u0026gt;) -\u0026gt; PyResult\u0026lt;isize\u0026gt; { let mut prod: isize = 1; for i in a { prod *= i; } Ok(prod) } #[cfg(test)] mod tests { use super::*; #[test] fn test_list_product() { let input=vec![1,2,3,4]; let result=list_prod(input).unwrap_or(0); assert_eq!(result, 24); } } now compile the library with cargo build and also unit test are working, so you can run them with cargo test --no-default-features\nnow we need a trivial python program to test our library:\nimport sys,os # for development we include the rust build path to the path # that python looks for modules for p in (\u0026#34;release\u0026#34;,\u0026#34;debug\u0026#34;): sys.path.append(os.path.join(\u0026#34;target\u0026#34;,p)) # now this import can be resolved from librusty import list_prod result=list_prod([10,3,6]) print(result) The initial part requires a bit of setup because Python must be aware of Rust\u0026rsquo;s target folder to load the external module. For development is fine, but in the future we can skip this and publish the module as a real python package, installable from pip using the maturin tool from PyO3.\nRunning the sample program, we get the expected result:\n$ python3 use_rust_lib.py 180 we are starting to make interesting interactions between Python and Rust. The main purpose of this kind of project can be performance improvements, so next time we will do some benchmarks on the same function implemented in both and see the results.\nAll of the source code for this post is available on github\n","permalink":"https://ilmanzo.github.io/post/writing-python-modules-in-rust-2/","summary":"In this post we are going to write a new module for python: a very simple function exported from Rust that we can consume in the Python interpreter. We\u0026rsquo;ll leverage the PyO3 Rust bindings for the Python interpreter.\nLet\u0026rsquo;s start with a new Cargo project:\n$ cargo init --lib demo_rust_lib and insert the required settings in Cargo.toml:\n[package] name = \u0026#34;rusty\u0026#34; version = \u0026#34;0.1.0\u0026#34; edition = \u0026#34;2021\u0026#34; [lib] name=\u0026#34;rusty\u0026#34; crate-type = [\u0026#34;cdylib\u0026#34;] [dependencies.","title":"integration between Python and Rust - Part 2"},{"content":"Let\u0026rsquo;s get our feet wet; in this first part I\u0026rsquo;ll write about a very simple way to interface Rust and Python. First of all let\u0026rsquo;s build a Rust dynamic library with some basic functions.\n// this file is: src/lib.rs #[no_mangle] pub extern \u0026#34;C\u0026#34; fn hello() { println!(\u0026#34;Hello from the library!\u0026#34;); } #[no_mangle] pub extern \u0026#34;C\u0026#34; fn sum(a: i32, b: i32) -\u0026gt; i32 { a + b } your Cargo.toml should look like this:\n[package] name = \u0026#34;pyrust\u0026#34; version = \u0026#34;0.1.0\u0026#34; edition = \u0026#34;2018\u0026#34; [dependencies] [lib] crate-type = [\u0026#34;cdylib\u0026#34;] compile the library with cargo build\nnow we need a trivial python program to test our library:\nimport ctypes lib=ctypes.PyDLL(\u0026#34;target/debug/libpyrust.so\u0026#34;) lib.hello() c=lib.sum(3,4) print(c) running it, we get the expected result:\n$ python3 test_lib.py Hello from the library! 7 since we exported our functions from Rust as plain C, and we don\u0026rsquo;t make any fancy allocation or manipulation of Python objects, it\u0026rsquo;s pretty standard to use the library as it was written in C. In the next post we\u0026rsquo;ll explore more advanced options\u0026hellip;\n","permalink":"https://ilmanzo.github.io/post/writing-python-modules-in-rust-1/","summary":"Let\u0026rsquo;s get our feet wet; in this first part I\u0026rsquo;ll write about a very simple way to interface Rust and Python. First of all let\u0026rsquo;s build a Rust dynamic library with some basic functions.\n// this file is: src/lib.rs #[no_mangle] pub extern \u0026#34;C\u0026#34; fn hello() { println!(\u0026#34;Hello from the library!\u0026#34;); } #[no_mangle] pub extern \u0026#34;C\u0026#34; fn sum(a: i32, b: i32) -\u0026gt; i32 { a + b } your Cargo.toml should look like this:","title":"integration between Python and Rust - Part 1"},{"content":"In the last post we introduced the BCC framework to interface Python code with eBPF facility. Now we are ready to make one step further!\n#!/usr/bin/python3 import bcc bpf = bcc.BPF(text=\u0026#34;\u0026#34;\u0026#34; #include \u0026lt;uapi/linux/ptrace.h\u0026gt; int trace_malloc(struct pt_regs *ctx, size_t size) { bpf_trace_printk(\u0026#34;size=%d\\\\n\u0026#34;,size); return 0; };\u0026#34;\u0026#34;\u0026#34;) bpf.attach_uprobe(name=\u0026#34;c\u0026#34;,sym=\u0026#34;malloc\u0026#34;,fn_name=\u0026#34;trace_malloc\u0026#34;) while 1: (task, pid, cpu, flags, ts, msg) = bpf.trace_fields() print(f\u0026#34;task={task}\\tmsg={msg}\u0026#34;) This code is a little more complex, but still quite easy: first of all we use bcc to attach an \u0026ldquo;user space probe\u0026rdquo; instead of a kernel probe, and the function being observed will be libc\u0026rsquo;s malloc.\nIn the tracing code itself, we simply report the parameter given to malloc function to the outside world, so with an infinite loop we print the tracing messages. Just to make it more explicit, we extract all the fields one by one and print only two of them.\nIt works like this: eBPF probe writes to a shared pipe named /sys/kernel/debug/tracing/trace_pipe , and python code reads from that pipe. The result is a fast scrolling stream of all the malloc invocations from all running programs, followed by the size requested.\n| Field | Field | |Number | Name | Meaning | ---- | ----- | ------- | 0 | task | The name of the application running when the probe fired | | 1 | pid | process id (PID) of the application | | 2 | cpu | The CPU it was running on | | 3 | flags | Various process context flags | | 4 | ts | A timestamp | | 5 | msg | The string that we passed to bpf_trace_printk() | task=b'Xorg'\tmsg=b'size=24' task=b'Xorg'\tmsg=b'size=24' task=b'gnome-terminal-'\tmsg=b'size=36' task=b'gnome-terminal-'\tmsg=b'size=16' task=b'Xorg'\tmsg=b'size=24' task=b'gnome-terminal-'\tmsg=b'size=24' task=b'gnome-terminal-'\tmsg=b'size=124' task=b'Xorg'\tmsg=b'size=24' task=b'gnome-terminal-'\tmsg=b'size=16' task=b'gnome-terminal-'\tmsg=b'size=312' task=b'Xorg'\tmsg=b'size=24' task=b'gnome-terminal-'\tmsg=b'size=72' ","permalink":"https://ilmanzo.github.io/post/tracing-with-ebpf-02/","summary":"In the last post we introduced the BCC framework to interface Python code with eBPF facility. Now we are ready to make one step further!\n#!/usr/bin/python3 import bcc bpf = bcc.BPF(text=\u0026#34;\u0026#34;\u0026#34; #include \u0026lt;uapi/linux/ptrace.h\u0026gt; int trace_malloc(struct pt_regs *ctx, size_t size) { bpf_trace_printk(\u0026#34;size=%d\\\\n\u0026#34;,size); return 0; };\u0026#34;\u0026#34;\u0026#34;) bpf.attach_uprobe(name=\u0026#34;c\u0026#34;,sym=\u0026#34;malloc\u0026#34;,fn_name=\u0026#34;trace_malloc\u0026#34;) while 1: (task, pid, cpu, flags, ts, msg) = bpf.trace_fields() print(f\u0026#34;task={task}\\tmsg={msg}\u0026#34;) This code is a little more complex, but still quite easy: first of all we use bcc to attach an \u0026ldquo;user space probe\u0026rdquo; instead of a kernel probe, and the function being observed will be libc\u0026rsquo;s malloc.","title":"playing with eBPF interface - 2"},{"content":"eBPF is a revolutionary technology that can run sandboxed programs in the Linux kernel without changing kernel source code or loading kernel modules. Basically any user can write code for a virtual machine that can interact with the kernel data structure and functions.\nbcc is an high-level helper interface to eBPF (another is bpftrace). To use it, start by following installation guide , but if you have a recent Debian system, it\u0026rsquo;s just a matter of installing some packages:\nsudo apt install bpfcc-tools python3-bpfcc libbpfcc libbpfcc-dev Now let\u0026rsquo;s test our installation with the classical \u0026lsquo;Hello, world\u0026rsquo;\n#!/usr/bin/python3 # run with: # sudo ./hello_world.py import bcc my_probe_src = r\u0026#34;\u0026#34;\u0026#34; int hello(void *ctx) { bpf_trace_printk(\u0026#34;Hello world!\\n\u0026#34;); return 0; } \u0026#34;\u0026#34;\u0026#34; bpf = bcc.BPF(text=my_probe_src) bpf.attach_kprobe(event=bpf.get_syscall_fnname(\u0026#34;clone\u0026#34;), fn_name=\u0026#34;hello\u0026#34;) bpf.trace_print() What does this program do ? It uses the BCC framework to attach a simple \u0026ldquo;probe\u0026rdquo; to the linux kernel sys_clone() function, so each time the function is called, our hook gets executed. So when you run this simple program, you\u0026rsquo;ll see on your terminal the message every time the syscall clone() function gets called.\nb' \u0026lt;...\u0026gt;-82733 [002] d... 11828.394029: bpf_trace_printk: Hello world!' b'' b' \u0026lt;...\u0026gt;-82225 [004] d... 11828.394071: bpf_trace_printk: Hello world!' b'' b' DedicatedWorker-6802 [005] d... 11842.465428: bpf_trace_printk: Hello world!' b'' b' \u0026lt;...\u0026gt;-82723 [004] d... 11842.465491: bpf_trace_printk: Hello world!' b'' b' \u0026lt;...\u0026gt;-82956 [000] d... 11842.466093: bpf_trace_printk: Hello world!' b'' b' ThreadPoolForeg-6590 [001] d... 11842.815580: bpf_trace_printk: Hello world!' There is a lot to know about eBPF; What\u0026rsquo;s the meaning of all the data displayed ? How to decode arguments ? How to obtain data values from probe ? What can we do in our function ? We have of course barely scratched the surface; we\u0026rsquo;ll see in the next post!\n","permalink":"https://ilmanzo.github.io/post/playing-with-ebpf-01/","summary":"eBPF is a revolutionary technology that can run sandboxed programs in the Linux kernel without changing kernel source code or loading kernel modules. Basically any user can write code for a virtual machine that can interact with the kernel data structure and functions.\nbcc is an high-level helper interface to eBPF (another is bpftrace). To use it, start by following installation guide , but if you have a recent Debian system, it\u0026rsquo;s just a matter of installing some packages:","title":"playing with eBPF interface - 1"},{"content":"When I write small command line utilities in Python, I often take advantage of the fileinput module that makes working with text files very convenient: the library permits to write quickly and easily a loop over standard input or a list of files, something like perl -a or awk line processing.\nThen the size of input data grew, and also for a language comparison, I wanted to port my utility in the D programming language, but I cannot find an equivalent module, so I decided to write one myself.\nThe usage is pretty similar to Python:\nimport fileinput; import std.stdio; void main(in string[] args) { foreach (line; fileinput.input(args)) { writeln(line); // do something with line } return; } Once compiled, this will lead to an executable that can accept any number of text file as input, or read from stdin and seamlessly iterate on all of the lines contained in every file.\nThanks to the range interface; every struct / class implementing these methods can be used in a foreach statement.\ninterface InputRange(E) { bool empty(); E front(); void popFront(); } You can find the full implementation on github\n","permalink":"https://ilmanzo.github.io/post/fileinput-for-d-programming-language/","summary":"When I write small command line utilities in Python, I often take advantage of the fileinput module that makes working with text files very convenient: the library permits to write quickly and easily a loop over standard input or a list of files, something like perl -a or awk line processing.\nThen the size of input data grew, and also for a language comparison, I wanted to port my utility in the D programming language, but I cannot find an equivalent module, so I decided to write one myself.","title":"a 'pythonic' fileinput module for the D programming language"},{"content":"Nim is a statically typed compiled systems programming language. It combines successful concepts from mature languages like Python, Ada and Modula. It\u0026rsquo;s Efficient, expressive, elegant and definitely worth to check.\nWhile I was playing with it, I stumbled upon an interesting module that allows almost seamless interoperability betweeen Nim and Python; so I\u0026rsquo;m building a small proof of concept on this github project.\nfirst of all the Nim code: # file: demo.nim - file name should match the module name you\u0026#39;re going to import from python import nimpy import unicode proc greet(name: string): string {.exportpy.} = return \u0026#34;Hello, \u0026#34; \u0026amp; name \u0026amp; \u0026#34;!\u0026#34; proc count(names: seq[string]): int {.exportpy.} = return names.len proc lowercase(names: seq[string]): seq[string] {.exportpy.} = for n in names: result.add tolower(n)\nIn the github project there is a complete build file, but to make it short, you can compile the module with a single command:\n#for windows: nim c --threads:on --app:lib --out: demo.pyd demo #for linux: nim c --threads:on --app:lib --out: demo.so demo now we can import the module from python and use its functions:\n# file: usage.py import demo # assert demo.greet(\u0026#34;world\u0026#34;) == \u0026#34;Hello, world!\u0026#34; assert demo.greet(name=\u0026#34;world\u0026#34;) == \u0026#34;Hello, world!\u0026#34; # fruits=[\u0026#34;banana\u0026#34;,\u0026#34;apple\u0026#34;,\u0026#34;orange\u0026#34;] assert demo.count(fruits) == 3 # upletters=[\u0026#34;AA\u0026#34;,\u0026#34;BB\u0026#34;,\u0026#34;CC\u0026#34;] letters=demo.lowercase(upletters) assert \u0026#34;\u0026#34;.join(letters) ==\u0026#34;aabbcc\u0026#34; # print(\u0026#34;all test sucessful\u0026#34;) ","permalink":"https://ilmanzo.github.io/post/writing-python-modules-in-nim/","summary":"Nim is a statically typed compiled systems programming language. It combines successful concepts from mature languages like Python, Ada and Modula. It\u0026rsquo;s Efficient, expressive, elegant and definitely worth to check.\nWhile I was playing with it, I stumbled upon an interesting module that allows almost seamless interoperability betweeen Nim and Python; so I\u0026rsquo;m building a small proof of concept on this github project.\nfirst of all the Nim code: # file: demo.","title":"Writing Python modules in Nim"},{"content":"I\u0026rsquo;ve started a new side project named Crystal Koans, it\u0026rsquo;s a simple series of exercises organized as a big unit test suite.\nThe \u0026ldquo;koans\u0026rdquo; are heavily inspired by similar projects for other languages, but I didn\u0026rsquo;t found anything similar for Crystal. The project has been included in the awesome collection under the official Learning Resource for the language.\nI\u0026rsquo;ll try to maintain and evolve it in the spare time, I hope you\u0026rsquo;ll find it useful, and any form of contribution is welcome.\n","permalink":"https://ilmanzo.github.io/post/a-new-project-to-learn-the-crystal-programming-language/","summary":"I\u0026rsquo;ve started a new side project named Crystal Koans, it\u0026rsquo;s a simple series of exercises organized as a big unit test suite.\nThe \u0026ldquo;koans\u0026rdquo; are heavily inspired by similar projects for other languages, but I didn\u0026rsquo;t found anything similar for Crystal. The project has been included in the awesome collection under the official Learning Resource for the language.\nI\u0026rsquo;ll try to maintain and evolve it in the spare time, I hope you\u0026rsquo;ll find it useful, and any form of contribution is welcome.","title":"A new project to learn the Crystal Programming Language"},{"content":"I like playing with the D programming language and I wrote this little post to show how it\u0026rsquo;s easy to create a dynamic library (shared object, .so) that can be invoked in other programs; to have a little fun we will write a D replacement for the rand() C standard library function call. For your convenience, all the code is also on github\nLet\u0026rsquo;s start with the demo implementation, a C program that calls 10 times the stdlib function rand() to get a random number.\n// random_num.c #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;time.h\u0026gt; int main(){ srand(time(NULL)); int i = 10; while(i--) printf(\u0026#34;%d\\n\u0026#34;,rand()%100); return 0; } if we compile and run this program, we get something like this:\n$ gcc -O3 -ansi -pedantic -std=c99 -Wall -O2 random_num.c -o random_num $ ./random_num 79 51 80 49 24 63 95 85 96 97 Now we will play a little and leverage LD_PRELOAD to give our program an \u0026lsquo;alternate\u0026rsquo; version of rand() ; this new one will be written in D:\n//file: mylib.d module mylib; import std.conv; import std.file : readText; import std.string : chomp; export extern(C) int rand() { return readText(\u0026#34;random.txt\u0026#34;).chomp.to!int; } as you can see, after the imports we declare a rand() function with C linkage; this function doesn\u0026rsquo;t accept any parameter but needs to return an integer. So we can use advanced phobos functions in the powerful D standard library, together with an easy to read UFCS syntax to read a number from a text file, remove extra whitespaces and convert to an integer. As a result, any program that uses the rand() function will get the number stored in the text file. Easier than Python, native as C.\nLet\u0026rsquo;s try:\n$ echo 42 \u0026gt; random.txt $ dmd -m64 -fPIC -w -O -shared -of=mylib.so mylib.d $ LD_PRELOAD=./mylib.so ./random_num 42 42 42 42 42 42 42 42 42 42 As a bonus, I leave here the GNUMakefile used for compilation and test of both programs; I prefer GNU Make format because it doesn\u0026rsquo;t rely on explicit \u0026ldquo;TAB\u0026rdquo; characters so it\u0026rsquo;s easier to copy and paste.\n#file: GNUMakefile .RECIPEPREFIX += .PHONY: all CFLAGS = -ansi -pedantic -std=c99 -Wall -O2 DFLAGS = -m64 -fPIC -w -O -shared all: random_num mylib.so random_num: random_num.c gcc -O3 $(CFLAGS) $\u0026lt; -o $@ %.so:%.d dmd $(DFLAGS) -of=$@ $\u0026lt; clean: rm -f *.so *.o random_num real_random: all ./random_num fake_random: all LD_PRELOAD=./mylib.so ./random_num ","permalink":"https://ilmanzo.github.io/post/hijack-c-library-function-in-d/","summary":"I like playing with the D programming language and I wrote this little post to show how it\u0026rsquo;s easy to create a dynamic library (shared object, .so) that can be invoked in other programs; to have a little fun we will write a D replacement for the rand() C standard library function call. For your convenience, all the code is also on github\nLet\u0026rsquo;s start with the demo implementation, a C program that calls 10 times the stdlib function rand() to get a random number.","title":"Hijack C library functions in D"},{"content":"I am quite a fan of the D programming language and I think it deserves more attention, even if since a few months it\u0026rsquo;s becoming more and more popular, as it gained top20 in the TIOBE Index for February 2020.\nAs an experiment in network programming, I took this simple NTP client written in C and translated to D ; in my opinion while it\u0026rsquo;s keeping the low-level nature, it\u0026rsquo;s shorter, clearer and more effective. It\u0026rsquo;s only a dozen lines of code, but full program is available on my github; stars and contributions are welcome!\nStarting from the top, we find the needed imports and then the packet structure, as is specified in the reference implementation (it\u0026rsquo;s a matter of copy-paste). Notice that in D we can initialize the structure field with tne value we need.\nimport std.stdio; import std.socket; import std.datetime; import std.bitmanip; // from reference struct Packet { align(1): // we want the structure packed, with no gaps byte flags=0x23; // Flags 00|100|011 for li=0, vn=4, mode=3 byte stratum; byte poll; byte precision; uint root_delay; uint root_dispersion; uint referenceID; uint ref_ts_secs; uint ref_ts_frac; uint origin_ts_secs; uint origin_ts_frac; ubyte[4] recv_ts_secs; // This is what we need mostly to get current time. ubyte[4] recv_ts_fracs; // for this example nanoseconds can be dropped uint transmit_ts_secs; uint transmit_ts_frac; } when the main function begins, we create a new UDP socket, with protocol IPV4, and allocate on the stack. Then we tell the socket to connect to a NTP server of the \u0026rsquo;europe\u0026rsquo; pool. Of course you can change it to any address you prefer :)\nconst ntpEpochOffset = 2208988800L; // Difference between Jan 1, 1900 and Jan 1, 1970 void main() { auto sock=new UdpSocket(AddressFamily.INET); Packet packet; // stack allocation sock.connect(new InternetAddress(\u0026#34;europe.pool.ntp.org\u0026#34;,123)); Here it comes the trickiest part: the send method of the UdpSocket class requires a slice, and returns the number of bytes effectively transferred; but we have to send a struct, so we need to cast our packet as a 1-element slice:\nconst sent=sock.send((\u0026amp;packet)[0..1]); const received=sock.receive((\u0026amp;packet)[0..1]); if (sent!=Packet.sizeof || received!=Packet.sizeof) { writeln(\u0026#34;Hmmm .. Something went wrong\u0026#34;); } The last piece is straightforward, thanks also to Phobos, the powerful D standard library: we convert the received bytes to our native bit-order representation (notice the template syntax) and translate from unix Epoch to human-readable date and time. Every variable type is inferred automagically for us :)\nsock.close(); // network byte order is Big-Endian auto unixTime=bigEndianToNative!uint(packet.recv_ts_secs); // NTP returns seconds from Jan 1, 1900 auto stdTime = SysTime.fromUnixTime(unixTime-ntpEpochOffset); writeln(\u0026#34;Hello, the time is: \u0026#34;,stdTime); ","permalink":"https://ilmanzo.github.io/post/a-simple-ntp-client-in-d/","summary":"I am quite a fan of the D programming language and I think it deserves more attention, even if since a few months it\u0026rsquo;s becoming more and more popular, as it gained top20 in the TIOBE Index for February 2020.\nAs an experiment in network programming, I took this simple NTP client written in C and translated to D ; in my opinion while it\u0026rsquo;s keeping the low-level nature, it\u0026rsquo;s shorter, clearer and more effective.","title":"a very simple NTP client in D"},{"content":"Since bitbucket is sunsetting the support for mercurial repositories, I wrote a quick and dirty script to automate the migration from mercurial to GIT:\n#!/bin/bash set -e set -u if [ \u0026#34;$#\u0026#34; -ne 3 ]; then echo \u0026#34;Illegal number of parameters\u0026#34; echo \u0026#34;usage: migrate.sh reponame hgrepourl gitrepourl\u0026#34; exit 1 fi REPONAME=$1 HGURL=$2 GITURL=$3 echo \u0026#34;Migrating $REPONAME from $HGURL to $GITURL...\u0026#34; cd /tmp hg clone $HGURL cd $REPONAME hg bookmark -r default master hg bookmarks hg cd .. mv $REPONAME ${REPONAME}_hg mkdir ${REPONAME}_git cd ${REPONAME}_git git init --bare . cd ../${REPONAME}_hg hg push ../${REPONAME}_git cd ../${REPONAME}_git git remote add hgmigrate $GITURL git push hgmigrate master cd /tmp rm -rf /tmp/${REPONAME}_hg /tmp/${REPONAME}_git echo \u0026#34;...done\u0026#34; Before running the script, you only need to install git and create a git repository (remote or local).\n","permalink":"https://ilmanzo.github.io/post/migrating-a-repository-from-mercurial-to-git/","summary":"Since bitbucket is sunsetting the support for mercurial repositories, I wrote a quick and dirty script to automate the migration from mercurial to GIT:\n#!/bin/bash set -e set -u if [ \u0026#34;$#\u0026#34; -ne 3 ]; then echo \u0026#34;Illegal number of parameters\u0026#34; echo \u0026#34;usage: migrate.sh reponame hgrepourl gitrepourl\u0026#34; exit 1 fi REPONAME=$1 HGURL=$2 GITURL=$3 echo \u0026#34;Migrating $REPONAME from $HGURL to $GITURL...\u0026#34; cd /tmp hg clone $HGURL cd $REPONAME hg bookmark -r default master hg bookmarks hg cd .","title":"migrating a repository from mercurial to git"},{"content":"segue dalla parte 13\nCoroutine Come approccio alla programmazione concorrente, il linguaggio Lua non ha meccanismi interni per gestire nativamente i thread, ma si pu√≤ appoggiare a ci√≤ che offre il sistema operativo sottostante. Lua invece internamente offre il supporto alle coroutine: un programma Lua pu√≤ avere diversi percorsi di esecuzione \u0026lsquo;parallela\u0026rsquo; ognuno col proprio stack e variabili locali ma che condividono risorse e variabili globali con le altre coroutine.\nLa prima differenza sostanziale col modello classico dei thread √® che in un determinato istante \u0026lsquo;gira\u0026rsquo; una e una sola coroutine, mentre in un sistema multiprocessore ci possono essere pi√π thread in esecuzione in contemporanea.\nLa seconda grande differenza √® che nei thread c\u0026rsquo;√® una entit√† esterna (di solito lo scheduler del il sistema operativo) che sovrintende all\u0026rsquo;ordine e assegna la \u0026lsquo;fetta\u0026rsquo; di processore a disposizione di ciascun thread, mentre in Lua ciascuna coroutine decide quando √® il momento di ‚Äúsospendersi‚Äù per lasciare la CPU alle altre.\nIn questo caso, si parla infatti di cooperative multitasking. Le ragioni di questa scelta degli autori sono molteplici: anzitutto la semplicit√† di implementazione, poi ricordiamo il fatto che Lua √® nato come linguaggio \u0026rsquo;embedded\u0026rsquo;, perci√≤ qualora ci fosse veramente bisogno dei thread si sfrutteranno le capacit√† del linguaggio ospitante.\nLe funzionalit√† per gestire le coroutine in Lua sono raggruppate nel package \u0026lsquo;coroutine\u0026rsquo;. La prima funzione che serve √® la create, che riceve come unico argomento una funzione e ritorna un valore di tipo thread:\n\u0026gt;co=coroutine.create(function () print ‚Äúciao‚Äù end) \u0026gt;print(co) thread: 0x8408068 una coroutine pu√≤ avere tre stati: suspended, running, dead. Una coroutine appena creata √® in stato suspended:\n\u0026gt;print(coroutine.status(co)) suspended quindi per avviarla chiamiamo .resume :\n\u0026gt;coroutine.resume(co) ciao ora la routine √® terminata:\n\u0026gt;print(coroutine.status(co)) dead ogni coroutine pu√≤ volontariamente \u0026lsquo;mettersi in pausa\u0026rsquo; e passare alcuni valori tramite la funzione yield ; vediamo un semplice esempio:\nNTHREADS=20 function ping() print \u0026#34;ping\u0026#34; coroutine.yield() end function pong() print \u0026#34;pong\u0026#34; coroutine.yield() end threads={} for j=1,NTHREADS do if j%2==0 then threads[j]=coroutine.create(pong) else threads[j]=coroutine.create(ping) end end running=true while running do for j=1,NTHREADS do running=coroutine.resume(threads[j]) end end se volessimo invece sfruttare i thread del sistema operativo, si possono utilizzare librerie come Lanes oppure llthreads2 .\n","permalink":"https://ilmanzo.github.io/post/il-linguaggio-lua-14/","summary":"segue dalla parte 13\nCoroutine Come approccio alla programmazione concorrente, il linguaggio Lua non ha meccanismi interni per gestire nativamente i thread, ma si pu√≤ appoggiare a ci√≤ che offre il sistema operativo sottostante. Lua invece internamente offre il supporto alle coroutine: un programma Lua pu√≤ avere diversi percorsi di esecuzione \u0026lsquo;parallela\u0026rsquo; ognuno col proprio stack e variabili locali ma che condividono risorse e variabili globali con le altre coroutine.","title":"il linguaggio Lua: parte 14"},{"content":"segue dalla parte 12\nUpvalue e Closure Per chi non ha familiarit√† con i concetti di programmazione funzionale questi termini possono sembrare un po‚Äô oscuri; vediamo di chiarirli con un semplice esempio:\n-- definisco una funzione che parte da un numero N e conta alla rovescia function CreaContatore(N) local v=N local function conta(x) if v\u0026gt;=x then v=v-x end return v end return conta end -- creo qualche istanza: contaDaDieci=CreaContatore(10) contaDaCento=CreaContatore(100) print(contaDaDieci(1)) 9 print(contaDaCento(1)) 99 print(contaDaCento(1)) 98 print(contaDaDieci(1)) 8 print(contaDaDieci(2)) 6 print(contaDaCento(10)) 88 osserviamo le variabili N,v che usate dalla funzione interna: non sono locali, ma nemmeno globali\u0026hellip; Sono upvalue, ovvero riferimenti che provengono da uno stackframe esterno. Quando una funzione usa variabili definite in uno scope lessicale a livello superiore, Lua provvede a memorizzare lo stato, tecnicamente spostando la gestione degli upvalue dallo stack in una zona di memoria dedicata, perch√© altrimenti al ritorno della funzione lo stack verrebbe perso. Ogni funzione che usa uno o pi√π upvalue √® chiamata closure. Si tratta di una caratteristica molto potente perch√© ci permette ad esempio di implementare callback e sandbox. Un esempio a puro scopo didattico:\ndo local oldExecute=os.execute -- salva vecchia funzione local function newExec(command) local a,b=command:find(\u0026#34;rm\u0026#34;) if a then print(\u0026#34;NON eseguo: \u0026#34;..command) else print(\u0026#34;eseguo: \u0026#34;..command) return oldExecute(command) end end os.execute=newExec end os.execute(\u0026#34;/bin/ls\u0026#34;) os.execute(\u0026#34;/bin/rm prova.txt\u0026#34;) dopo questa ridefinizione, abbiamo creato una versione ‚Äòsicura‚Äô di os.execute: decidiamo noi quali comandi pu√≤ lanciare l‚Äôutente\u0026hellip; Nell‚Äôesempio, scartiamo qualsiasi cosa contenga ‚Äúrm‚Äù. Proviamo:\n$ lua sandbox.lua eseguo: /bin/ls coroutine.lua sandbox.lua NON eseguo: /bin/rm prova.txt ","permalink":"https://ilmanzo.github.io/post/il-linguaggio-lua-13/","summary":"segue dalla parte 12\nUpvalue e Closure Per chi non ha familiarit√† con i concetti di programmazione funzionale questi termini possono sembrare un po‚Äô oscuri; vediamo di chiarirli con un semplice esempio:\n-- definisco una funzione che parte da un numero N e conta alla rovescia function CreaContatore(N) local v=N local function conta(x) if v\u0026gt;=x then v=v-x end return v end return conta end -- creo qualche istanza: contaDaDieci=CreaContatore(10) contaDaCento=CreaContatore(100) print(contaDaDieci(1)) 9 print(contaDaCento(1)) 99 print(contaDaCento(1)) 98 print(contaDaDieci(1)) 8 print(contaDaDieci(2)) 6 print(contaDaCento(10)) 88 osserviamo le variabili N,v che usate dalla funzione interna: non sono locali, ma nemmeno globali\u0026hellip; Sono upvalue, ovvero riferimenti che provengono da uno stackframe esterno.","title":"il linguaggio Lua: parte 13"},{"content":"segue dalla parte 11\nsegnalazioni lunari Tra le rocks pi√π interessanti citiamo quelle che permettono le operazioni di networking, come luasocket; salendo di livello, spicca il Kepler project, che comprende un intero stack per applicazioni web: Lapis micro framework, il framework MVC Sailor, e TurboLua, un tool per costuire velocissimi microservizi REST .\nConcludiamo la panoramica sulle librerie accennando ai moduli per creare interfacce grafiche; al pari degli altri linguaggi di scripting, Lua offre binding per i maggiori toolkit grafici: curses, GTK, QT, fltk, wx si usano come negli altri linguaggi e sarebbe qui tedioso illustrarne le modalit√†. Ci focalizzeremo invece su due progetti peculiari, rispettivamente Lua Visual Controls (VCLua) e L√ñVE , che hanno l\u0026rsquo;ulteriore pregio di essere leggeri e snelli. Scarichiamo e installiamo VCLua:\n$ wget http://luaforge.net/frs/download.php/4705/vclua-0.3.5-linux-gtk2.zip scompattiamo e copiamo la shared library nella directory corrente:\n$ unzip vclua*.zip \u0026amp;\u0026amp; cp vclua*/bin/vcl.so . Di seguito una piccola dimostrazione dell‚Äôuso di questa libreria.\n-- guibutton.lua require \u0026#34;vcl\u0026#34; mainForm = VCL.Form(\u0026#34;mainForm\u0026#34;) mainForm.Caption = \u0026#34;VCLua application\u0026#34; mainForm.onclosequery = \u0026#34;onCloseHandler\u0026#34; function onCloseHandler(Sender) return true -- the form can be closed end button = VCL.Button(mainForm) button.onclick = \u0026#34;onButtonClick\u0026#34; button.Caption=\u0026#34;Close\u0026#34; function onButtonClick(sender) print \u0026#34;bottone premuto\u0026#34; mainForm:Close() end mainForm:ShowModal() mainForm:Free() L√ñVE, che ha come motto ‚ÄúDon‚Äôt forget to have fun‚Äù non √® solo una libreria grafica, ma un completo framework: il programmatore ha il compito di scrivere poche funzioni che vengono richiamate periodicamente dal motore runtime. Vediamo il meccanismo con un esempio pratico. Anzitutto scarichiamo e installiamo il software con un\n$ sudo apt-get install love oppure visitando il sito http://love2d.org/ ; verifichiamo il funzionamento con un\n$ love --version ora creiamo una nuova directory\n$ mkdir hello ; cd hello e dentro questa prepariamo un file di nome main.lua con il seguente contenuto:\nfunction love.load() love.graphics.setFont(love.graphics.newFont(70)) love.graphics.setBackgroundColor(255,255,150) love.graphics.setColor(0,0,160) end function love.draw() love.graphics.print(\u0026#34;Hello World\u0026#34;, 200, 300) end abbiamo finito; possiamo vedere il risultato lanciando\n$ love hello o, per i pigri, in figura:\nL√ñVE si basa sul concetto di callback: il framework cerca determinate funzioni dentro il nostro script e le esegue quando ne ha necessit√†; ad esempio love.load() viene invocata alla partenza, e verosimilmente conterr√† il codice per caricare le immagini, i suoni e come abbiamo fatto noi impostare i colori. Altre funzioni come love.update() e love.draw() vengono eseguite ripetutamente (anche pi√π volte al secondo) e si occuperanno rispettivamente di aggiornare lo stato degli oggetti e di disegnarli a video. Essendo un ambiente pensato per sviluppare videogiochi, abbiamo a disposizione una vasta serie di routine anche per il suono, lo scrolling, la lettura dell\u0026rsquo;input (tastiera, mouse, joystick) e nelle ultime versioni anche love.physics, un potente motore fisico basato sul celebre engine Box2D (utilizzato da moltissimi giochi tra cui il celebre Angry Birds) per simulare in maniera realistica il movimento e l\u0026rsquo;interazione tra corpi rigidi. Non essendo possibile soffermarci troppo su questi aspetti, invito gli interessati a visitare il sito di riferimento gi√† citato.\nPrima di concludere segnalo il wiki ufficiale della comunit√† Lua: http://lua-users.org/wiki Una curiosit√† su questo sito: i costi di gestione e mantenimento sono sostenuti grazie ad una lotteria che si tiene periodicamente tra tutti gli aderenti : http://lua-users.org/wiki/LuaUsersLottery . Parteciparvi pu√≤ essere un modo semplice ed efficace per sostenere un validissimo progetto opensource.\n","permalink":"https://ilmanzo.github.io/post/il-linguaggio-lua-12/","summary":"segue dalla parte 11\nsegnalazioni lunari Tra le rocks pi√π interessanti citiamo quelle che permettono le operazioni di networking, come luasocket; salendo di livello, spicca il Kepler project, che comprende un intero stack per applicazioni web: Lapis micro framework, il framework MVC Sailor, e TurboLua, un tool per costuire velocissimi microservizi REST .\nConcludiamo la panoramica sulle librerie accennando ai moduli per creare interfacce grafiche; al pari degli altri linguaggi di scripting, Lua offre binding per i maggiori toolkit grafici: curses, GTK, QT, fltk, wx si usano come negli altri linguaggi e sarebbe qui tedioso illustrarne le modalit√†.","title":"il linguaggio Lua: parte 12"},{"content":"segue dalla parte 10\nRocce di Luna Poter organizzare il codice in pi√π file √® molto utile per modularizzare i programmi, creando package che verranno caricati tramite l\u0026rsquo;istruzione require ‚Äúnomefile‚Äù. Vediamo un esempio:\n-- geompkg.lua module(\u0026#34;geom\u0026#34;) local function quadrato(x) return x*x end local function rettangolo(b,h) return b*h end function area(param) if param.lato then return quadrato(param.lato) end local area=rettangolo(param.base,param.altezza) if param.triangolo or param.trapezio then return area/2 end return area end -- usepkg.lua require(\u0026#39;geompkg\u0026#39;) print(geom.area{base=3,altezza=5}) print(geom.area{lato=3}) --errore, quadrato √® local nel modulo --quindi non accessibile esternamente print(geom.quadrato(5)) nell\u0026rsquo;esempio vogliamo separare le funzioni di calcolo geometrico dal programma principale, cos√¨ le raggruppiamo in un file geompkg.lua; notiamo che nello stesso file abbiamo definito anche delle funzioni locali che non saranno visibili all\u0026rsquo;esterno, come evidenziato dall\u0026rsquo;ultima riga di usepkg.lua. pi√π avanti impareremo come un modulo possa anche essere binario, cio√® compilato come codice nativo. Verificheremo perci√≤ come sia agevole usare da Lua le sterminate librerie disponibili in C.\nAttorno a questo primitivo meccanismo di modularizzazione la comunit√† opensource ha sviluppato una completa infrastruttura di versioning, deploy e gestione dei pacchetti che somiglia a quelli gi√† disponibili in altri linguaggi come Python, Ruby, Perl, e che prende il nome di luarocks http://luarocks.org/. Grazie a questo progetto √® semplicissimo installare e utilizzare numerosi moduli aggiuntivi per le pi√π disparate esigenze, vediamo ora come sfruttarlo.\nAnzitutto occorre installare luarocks, seguendo le istruzioni per compilare i sorgenti presenti sul sito o scaricando il pacchetto della nostra distribuzione preferita oppure. Su Debian/Ubuntu basta un:\n$ sudo apt-get install luarocks terminata l\u0026rsquo;installazione, controlliamo il percorso del repository:\n$ grep -3 servers /etc/luarocks/config.lua rocks_servers = { [[http://luarocks.org/repositories/rocks]] } dopo esserci assicurati che l\u0026rsquo; URL indicato sia raggiungibile, possiamo provare qualche ricerca:\n$ luarocks search twitter $ luarocks search sql la maggior parte di questi progetti sono ospitati su http://luaforge.net, l\u0026rsquo;equivalente del pi√π noto Sourceforge. A titolo di esempio e tanto per rimanere nell\u0026rsquo;ambito ‚Äúlightweight‚Äù, installiamo e proviamo il modulo per interfacciarsi a sqlite:\n$ sudo luarocks install luasql-sqlite3 se non avessimo gi√† installato la libreria di sviluppo, eventualmente occorre un:\n$ sudo apt-get install libsqlite3-dev. Ci prepariamo un database e una tabella di prova:\n$ sqlite3 dati.db SQLite version 3.22.0 2018-01-22 18:45:57 Enter \u0026#34;.help\u0026#34; for usage hints. sqlite\u0026gt; create table rubrica(nome varchar(35), telefono varchar(15)); sqlite\u0026gt; insert into rubrica values(\u0026#39;Linus Torvalds\u0026#39;,\u0026#39;0123456732\u0026#39;); sqlite\u0026gt; insert into rubrica values(\u0026#39;Richard Stallman\u0026#39;,\u0026#39;932874936\u0026#39;); sqlite\u0026gt;.quit e lo interroghiamo da Lua:\n$ lua Lua 5.2.4 Copyright (C) 1994-2015 Lua.org, PUC-Rio \u0026gt; require \u0026#34;luasql.sqlite3\u0026#34; \u0026gt; db=luasql.sqlite3() \u0026gt; conn=db:connect(\u0026#34;dati.db\u0026#34;) \u0026gt; print(conn) SQLite3 connection (0x99e05bc) \u0026gt; curs=conn:execute(\u0026#34;SELECT * FROM rubrica\u0026#34;) \u0026gt; print(curs:fetch()) Linus Torvalds\t0123456732 \u0026gt; print(curs:fetch()) Richard Stallman\t932874936 ","permalink":"https://ilmanzo.github.io/post/il-linguaggio-lua-11/","summary":"segue dalla parte 10\nRocce di Luna Poter organizzare il codice in pi√π file √® molto utile per modularizzare i programmi, creando package che verranno caricati tramite l\u0026rsquo;istruzione require ‚Äúnomefile‚Äù. Vediamo un esempio:\n-- geompkg.lua module(\u0026#34;geom\u0026#34;) local function quadrato(x) return x*x end local function rettangolo(b,h) return b*h end function area(param) if param.lato then return quadrato(param.lato) end local area=rettangolo(param.base,param.altezza) if param.triangolo or param.trapezio then return area/2 end return area end -- usepkg.","title":"il linguaggio Lua: parte 11"},{"content":"segue dalla parte 9\nstringhe e regular expression in questa puntata apriremo una piccola digressione per analizzare le funzionalit√† del modulo string, in particolare l\u0026rsquo;uso delle regular expression.\nIl modulo string ci mette a disposizione potenti funzioni di ricerca e sostituzione basate su espressioni regolari. Una completa implementazione delle regexp POSIX occuperebbe pi√π dell\u0026rsquo;intero linguaggio, ma tutto sommato le funzionalit√† principali sono state mantenute, e gli autori di Lua sono riusciti a impacchettare un ‚Äúmotore‚Äù di pattern matching in meno di 500 righe di codice. Vediamone per sommi capi alcune caratteristiche: La funzione string.find(s,p) cerca un pattern p dentro la stringa s e ritorna una tupla di due valori: la posizione dove inizia la corrispondenza e quella dove finisce; in caso il pattern non sia presente, ritorner√† nil.\n\u0026gt;s=‚Äùhello moon‚Äù \u0026gt;print(string.find(s,‚Äùbazinga‚Äù)) nil \u0026gt;i,j=string.find(s,‚Äùhello‚Äù) \u0026gt;print(i,j) 1 5 \u0026gt;print(string.sub(s,i,j)) hello o, pi√π concisamente, utilizzando la sintassi alternativa,\n\u0026gt;print(s:sub(i,j)) hello possiamo abbreviare la ricerca ed estrazione del testo con una sola chiamata:\n\u0026gt;print(s:match(‚Äùhello‚Äù)) hello la funzione di replace() richiede ovviamente un parametro in pi√π; restituisce la nuova stringa e il numero di sostituzioni eseguite:\n\u0026gt;k=‚Äùall your bases are belong to us‚Äù \u0026gt;s,n=string.gsub(k,‚Äùs‚Äù,‚Äùz‚Äù) \u0026gt;print(s,n) il tutto diventa pi√π interessante quando ricerchiamo o sostituiamo un pattern:\n\u0026gt;p=‚Äùaiuole oltremisura‚Äù \u0026gt;_,v=string.gsub(p,‚Äù[aeiou]‚Äù,‚Äù‚Äù) \u0026gt;print(‚Äútrovate‚Äù,v,‚Äùvocali‚Äù) in questo caso scartiamo il primo valore ritornato assegnandolo a una variabile fittizia (underscore) perch√© ci serve solo il conteggio.\n\u0026gt;html=[[\u0026lt;a href=‚Äùhttp://www.kernel.org‚Äù\u0026gt; \u0026lt;img src=‚Äùpinguino.gif‚Äù\u0026gt; \u0026lt;/a\u0026gt;]] \u0026gt;greedy=‚Äùhref=(.+)\u0026gt;‚Äù \u0026gt;lazy=‚Äùhref=(.-)\u0026gt;‚Äù \u0026gt;print(string.match(html,greedy)) -- non proprio quello che vogliamo \u0026#34;http://www.kernel.org\u0026#34;\u0026gt; img src=\u0026#34;pinguino.gif\u0026#34; \u0026lt;/a \u0026gt;print(string.match(html,lazy)) \u0026#34;http://www.kernel.org\u0026#34; string.match ha anche l\u0026rsquo;equivalente string.gmatch che funziona come un iteratore. La sequenza di escape %b serve per il matching di testo racchiuso tra delimitatori. Quindi per tirare fuori tutti i tag da un html:\n\u0026gt; for tag in string.gmatch(html,‚Äù%b\u0026lt;\u0026gt;‚Äù) print(tag) end vale anche per gfind, ad esempio per implementare la classica funzione split() che suddivide le parole di un testo, che non √® implementata nella libreria standard:\nfunction split(s) local words={} for w in s:gfind(‚Äù%a‚Äù) do table.insert(words,w) end return words end per mostrare le potenzialit√† del meccanismo di ricerca e sostituzione scriviamo un convertitore di formato, che trasforma un comando in stile LaTex come \\comando{testo libero} in XML testo libero:\n\u0026gt;s=‚Äùla nostra \\quote{missione} √® quasi \\em{compiuta}‚Äù \u0026gt;s=string.gsub(s, ‚Äú\\\\(%a+){(.-)}‚Äù,‚Äù\u0026lt;%1\u0026gt;%2\u0026lt;/%1\u0026gt;‚Äù) \u0026gt;print(s) la nostra \u0026lt;quote\u0026gt;missione\u0026lt;/quote\u0026gt; √® quasi \u0026lt;em\u0026gt;compiuta\u0026lt;/em\u0026gt;‚Äù invece di un testo fisso o un pattern, possiamo passare a gsub una funzione, che riceve come input il testo cercato e restituisce la sostituzione. Esemplifichiamo questo concetto con una routine che decodifica gli URL encoding:\n-- funzione ‚Äòhelper‚Äô di appoggio -- trasforma una coppia di cifre hex nel carattere corrispondente function hextochar(n) return string.char(tonumber(n,16)) end function unescape(url) url=string.gsub(url,\u0026#39;+\u0026#39;,\u0026#39; \u0026#39;) -- trasforma + in spazi url=string.gsub(url,‚Äù%%(%x%x)‚Äù, hextochar ) -- applica la funzione di trasformazione hex-\u0026gt;char return url end \u0026gt;q=‚Äùa%2Bb+%3D+c‚Äù \u0026gt;print(unescape(q)) a+b = c prima di concludere, come \u0026lsquo;chicca\u0026rsquo; finale segnalo un software : Lua-Quick-Try-Out\n√® un comodo ambiente di sviluppo interattivo dove scrivere ed eseguire comandi e script Lua, compresi esperimenti di grafica bitmap e vettoriale\u0026hellip; Si scrive codice e si vede subito il risultato, in modo molto simile al basic dei primi homecomputer a 8bit!\n","permalink":"https://ilmanzo.github.io/post/il-linguaggio-lua-10/","summary":"segue dalla parte 9\nstringhe e regular expression in questa puntata apriremo una piccola digressione per analizzare le funzionalit√† del modulo string, in particolare l\u0026rsquo;uso delle regular expression.\nIl modulo string ci mette a disposizione potenti funzioni di ricerca e sostituzione basate su espressioni regolari. Una completa implementazione delle regexp POSIX occuperebbe pi√π dell\u0026rsquo;intero linguaggio, ma tutto sommato le funzionalit√† principali sono state mantenute, e gli autori di Lua sono riusciti a impacchettare un ‚Äúmotore‚Äù di pattern matching in meno di 500 righe di codice.","title":"il linguaggio Lua: parte 10"},{"content":"honey-ssh-pot Curious about who and how attempts ssh login to your home server ? Me too\u0026hellip; So I wrote a very simple ssh honeypot, just to collect interesting info about the kind guys who knocks my door :)\nwarning: this is safe, but don\u0026rsquo;t run the service (well, ANY service) as root user. Even better if you can run it as a dedicate unprivileged user.\nThis program is only for didactic use and not intended for deployment in a production network environment.\nIf you want to have it exposed on the public internet, you must map port 22 of your wan router to the internal server port ( 2222 by default)\u0026hellip; Do it at your risk!\npackage main import ( \u0026#34;github.com/gliderlabs/ssh\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;log/syslog\u0026#34; \u0026#34;os\u0026#34; ) // this is the function called when ssh client requests authentication // here we log attacker credentials on purpose func authHandler(ctx ssh.Context, password string) bool { log.Printf(\u0026#34;User: %s connecting from %s with password: %s\\n\u0026#34;, ctx.User(), ctx.RemoteAddr(), password) return true } // dear guest, your ssh session will be very short... // to free up resources we only send a message and quit func sessionHandler(s ssh.Session) { io.WriteString(s, \u0026#34;Welcome!\\n\u0026#34;) } func main() { // Configure logger to write to the syslog logwriter, e := syslog.New(syslog.LOG_INFO, os.Args[0]) if e == nil { log.SetOutput(logwriter) } s := \u0026amp;ssh.Server{ Addr: \u0026#34;:2222\u0026#34;, Handler: sessionHandler, PasswordHandler: authHandler, } log.Println(\u0026#34;starting ssh server on port 2222...\u0026#34;) log.Fatal(s.ListenAndServe()) } $ git clone https://github.com/ilmanzo/honey-ssh-pot.git $ go get github.com/gliderlabs/ssh $ go build -ldflags=\u0026#34;-s -w\u0026#34; # makes a smaller binary $ ./honey-ssh-pot now get some popcorn and watch on your syslog :)\n$ tail -f /var/log/messages ./honey-ssh-pot[24125]: 2018/06/26 21:50:09 starting ssh server on port 2222... ./honey-ssh-pot[24125]: 2018/06/26 21:50:40 User: evilhacker connecting from 127.0.0.1:51182 with password: secretpassword credits to gliderlabs for the awesome ssh wrapper package. Thank you guys !\n","permalink":"https://ilmanzo.github.io/post/a-honeypot-ssh-server-in-go/","summary":"\u003ch2 id=\"honey-ssh-pot\"\u003ehoney-ssh-pot\u003c/h2\u003e\n\u003cp\u003eCurious about who and how attempts ssh login to your home server ? Me too\u0026hellip; So I wrote a very simple ssh honeypot, just to collect interesting info about the kind guys who knocks my door :)\u003c/p\u003e\n\u003cp\u003ewarning: this is safe, but don\u0026rsquo;t run the service (well, ANY service) as root user. Even better if you can run it as a dedicate unprivileged user.\u003c/p\u003e\n\u003cp\u003eThis program is only for didactic use and not intended for deployment in a production network environment.\u003c/p\u003e\n\u003cp\u003eIf you want to have it exposed on the public internet, you must map port 22 of your wan router to the internal server port ( 2222 by default)\u0026hellip; Do it at your risk!\u003c/p\u003e","title":"a honeypot ssh server in Go"},{"content":"segue dalla parte 8\nil modulo lunare Per mantenere la sua natura minimalista, Lua ha ben poche funzionalit√† incluse nel linguaggio e delega molti aspetti a librerie e moduli esterni. Ad esempio le operazioni matematiche sono accessibili nel package, o se preferite, namespace col prefisso math:\n$ lua \u0026gt;print(math.sin(math.pi/2)) 1 sarebbe oltremodo noioso elencare tutte le funzioni presenti, basti dire che oltre alle funzioni trigonometriche abbiamo logaritmi, esponenziali, modulo, minimo, massimo, arrotondamenti e generazione di valori random. Per operare in modo agevole con tabelle e vettori abbiamo a disposizione il modulo table:\n\u0026gt;t={10,30,40} \u0026gt;table.insert(t,2,\u0026#34;venti\u0026#34;) \u0026gt;table.insert(t,\u0026#34;cinquanta\u0026#34;) \u0026gt;table.foreach(t,print) 1 10 2 venti 3 30 4 40 5 cinquanta \u0026gt;a={8,3,6,1,7} \u0026gt;table.sort(a) \u0026gt;print(table.concat(a,\u0026#34;-\u0026#34;)) 1-3-6-7-8 e, come promesso tempo fa, ecco versione ottimizzata della funzione chain():\nfunction chain2(...) local result={} for i,v in ipairs(arg) do result[i]=tostring(v) end return table.concat(result) end poich√© evita la creazione di stringhe temporanee, questa funzione risulta di gran lunga pi√π efficiente della precedente. Le funzioni di dialogo col sistema operativo sono invece raggruppate nel package os:\n\u0026gt;print(os.getenv(\u0026#39;HOME\u0026#39;)) /home/andrea \u0026gt;os.execute(\u0026#39;/bin/ls\u0026#39;) mentre per gestire flussi di dati in ingresso e in uscita (input/output) servir√† il modulo \u0026lsquo;io\u0026rsquo;:\nfdati=io.open(\u0026#39;dati.txt\u0026#39;,\u0026#39;w\u0026#39;) for i=1,10 do fdati:write(\u0026#34;riga\u0026#34;,i,\u0026#34;\\n\u0026#34;) end fdati:close() for riga in io.lines(\u0026#34;dati.txt\u0026#34;) do print(\u0026#34;lettura\u0026#34;,riga) end Per la manipolazione di stringhe useremo il prefisso string:\n$lua \u0026gt;a=\u0026#34;gnu/linux\u0026#34; \u0026gt;print(string.upper(a)) GNU/LINUX \u0026gt;b=string.rep(\u0026#34;x\u0026#34;,2^20) -- stringa da 1 Megabyte \u0026gt;print(string.len(a..b)) 1048585 \u0026gt;print(string.sub(a,1,3)) -- primi tre caratteri gnu \u0026gt;print(string.sub(a,-5,-1) -- ultimi cinque caratteri linux lo stesso modulo contiene anche funzioni di formattazione, con una sintassi analoga alla printf(3) del C:\n\u0026gt;tag,titolo,numero=\u0026#34;h1\u0026#34;,\u0026#34;titolo\u0026#34;,2 \u0026gt;s=string.format(\u0026#34;\u0026lt;%s\u0026gt;%s %d\u0026lt;/%s\u0026gt;\u0026#34;,tag,titolo,numero,tag) \u0026gt;print(s) \u0026lt;h1\u0026gt;titolo 2\u0026lt;/h1\u0026gt; string fornisce una implementazione ridotta, ma efficace, delle regular expression. Nell\u0026rsquo;interprete interattivo e nei nostri script le librerie built-in come math, io, os, string sono gi√† disponibili senza dover specificare nient\u0026rsquo;altro; come vedremo pi√π avanti, questo non vale pi√π quando useremo Lua come libreria \u0026rsquo;embedded\u0026rsquo; nei programmi C, perch√© potremo scegliere di volta in volta le funzionalit√† da includere o meno, con il beneficio di snellire i nostri programmi togliendo le funzionalit√† che non usiamo.\n","permalink":"https://ilmanzo.github.io/post/il-linguaggio-lua-09/","summary":"segue dalla parte 8\nil modulo lunare Per mantenere la sua natura minimalista, Lua ha ben poche funzionalit√† incluse nel linguaggio e delega molti aspetti a librerie e moduli esterni. Ad esempio le operazioni matematiche sono accessibili nel package, o se preferite, namespace col prefisso math:\n$ lua \u0026gt;print(math.sin(math.pi/2)) 1 sarebbe oltremodo noioso elencare tutte le funzioni presenti, basti dire che oltre alle funzioni trigonometriche abbiamo logaritmi, esponenziali, modulo, minimo, massimo, arrotondamenti e generazione di valori random.","title":"il linguaggio Lua: parte 9"},{"content":"segue dalla settima parte\nOggetti volanti e non Lua non √® un linguaggio nativamente object-oriented. Se nei nostri script volessimo adottare uno stile OOP, ad esempio per modellare le operazioni su un conto corrente la cosa pi√π naturale sarebbe usare una tabella:\nConto = { saldo = 200.0 } Questa sintassi potrebbe essere assimilata al \u0026lsquo;costruttore\u0026rsquo; dell\u0026rsquo;oggetto Conto. Possiamo anche definire dei metodi:\nfunction Conto.preleva(cifra) Conto.saldo = Conto.saldo - cifra end e quindi potremmo comodamente chiamare, problemi economici a parte:\nConto.preleva(200) purtroppo, per√≤, questa implementazione semplicistica ha il difetto di essere legata alla variabile Conto; possiamo infatti invocare il metodo solo su quella:\na1=Conto; Conto=nil a1.preleva(200.0) -- errore! La soluzione consiste nell\u0026rsquo;aggiungere un ulteriore parametro al metodo, ovvero passare l\u0026rsquo;oggetto su cui operare, che in pratica √® la prassi anche in altri linguaggi come Python:\nfunction Conto.preleva(self,cifra) self.saldo = self.saldo - cifra end ora dunque siamo liberi di dare qualsiasi nome al nostro oggetto:\na2=Conto; Conto=nil; a2.preleva(a2,100.0) -- nessun errore per√≤ siamo obbligati a passare sempre l\u0026rsquo;oggetto come primo parametro. Ci viene in aiuto la sintassi:\na2:preleva(100.0) possiamo usare la stessa forma anche per definire le funzioni-metodo:\nfunction Conto:deposita(cifra) self.saldo = self.saldo + cifra end il parametro \u0026rsquo;nascosto\u0026rsquo; si chiamer√† sempre self; altri linguaggi lo chiamano this ma il concetto non cambia. Sull\u0026rsquo;argomento object oriented ci sarebbe ancora molto da dire, ma invito gli interessati a consultare il capitolo 16 di ‚ÄúProgramming in Lua‚Äù, il libro ufficiale del quale la prima edizione √® disponibile gratuitamente all\u0026rsquo;URL http://www.lua.org/pil/16.html\n","permalink":"https://ilmanzo.github.io/post/il-linguaggio-lua-08/","summary":"segue dalla settima parte\nOggetti volanti e non Lua non √® un linguaggio nativamente object-oriented. Se nei nostri script volessimo adottare uno stile OOP, ad esempio per modellare le operazioni su un conto corrente la cosa pi√π naturale sarebbe usare una tabella:\nConto = { saldo = 200.0 } Questa sintassi potrebbe essere assimilata al \u0026lsquo;costruttore\u0026rsquo; dell\u0026rsquo;oggetto Conto. Possiamo anche definire dei metodi:\nfunction Conto.preleva(cifra) Conto.saldo = Conto.saldo - cifra end e quindi potremmo comodamente chiamare, problemi economici a parte:","title":"il linguaggio Lua: ottava parte"},{"content":"segue dalla sesta parte\nIteratori e lua funzionale Cos\u0026rsquo;√® un iteratore? Informaticamente parlando, √® un costrutto che ci permette di scorrere strutture dati come liste, array, elenchi. In pratica, dato un elemento della struttura il compito dell\u0026rsquo;iteratore √® farci avere il prossimo su cui operare. Non ci stupir√† apprendere che in Lua gli iteratori sono funzioni. Vediamo un semplice esempio:\nfunction reverse_iter(t) local i=#t+1 return function() i=i-1 if i\u0026gt;=0 then return t[i] end end end reverse_iter √® una fabbrica (factory) di funzioni: ogni volta che la chiamiamo, ci crea una nuova closure, ossia l\u0026rsquo;iteratore specifico per l\u0026rsquo;array che gli passiamo. La funzione che otteniamo mantiene il suo stato grazie alle variabili i e t ; quando non ci sono pi√π elementi, restituisce nil. L\u0026rsquo;iteratore si potrebbe usare cos√¨:\nlista={10,20,30,40} iteratore = reverse_iter(lista) \u0026gt; print(iteratore()) 40 \u0026gt; print(iteratore()) 30 \u0026gt; print(iteratore()) 20 \u0026gt; print(iteratore()) 10 \u0026gt; print(iteratore()) nil oppure, semplificando:\nlista={10,20,30,40} for item in reverse_iter(lista) do print(item) end la semplicit√† del costrutto for ci nasconde parecchie operazioni: invocare la factory, tenerci un riferimento all\u0026rsquo;iteratore, chiamarlo ad ogni ciclo e fermare il loop quando otteniamo un valore nil. La flessibilit√† di Lua ci consente di scrivere lo stesso ciclo in modo alternativo: anzich√© passare l\u0026rsquo;array alla funzione, passiamo la funzione come parametro:\nlista={5,6,7,8,9} function alrovescio(f) for i=5,1,-1 do f(lista[i]) end end e quindi stampare tutti gli elementi con:\nalrovescio(print) ma anche fare qualcos\u0026rsquo;altro, per esempio filtrare i valori pari:\nalrovescio(function(x) if (x%2)\u0026gt;0 then print(x) end end) l\u0026rsquo;uso di questo stile di programmazione √® tipico dei linguaggi funzionali, ma come abbiamo visto √® semplice utilizzare lo stesso paradigma in Lua. Qualcuno si √® perfino divertito a creare un interprete Lisp : http://urn-lang.com/\n","permalink":"https://ilmanzo.github.io/post/il-linguaggio-lua-07/","summary":"segue dalla sesta parte\nIteratori e lua funzionale Cos\u0026rsquo;√® un iteratore? Informaticamente parlando, √® un costrutto che ci permette di scorrere strutture dati come liste, array, elenchi. In pratica, dato un elemento della struttura il compito dell\u0026rsquo;iteratore √® farci avere il prossimo su cui operare. Non ci stupir√† apprendere che in Lua gli iteratori sono funzioni. Vediamo un semplice esempio:\nfunction reverse_iter(t) local i=#t+1 return function() i=i-1 if i\u0026gt;=0 then return t[i] end end end reverse_iter √® una fabbrica (factory) di funzioni: ogni volta che la chiamiamo, ci crea una nuova closure, ossia l\u0026rsquo;iteratore specifico per l\u0026rsquo;array che gli passiamo.","title":"il linguaggio Lua: settima parte"},{"content":"while working with image files, I needed a simple way to analyze content of a picture; so I wrote this tool that \u0026ldquo;walks\u0026rdquo; inside a PNG file and reports all the chunks seen; this is intended to be expanded with more features in a future.\npackage main import ( \u0026#34;encoding/binary\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;os\u0026#34; ) type chunk struct { Length uint32 ChunkType [4]byte } func main() { if len(os.Args) != 2 { fmt.Printf(\u0026#34;Usage: %s filename.png\\n\u0026#34;, os.Args[0]) os.Exit(1) } f, err := os.Open(os.Args[1]) if err != nil { panic(err) } defer f.Close() header := make([]byte, 8) _, err = f.Read(header) fmt.Printf(\u0026#34;header: %v\\n\u0026#34;, header) if err != nil { panic(err) } var data chunk var offset int64 offset = 8 for { err = binary.Read(f, binary.BigEndian, \u0026amp;data) if err != nil { if err == io.EOF { break } panic(err) } fmt.Printf(\u0026#34;Offset: %d chunk len=%d, type: %s\\n\u0026#34;, offset, data.Length, string(data.ChunkType[:4])) f.Seek(int64(data.Length+4), io.SeekCurrent) offset += int64(data.Length) + 4 } } usage:\n$ go build $ ./pngwalker example.png header: [137 80 78 71 13 10 26 10] Offset: 8 chunk len=13, type: IHDR Offset: 25 chunk len=93, type: PLTE Offset: 122 chunk len=2173, type: IDAT Offset: 2299 chunk len=0, type: IEND ","permalink":"https://ilmanzo.github.io/post/a-simple-png-decoder/","summary":"while working with image files, I needed a simple way to analyze content of a picture; so I wrote this tool that \u0026ldquo;walks\u0026rdquo; inside a PNG file and reports all the chunks seen; this is intended to be expanded with more features in a future.\npackage main import ( \u0026#34;encoding/binary\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;os\u0026#34; ) type chunk struct { Length uint32 ChunkType [4]byte } func main() { if len(os.Args) != 2 { fmt.","title":"a simple PNG decoder in Go"},{"content":"segue dalla quinta parte\nQuando il saggio indica la luna, lo sciocco guarda il dito Nello scorse puntate abbiamo appreso le basi di un linguaggio minimalista, il cui motto √® ‚Äúdoing more with less‚Äù, che occupa meno byte della vostra foto su Facebook e che i benchmark dichiarano il pi√π veloce tra i linguaggi di scripting. Nato da menti brasiliane, l\u0026rsquo;hanno chiamato Lua, che vuol dire Luna in portoghese. Lua viene usato come linguaggio di scripting in Angry Birds, World of Warcraft e decine di altri videogame e software: nello scorso post abbiamo visto come creare un semplice plugin per VLC. In questo invece approfondiremo le peculiarit√† del linguaggio e cominceremo a guardare oltre, presentando l‚Äôecosistema di librerie; infine nel prossimo sperimenteremo l‚Äôintegrazione tra Lua e C.\nLuna di miele: zucchero sintattico Abbiamo gi√† studiato due elementi chiave del linguaggio Lua: le funzioni e le tabelle. L\u0026rsquo;uso di questi costrutti √® talmente comune che gli autori ci mettono a disposizione alcune scorciatoie. Ad esempio scrivere\nlibro.pagine=268 equivale a\nlibro[‚Äúpagine‚Äù]=268 attenzione: non √® invece la stessa cosa scrivere libro[pagine], perch√© quest\u0026rsquo;ultima espressione usa l\u0026rsquo;eventuale variabile \u0026ldquo;pagine\u0026rdquo; come chiave nell\u0026rsquo;array associativo. Se pagine non √® una variabile definita, in questo caso sarebbe come scrivere libro[nil]=268 il che causerebbe un errore. Capita spesso di chiamare una funzione passando un solo argomento: se tale argomento √® una costante di tipo stringa o tabella, possiamo omettere le parentesi tonde; quindi func(‚Äúciao‚Äù) diventa func ‚Äúciao‚Äù e, analogamente, potremo tradurre\nfunc([[ci vediamo presto]]) con\nfunc[[ci vediamo presto]] inoltre funz({x=3,y=4}) si pu√≤ scrivere con un pi√π succinto funz{x=3,y=4}. In questo ultimo caso di fatto otteniamo quello che in altri linguaggi si chiama \u0026rsquo;named parameters\u0026rsquo;, ovvero il passaggio di argomenti per nome (e non per posizione) e con lo stesso meccanismo possiamo predisporre dei valori di default ai parametri. Vediamo un gustoso esempio:\nfunction cena(dettagli) --valorizza parametri con valori di default primo=dettagli.primo or \u0026#34;pasta\u0026#34; secondo=dettagli.secondo or \u0026#34;pesce\u0026#34; quando=dettagli.quando or \u0026#34;stasera\u0026#34; print(quando..\u0026#34; preparo \u0026#34;..primo..\u0026#34; e \u0026#34;..secondo) end cena{secondo=\u0026#34;carne\u0026#34;} cena{primo=\u0026#34;risotto\u0026#34;,quando=\u0026#34;domani\u0026#34;} l‚Äôoutput sar√†:\nstasera mangio pasta e carne domani mangio risotto e pesce in pratica passiamo alla funzione una sola hashtable che contiene tutti i parametri necessari; se uno di questi non viene valorizzato, vale NIL e perci√≤ possiamo inizializzarlo con un valore di default.\nUna funzione che accetti un numero variabile di argomenti si dichiara con la sintassi a ‚Äúpunti di sospensione‚Äù\nfunction chain(...) local result=‚Äù‚Äù for i,v in ipairs(arg) do result=result..tostring(v) end return result end questa funzione restituisce una stringa accodando tutti i parametri. Come possiamo vedere, gli argomenti vengono passati tramite l\u0026rsquo;array convenzionale arg. Notiamo anche l\u0026rsquo;uso dell\u0026rsquo;iteratore ipairs(), aspetto che approfondiremo in seguito.\nprint(chain(3,‚Äù\\064‚Äù,-5)) 3@-5 per i pi√π esperti, facciamo presente che le stringhe Lua sono immutabili, perci√≤ per concatenare stringhe piuttosto grandi, il metodo usato in chain() √® inefficiente, in quanto provoca continue allocazioni/deallocazioni. Pi√π avanti ne scriveremo una versione ottimizzata.\n","permalink":"https://ilmanzo.github.io/post/il-linguaggio-lua-06/","summary":"segue dalla quinta parte\nQuando il saggio indica la luna, lo sciocco guarda il dito Nello scorse puntate abbiamo appreso le basi di un linguaggio minimalista, il cui motto √® ‚Äúdoing more with less‚Äù, che occupa meno byte della vostra foto su Facebook e che i benchmark dichiarano il pi√π veloce tra i linguaggi di scripting. Nato da menti brasiliane, l\u0026rsquo;hanno chiamato Lua, che vuol dire Luna in portoghese. Lua viene usato come linguaggio di scripting in Angry Birds, World of Warcraft e decine di altri videogame e software: nello scorso post abbiamo visto come creare un semplice plugin per VLC.","title":"il linguaggio Lua: sesta parte"},{"content":"As you may know, you can configure any DHCP server to send many options to the clients; for example to setup dns domains, http proxy (WPAD) and so on.\nIf you need to access these options from a linux client, you must configure the client to ASK the server for the new options, by editing /etc/dhcp/dhclient.conf, and add an entry like:\noption WPAD code 252 = string; also request WPAD; done that, when you\u0026rsquo;ll ask for a dhcp, the dhclient process will invoke your hook scripts with two new environment variables, old_WPAD and new_WPAD, with the values before and after the renewal.\nso you can put a script in the folder /etc/dhcp/dhclient-enter-hooks.d or /etc/dhcp/dhclient-exit-hooks.d to simply \u0026ldquo;use\u0026rdquo; the value, by writing it in a configuration file or somewhere else.\n#!/bin/bash echo \u0026#34;I got a new value of WPAD from DHCP : ${new_WPAD}\u0026#34; \u0026gt; /tmp/wpad.txt ","permalink":"https://ilmanzo.github.io/post/access-dhcp-options-from-client/","summary":"As you may know, you can configure any DHCP server to send many options to the clients; for example to setup dns domains, http proxy (WPAD) and so on.\nIf you need to access these options from a linux client, you must configure the client to ASK the server for the new options, by editing /etc/dhcp/dhclient.conf, and add an entry like:\noption WPAD code 252 = string; also request WPAD; done that, when you\u0026rsquo;ll ask for a dhcp, the dhclient process will invoke your hook scripts with two new environment variables, old_WPAD and new_WPAD, with the values before and after the renewal.","title":"linux: how to access DHCP options from client"},{"content":"segue dalla quarta parte\n‚ÄúSonata al chiaro di luna‚Äù : un plugin per vlc Come dicevamo all\u0026rsquo;inizio, Lua √® usato da numerose applicazioni come linguaggio di estensione; per scopi didattici ho scelto di scrivere un semplice plugin per un programma diffuso, il media player universale VLC. Con questo plugin risolveremo per sempre l\u0026rsquo;annoso problema di decidere cosa sarebbe meglio sgranocchiare durante la visione! L\u0026rsquo;integrazione con lo scripting Lua √® documentata in una serie di file README.TXT sparsi nella directory $SRC/share/lua/ (dove $SRC √® la directory dove abbiamo decompresso l\u0026rsquo;archivio del sorgente di vlc). Grazie ad essi apprendiamo che VLC supporta diversi tipi di \u0026ldquo;agganci\u0026rdquo; (hooks) con Lua: per la generazione di playlist (ad esempio trasformare una playlist Youtube in una VLC), per le interfacce di controllo (a titolo di esempio, si pu√≤ comandare VLC via telnet), per il recupero di meta-informazioni sullo stream (tipicamente scaricare e visualizzare la copertina dell\u0026rsquo;album o la locandina del film in riproduzione) e, finalmente, quella che useremo noi, cio√® una generica funzionalit√† aggiuntiva attivabile e disattivabile da men√π. Il file README specifica che questo tipo di estensione deve contenere due funzioni Lua di nome activate() e deactivate() che verranno chiamte in concomitanza con questi due eventi. Lo script deve avere anche una funzione descriptor() che VLC chiamer√† allo startup ed avr√† il compito di esporre una tabella con delle informazioni sul plugin come titolo, autore, versione. Ultimo vincolo, lo script deve risiedere in uno specifico path, ovvero $LIB/vlc/lua, dove $LIB √® il percorso di libvlc (il ‚Äúmotore‚Äù del programma) a livello di sistema oppure $HOME/.local/share/vlc/lua, soluzione che permette ad ogni utente di usare i propri plugin; io ho pertanto copiato lo script seguente [vlc_cibo.lua] in ~/.local/share/vlc/lua/extensions/cibo.lua\n-- da salvare in $HOME/.local/share/vlc/lua/extensions -- ritorna una tabella con una serie di dati sul plugin -- ad esempio il titolo da mostrare nel menu function descriptor() return { version = \u0026#34;0.1\u0026#34;; capabilities = {}; title=\u0026#34;cibarie giuste\u0026#34;; } end -- funzione chiamata quando l\u0026#39;utente seleziona il plugin dal menu function activate() local durata=vlc.input.item():duration() durata=math.floor(durata/60) local msg=\u0026#34;per soli \u0026#34;..tostring(durata)..\u0026#34; minuti ci accontentiamo del popcorn\u0026#34; if durata\u0026gt;60 then msg=\u0026#34;il film sembra lungo, meglio ordinare una \u0026lt;b\u0026gt;pizza\u0026lt;/b\u0026gt;\u0026#34; end dlg=vlc.dialog(\u0026#34;cibarie giuste\u0026#34;) dlg:add_label(msg) dlg:add_button(\u0026#34;Chiudi\u0026#34;,clicked) -- associa al click del pulsante la funzione clicked vlc.playlist.pause() -- ferma la riproduzione end -- chiamata quando l\u0026#39;utente clicca sul pulsante Chiudi della message box function clicked() vlc.deactivate() end -- chiamata da VLC quando l\u0026#39;utente disattiva il plugin function deactivate() vlc.playlist.play() -- fa ripartire il filmato end function close() vlc.deactivate() end Analizziamo rapidamente il sorgente; dopo i commenti iniziali troviamo la funzione descriptor, che nel nostro caso inizializza e ritorna al chiamante una tabella con un solo campo, cio√® il titolo del plugin; √® l\u0026rsquo;unico indispensabile e come si vede in figura √® ci√≤ che troveremo come voce di menu in VLC.\nLa seconda funzione √® cruciale: viene chiamata quando l\u0026rsquo;utente seleziona il plugin. Come prima cosa si fa dare la durata in secondi dell\u0026rsquo;attuale media in riproduzione. VLC infatti espone verso Lua un ‚Äúoggetto‚Äù vlc (vedremo nel prossimo articolo come implementare questa tecnica) tramite il quale ciascun plugin pu√≤ interagire col media player. Grazie alla documentazione apprendiamo che la funzione input.item() dell\u0026rsquo;oggetto vlc ritorna un riferimento al film che stiamo guardando. A sua volta questo oggetto ha una serie di metodi, tra i quali duration() che fornisce la lunghezza in secondi. In questo esempio la durata viene convertita in minuti (divisione per 60) ed utilizzata come parametro per stabilire quale messaggio visualizzare. Usando ancora l\u0026rsquo;oggetto vlc, chiediamo al programma di creare per noi una dialog box nella quale inseriamo la nostra scritta ed un pulsante, il cui evento click viene associato ad una nostra funzione. Come ultima operazione, decidiamo di attirare l\u0026rsquo;attenzione chiedendo al media player di mettere in pausa la riproduzione, cos√¨ l\u0026rsquo;utente potr√† leggere l\u0026rsquo;avviso e prepararsi le giuste cibarie!\nLa terza funzione dello script √® quella che viene chiamata da VLC quando l\u0026rsquo;utente ha cliccato sul pulsante della dialog box; in questo esempio abbiamo scelto di disattivare il plugin (provocando quindi l\u0026rsquo;esecuzione della prossima funzione), ma nessuno ci vieta di scrivere del codice per ordinare effettivamente la pizza tramite un web service\u0026hellip; Ci resta solo la deactivate(): qui andrebbero eseguite tutte le operazioni di pulizia del plugin, nel nostro caso ci limitiamo a far ripartire il filmato.\nA parte la dubbia utilit√† di questo plugin didattico, possiamo notare alcune cose interessanti: anzitutto la robustezza, nel senso che qualunque errore o problema in uno script Lua non metter√† minimamente in crisi il programma principale; apprezziamo inoltre la chiarezza e la semplicit√† di avere interfacce ben definite, nel senso che il team VLC ha deciso per noi cosa esporre del programma e come farlo, nascondendoci la complessit√† dell\u0026rsquo;implementazione, ma allo stesso tempo consentendoci di aggiungere nostre funzionalit√†. Infine non trascuriamo la portabilit√†, ovvero che questo plugin funzioner√† allo stesso modo e senza modifiche anche in ambiente Windows o Mac.\n","permalink":"https://ilmanzo.github.io/post/il-linguaggio-lua-05/","summary":"segue dalla quarta parte\n‚ÄúSonata al chiaro di luna‚Äù : un plugin per vlc Come dicevamo all\u0026rsquo;inizio, Lua √® usato da numerose applicazioni come linguaggio di estensione; per scopi didattici ho scelto di scrivere un semplice plugin per un programma diffuso, il media player universale VLC. Con questo plugin risolveremo per sempre l\u0026rsquo;annoso problema di decidere cosa sarebbe meglio sgranocchiare durante la visione! L\u0026rsquo;integrazione con lo scripting Lua √® documentata in una serie di file README.","title":"il linguaggio Lua: quinta parte"},{"content":"segue dalla terza parte\n‚ÄúMoonlight Bay‚Äù (ovvero: ‚Äúchiedi chi erano i vectors‚Äù) L\u0026rsquo;unica struttura dati disponibile in Lua √® rappresentata dagli array o meglio, dalle tabelle (o hash): array associativi formati da coppie chiave-valore, nelle quali sia la chiave sia il valore possono essere qualsiasi tipo di dato. Vediamo un paio di esempi, dapprima un normale vettore:\n\u0026gt; i = 3 \u0026gt; a = {1,3,5,7,9} \u0026gt; print(i,a[3],a[4],a[i+3]) questa sequenza stampa i valori 3,5,7,nil; la prima cosa che appare diversa rispetto ad un altro linguaggio √® che gli indici per gli array partono da 1 anzich√© da zero; la seconda √® che un eventuale sforamento dell\u0026rsquo;array non causa errore ma semplicemente ritorna nil. Le tabelle Lua sono flessibili\u0026hellip; Esploriamole con un esempio di complessit√† crescente.\n\u0026gt;band={ Paul=\u0026#39;basso\u0026#39;, Ringo=\u0026#39;batteria\u0026#39;, George=\u0026#39;chitarra\u0026#39;, John=\u0026#39;chitarra\u0026#39;} \u0026gt;print(band[\u0026#39;Ringo\u0026#39;]) batteria ma anche, con una sintassi semplificata:\n\u0026gt;print(band.Ringo) batteria E ovviamente funziona anche in modifica:\n\u0026gt;band.Paul=\u0026#39;chitarra\u0026#39; √à semplice aggiungere nuovi elementi (anche se gli effetti non sono sempre positivi!):\n\u0026gt;band.Yoko=\u0026#39;sitar\u0026#39; se volessimo vedere il contenuto di tutta la tabella, non basterebbe un semplice print band, ma occorrer√† iterare sui singoli elementi:\n\u0026gt;for k,v in pairs(band) do print(k,v) end I fans saranno felici di sapere che basta impostare un elemento a nil per rimuoverlo dalla tabella:\n\u0026gt;band.Yoko=nil Come dicevamo, un hash pu√≤ contenere qualsiasi tipo di dato, comprese altre tabelle:\n\u0026gt;band.tour={‚ÄúLondra‚Äù,‚ÄùParigi‚Äù,‚ÄùMadrid‚Äù,‚ÄùRoma‚Äù} \u0026gt;for city in 1,4 do print(band.tour[city]) end e via complicando:\n\u0026gt;band.playlist={ \u0026gt;\u0026gt;{titolo=‚ÄúLove me do‚Äù,voto=8.5}, \u0026gt;\u0026gt;{titolo=‚ÄùLet it be‚Äù, voto=8}, \u0026gt;\u0026gt;yday={titolo=‚ÄùYesterday‚Äù,voto=7.5}, \u0026gt;\u0026gt;help={titolo=‚ÄùHelp‚Äù,voto=7.5} \u0026gt;\u0026gt;} possiamo accedere ai singoli elementi delle sotto-tabelle con la sintassi\n\u0026gt;print(band[\u0026#39;tour\u0026#39;][1]) o pi√π semplicemente\n\u0026gt;print(band.tour[1]) e in maniera analoga, avendo assegnato delle reference agli elementi, richiamarli per nome:\n\u0026gt;print(band.playlist.help.voto) Anticipo che quando gli elementi di una tabella sono funzioni, otteniamo un comportamento object-oriented:\n\u0026gt;function suona(song) \u0026gt;\u0026gt;print(‚ÄúStiamo suonando‚Äù,song) \u0026gt;\u0026gt;end \u0026gt;band.playfunc=suona ","permalink":"https://ilmanzo.github.io/post/il-linguaggio-lua-04/","summary":"segue dalla terza parte\n‚ÄúMoonlight Bay‚Äù (ovvero: ‚Äúchiedi chi erano i vectors‚Äù) L\u0026rsquo;unica struttura dati disponibile in Lua √® rappresentata dagli array o meglio, dalle tabelle (o hash): array associativi formati da coppie chiave-valore, nelle quali sia la chiave sia il valore possono essere qualsiasi tipo di dato. Vediamo un paio di esempi, dapprima un normale vettore:\n\u0026gt; i = 3 \u0026gt; a = {1,3,5,7,9} \u0026gt; print(i,a[3],a[4],a[i+3]) questa sequenza stampa i valori 3,5,7,nil; la prima cosa che appare diversa rispetto ad un altro linguaggio √® che gli indici per gli array partono da 1 anzich√© da zero; la seconda √® che un eventuale sforamento dell\u0026rsquo;array non causa errore ma semplicemente ritorna nil.","title":"il linguaggio Lua: parte 4"},{"content":"segue dalla seconda parte\nChe fai tu luna in ciel ? : le funzioni Fino a che scriviamo script di poche righe, possiamo inserire le istruzioni nel programma principale, ma aumentando la complessit√† diventa necessario organizzare il codice in pezzi indipendenti e riutilizzabili; come in tutti gli altri linguaggi, in Lua √® possibile definire funzioni; vediamo un esempio piuttosto classico:\nfunction fattoriale(n) local f=1 -- variabile locale alla funzione for i=2,n do f=f*i end return f Abbiamo definito la funzione fattoriale, che da ora in avanti possiamo richiamare nel nostro codice:\nprint(fattoriale(10)) Notiamo che la variabile f ha il prefisso local: questo perch√© per default in Lua le variabili sono globali se non viene esplicitato diversamente. Vediamo un esempio:\npippo,pluto=1,2 function func() pippo=3 local pluto=4 end func() print(pippo,pluto) stamper√† 3,2, perch√© il valore di \u0026lsquo;pippo\u0026rsquo; √® stato sovrascritto dentro la funzione, in quanto ogni variabile non dichiarata esplicitamente local ha visibilit√† globale. Fanno eccezione gli iteratori dei cicli:\ni=10 for i=1,3 do print(i) end print(i) 1 2 3 10 in conclusione: nelle funzioni conviene sempre dichiarare le variabili \u0026rsquo;local\u0026rsquo;, a meno che non sappiate esattamente cosa state facendo!\nPer i pi√π virtuosi, divertiamoci a scrivere il fattoriale in maniera ricorsiva:\nfunction fattorialeR(n) if n==0 then return 1 else return n*fattorialeR(n-1) end end Questo tipo di ricorsione (tail recursion) √® implementata in maniera efficiente in Lua, in quanto il compilatore provvede ad ottimizzare le chiamate in modo da non utilizzare spazio nello stack.\nUna funzione √® anche un tipo di dato, ovvero √® possibile ottenere riferimenti a funzioni e utilizzarli associandoli a variabili. Potremmo scrivere ad esempio:\nfunc=fattoriale if recurse then func=fattorialeR print(func(10)) che utilizza la versione ricorsiva o iterativa a seconda di una scelta operata in precedenza. Come conseguenza, possiamo scrivere funzioni che ritornano funzioni:\nfunction makeIncr(x) local i=x return function() i=i+1 return i end end dieci=makeIncr(10) cento=makeIncr(100) for i=1,5 do print(dieci(),cento()) end Non √® necessario capire immediatamente l\u0026rsquo;utilit√† di costrutti avanzati come questo\u0026hellip; Basti dire che sono la base della programmazione funzionale e del concetto di coroutine in Lua. Notiamo infatti che ciascuna delle due funzioni \u0026lsquo;mantiene\u0026rsquo; il proprio stato (in questo caso il contatore) indipendentemente, pur essendo generate dalla stessa \u0026lsquo;madre\u0026rsquo;.\n","permalink":"https://ilmanzo.github.io/post/il-linguaggio-lua-03/","summary":"segue dalla seconda parte\nChe fai tu luna in ciel ? : le funzioni Fino a che scriviamo script di poche righe, possiamo inserire le istruzioni nel programma principale, ma aumentando la complessit√† diventa necessario organizzare il codice in pezzi indipendenti e riutilizzabili; come in tutti gli altri linguaggi, in Lua √® possibile definire funzioni; vediamo un esempio piuttosto classico:\nfunction fattoriale(n) local f=1 -- variabile locale alla funzione for i=2,n do f=f*i end return f Abbiamo definito la funzione fattoriale, che da ora in avanti possiamo richiamare nel nostro codice:","title":"il linguaggio Lua: parte 3"},{"content":"I have a binary file with data stored as two-byte big-endian 16-bit words. We need to extract the values in the file and print them in decimal ASCII format, so to obtain numbers in the 0-655535 range.\nlet\u0026rsquo;s create the sample file:\n$ echo -en \u0026#34;\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\u0026#34; \u0026gt; file.bin and show its content in binary form:\n$ hexdump -C file.bin 00000000 01 02 03 04 05 06 07 08 |........| 00000008 to get the desired output we can use the powerful, but little documented format string option of hexdump:\n$ hexdump -e \u0026#39;/2 \u0026#34;%d\\n\u0026#34;\u0026#39; file.bin 513 1027 1541 2055 also see more on https://www.suse.com/communities/blog/making-sense-hexdump/\n","permalink":"https://ilmanzo.github.io/post/hexdump-for-binary-file-manipulation/","summary":"I have a binary file with data stored as two-byte big-endian 16-bit words. We need to extract the values in the file and print them in decimal ASCII format, so to obtain numbers in the 0-655535 range.\nlet\u0026rsquo;s create the sample file:\n$ echo -en \u0026#34;\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\u0026#34; \u0026gt; file.bin and show its content in binary form:\n$ hexdump -C file.bin 00000000 01 02 03 04 05 06 07 08 |........| 00000008 to get the desired output we can use the powerful, but little documented format string option of hexdump:","title":"convert a binary file to ascii using hexdump"},{"content":"I\u0026rsquo;ve started experimenting with the Crystal Programming Language. It\u0026rsquo;s a nice and clean language with syntax similar to Ruby, but compiled to fast native code, and a lot of clever ideas, like union types and seamless C integration The project is still in early stages, but it\u0026rsquo;s promising.\nJust to see how easy, I ported a small python library to Crystal, you can find it on https://github.com/ilmanzo/spark. I hope to find the time to improve on it!\n","permalink":"https://ilmanzo.github.io/post/playing-with-crystal-programming-language/","summary":"I\u0026rsquo;ve started experimenting with the Crystal Programming Language. It\u0026rsquo;s a nice and clean language with syntax similar to Ruby, but compiled to fast native code, and a lot of clever ideas, like union types and seamless C integration The project is still in early stages, but it\u0026rsquo;s promising.\nJust to see how easy, I ported a small python library to Crystal, you can find it on https://github.com/ilmanzo/spark. I hope to find the time to improve on it!","title":"playing with Crystal Programming Language"},{"content":"This is an example of using goproxy, a fast and robust multithread proxy engine to develop an HTTP proxy that rewrites content on the fly, with multiple search and substitutions. It can be useful for debugging and other less noble (but useful) purposes \u0026hellip;\n// rewriting_proxy project main.go package main import ( \u0026#34;bytes\u0026#34; \u0026#34;flag\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;github.com/elazarl/goproxy\u0026#34; ) var replacements = []struct { from []byte to []byte }{ {[]byte(\u0026#34;#e8ecec\u0026#34;), []byte(\u0026#34;Red\u0026#34;)}, // ugly colors!! {[]byte(\u0026#34;Comic Sans MS\u0026#34;), []byte(\u0026#34;Lucida Sans Unicode\u0026#34;)}, // for eyes sanity {[]byte(\u0026#34;Java \u0026#34;), []byte(\u0026#34;Golang \u0026#34;)}, // just joking } func myHandler(resp *http.Response, ctx *goproxy.ProxyCtx) *http.Response { readBody, err := ioutil.ReadAll(resp.Body) if err != nil { //TODO handle read error gracefully return resp } resp.Body.Close() for _, elem := range replacements { readBody = bytes.Replace(readBody, elem.from, elem.to, -1) } resp.Body = ioutil.NopCloser(bytes.NewReader(readBody)) return resp } func main() { verbose := flag.Bool(\u0026#34;v\u0026#34;, true, \u0026#34;should every proxy request be logged to stdout\u0026#34;) proxy := goproxy.NewProxyHttpServer() proxy.Verbose = *verbose proxy.OnResponse().DoFunc(myHandler) log.Fatal(http.ListenAndServe(\u0026#34;:8081\u0026#34;, proxy)) } ","permalink":"https://ilmanzo.github.io/post/a-simple-http-rewriting-proxy/","summary":"This is an example of using goproxy, a fast and robust multithread proxy engine to develop an HTTP proxy that rewrites content on the fly, with multiple search and substitutions. It can be useful for debugging and other less noble (but useful) purposes \u0026hellip;\n// rewriting_proxy project main.go package main import ( \u0026#34;bytes\u0026#34; \u0026#34;flag\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;github.com/elazarl/goproxy\u0026#34; ) var replacements = []struct { from []byte to []byte }{ {[]byte(\u0026#34;#e8ecec\u0026#34;), []byte(\u0026#34;Red\u0026#34;)}, // ugly colors!","title":"a simple HTTP rewriting proxy"},{"content":"This is a quick and dirty way to interface C++ code with Python, translating one or more C++ classes in Python objects.\nFirst, we need some c++ sample code:\n//myclass.h #ifndef MYCLASS_H #define MYCLASS_H #include \u0026lt;string\u0026gt; using namespace std; namespace pets { class Dog { public: Dog(string name, int age); virtual ~Dog(); string talk(); protected: string m_name; int m_age; }; } //myclass.cpp #include \u0026#34;myclass.h\u0026#34; #include \u0026lt;string\u0026gt; namespace pets { Dog::Dog(std::string name, int age): m_name(name),m_age(age) { } Dog::~Dog() { } std::string Dog::talk() { return \u0026#34;BARK! I am a DOG and my name is \u0026#34;+m_name; } } now, we can try a little test program just to exercise our class:\n#include \u0026lt;iostream\u0026gt; #include \u0026#34;myclass.h\u0026#34; using namespace std; int main() { pets::Dog dog(\u0026#34;Charlie\u0026#34;,3); cout \u0026lt;\u0026lt; dog.talk() \u0026lt;\u0026lt; endl; } compile and run:\ng++ myprog.cpp myclass.cpp -o myprog ; ./myprog To use the Dog class from Python, we can create a wrapper using Cython.\nCython is a programming language that makes writing C extensions for the Python language as easy as Python itself. It aims to become a superset of the Python language which gives it high-level, object-oriented, functional, and dynamic programming. Its main feature on top of these is support for optional static type declarations as part of the language. The source code gets translated into optimized C/C++ code and compiled as Python extension modules. This allows for both very fast program execution and tight integration with external C libraries, while keeping up the high programmer productivity for which the Python language is well known.\nSo this is the \u0026ldquo;C++ to python\u0026rdquo; (Cython) wrapper glue code:\n#pets.pyx from libcpp.string cimport string cdef extern from \u0026#34;myclass.h\u0026#34; namespace \u0026#34;pets\u0026#34;: cppclass Dog: Dog(string, int) string talk() cdef class PyDog: cdef Dog* c_dog #Cython class holds a c++ \u0026#34;Dog\u0026#34; instance def __cinit__(self, string name, int age): pyname=\u0026lt;bytes\u0026gt;name self.c_dog=new Dog(pyname,age) def __dealloc__(self): del self.c_dog def talk(self): return self.c_dog.talk() we can also write a setup script in oreder to provide an easy and smooth compilation/install process:\n#setup.py from distutils.core import setup from distutils.extension import Extension from Cython.Build import cythonize extensions = [ Extension(\u0026#34;pets\u0026#34;, [\u0026#34;pets.pyx\u0026#34;,\u0026#34;myclass.cpp\u0026#34;], language=\u0026#34;c++\u0026#34;), ] setup( name = \u0026#39;test_pets\u0026#39;, ext_modules = cythonize(extensions) ) using this, to compile all the code in a single shared library, the user can run:\npython3 setup.py build_ext --inplace After this step, we have under current directory a new file with a .so extension, and we can finally use this shared library as a Python module:\nimport pets dog1=pets.PyDog(b\u0026#34;Max\u0026#34;,5) print(dog1.talk()) notice that under the hood a lot of \u0026ldquo;automagic\u0026rdquo; type conversions does happen; Cython for example is able to translate between standard C++ enumerable classes and Python tuples. More information of course is available in the official documentation\n","permalink":"https://ilmanzo.github.io/post/wrapping-c-plus-plus-classes-in-python/","summary":"This is a quick and dirty way to interface C++ code with Python, translating one or more C++ classes in Python objects.\nFirst, we need some c++ sample code:\n//myclass.h #ifndef MYCLASS_H #define MYCLASS_H #include \u0026lt;string\u0026gt; using namespace std; namespace pets { class Dog { public: Dog(string name, int age); virtual ~Dog(); string talk(); protected: string m_name; int m_age; }; } //myclass.cpp #include \u0026#34;myclass.h\u0026#34; #include \u0026lt;string\u0026gt; namespace pets { Dog::Dog(std::string name, int age): m_name(name),m_age(age) { } Dog::~Dog() { } std::string Dog::talk() { return \u0026#34;BARK!","title":"wrapping c plus plus classes in Python"},{"content":"segue dalla prima parte\nMoonwalking: Tipi di dato Nello scorsa puntata abbiamo utilizzato due degli otto tipi disponibili: i numeri e le stringhe. Per semplicita\u0026rsquo;, Lua non distingue tra interi e floating point: tutti i valori numerici sono conservati come double, cioe\u0026rsquo; in virgola mobile a doppia precisione. Nel caso la CPU non disponesse di unita\u0026rsquo; FPU, √® possibile cambiare una riga nel sorgente (per l\u0026rsquo;esattezza, #define LUA_NUMBER in lua.h) e ricompilare; questo si fa tipicamente nei sistemi embedded con processori a basse prestazioni. Le stringhe posso essere delimitate da apici singoli o doppi, nel qual caso vengono espanse le usuali sequenze di escape come \\b e \\n; usando invece i delimitatori [[ ]], possiamo scrivere stringhe su piu\u0026rsquo; righe e disattivare l\u0026rsquo;interpolazione. Vediamo un paio di esempi, sfruttando l\u0026rsquo;opzione -e per eseguire codice da riga di comando:\n$ lua -e \u0026#39;print(\u0026#34;questo va\\n a capo\u0026#34;)\u0026#39; questo va a capo $ lua -e \u0026#39;print([[questo \\n invece no]])\u0026#39; questo \\n invece no La funzione built-in print √® piuttosto povera nella formattazione, se volessimo qualcosa di pi√π complesso dovremmo ricorrere alla libreria string.format, ma andiamo con ordine. Attenzione: Lua converte stringhe numeriche in numeri dove ci√≤ abbia senso, quindi √® lecito fare\n$ lua \u0026gt;a=‚Äù3‚Äù+1 \u0026gt;b=2+2 \u0026gt;print(a,b,a==b) 4 4 true Mentre una riga come\n\u0026gt;a=‚Äù3‚Äù+‚Äùx‚Äù causa un errore di sintassi: per concatenare due stringhe usiamo l\u0026rsquo;operatore doppio punto:\n\u0026gt; print(‚Äúciao‚Äù..‚Äùmondo‚Äù). (da ora in avanti omettero\u0026rsquo; l\u0026rsquo;invocazione dell\u0026rsquo;interprete e indicher√≤ con il prompt \u0026gt; dove scrivere le istruzioni Lua). Proseguiamo con l\u0026rsquo;analisi del tipo di dato boolean, che pu√≤ assumere esclusivamente i valori true e false e a cui sono associati gli operatori logici and, or, not e che, come possiamo immaginare, viene usato specialmente nelle istruzioni condizionali:\nif \u0026lt;expr\u0026gt; then \u0026lt;blocco\u0026gt; end if \u0026lt;expr\u0026gt; then \u0026lt;blocco1\u0026gt; else \u0026lt;blocco2\u0026gt; end dove \u0026lt;expr\u0026gt; indica una qualsiasi espressione che restituisca un risultato booleano, mentre \u0026lt;blocco\u0026gt; sono le istruzioni che vengono o meno eseguite. Gi√† che parliamo di costrutti di controllo, citiamo anche i classici loop:\nwhile \u0026lt;expr\u0026gt; do \u0026lt;blocco\u0026gt; end repeat \u0026lt;blocco\u0026gt; until \u0026lt;expr\u0026gt; rispettivamente, ripetono il \u0026lt;blocco\u0026gt; finch√© la condizione \u0026lt;expr\u0026gt; √® vera (nel while..do) o falsa (repeat..until). Per terminare anzitempo un ciclo si pu√≤ usare nel blocco l\u0026rsquo;istruzione break:\nn=43 repeat if n%2==0 then n=n/2 else n=n*3+1 end print(n) until n==1 Un altro tipo che si usa spesso nelle condizioni √® nil: esso rappresenta l\u0026rsquo;assenza di un valore (ad esempio una variabile non ancora inizializzata). Attenzione perch√© nil √® considerato false, ma qualsiasi valore non nil √® true , compresi quindi il numero zero, le stringhe vuote e gli array senza elementi:\n-- questo √® un commento -- inizia lo script3.lua if not v then print \u0026#34;variabile \u0026#39;v\u0026#39; non dichiarata\u0026#34; end --[[ questo √® un commento su pi√π righe il prossimo test non funziona come ci aspettiamo --]] s=\u0026#39;\u0026#39; -- stringa vuota print \u0026#34;primo test\u0026#34; if not s then -- questa condizione non si verifica print \u0026#34;stringa vuota\u0026#34; end print \u0026#34;secondo test\u0026#34; if #s==0 then print \u0026#34;stringa vuota\u0026#34; end if s~=\u0026#39;\u0026#39; then print \u0026#34;stringa non vuota\u0026#34; end questo pezzo di codice, oltre a mostrare lo stile per i commenti, non funziona come ci aspettiamo: all\u0026rsquo;inizio v vale nil, perci√≤ otteniamo il primo output, mentre il test sulla variabile s non fa scattare la condizione: per controllare la lunghezza di una stringa o di un array in Lua c\u0026rsquo;√® l\u0026rsquo;apposito operatore #. Nell\u0026rsquo;esempio notiamo anche la particolare sintassi per esprimere la condizione ‚Äúdiverso da‚Äù.\n","permalink":"https://ilmanzo.github.io/post/il-linguaggio-lua-02/","summary":"segue dalla prima parte\nMoonwalking: Tipi di dato Nello scorsa puntata abbiamo utilizzato due degli otto tipi disponibili: i numeri e le stringhe. Per semplicita\u0026rsquo;, Lua non distingue tra interi e floating point: tutti i valori numerici sono conservati come double, cioe\u0026rsquo; in virgola mobile a doppia precisione. Nel caso la CPU non disponesse di unita\u0026rsquo; FPU, √® possibile cambiare una riga nel sorgente (per l\u0026rsquo;esattezza, #define LUA_NUMBER in lua.h) e ricompilare; questo si fa tipicamente nei sistemi embedded con processori a basse prestazioni.","title":"il linguaggio Lua: parte 2"},{"content":"the issue we have a database table containing usernames and passwords, but we want to make them temporary like expiring after a fixed number of days from the creation. This is typical usage for a wi-fi captive portal with RADIUS authentication backed on mysql.\nthe idea we store a new field in the table with the timestamp, and run a periodic \u0026ldquo;cleaner\u0026rdquo; job that deletes record older than X days.\nwe can leverage the mysql event scheduler in order to provide a self-contained solution, indipendent from operating system.\nthe implementation alter table radcheck add column ts_create TIMESTAMP DEFAULT CURRENT_TIMESTAMP; CREATE EVENT expireuser ON SCHEDULE EVERY 12 HOUR DO DELETE FROM radcheck WHERE TIMESTAMPDIFF(DAY, ts_create , NOW()) \u0026gt; 7 ; to get it started, make sure you have enabled the event scheduler:\nSET GLOBAL event_scheduler = ON; or by placing\nevent_scheduler=ON in your my.cnf, section [mysqld]\n","permalink":"https://ilmanzo.github.io/post/automatic-expiring-of-mysql-rows/","summary":"the issue we have a database table containing usernames and passwords, but we want to make them temporary like expiring after a fixed number of days from the creation. This is typical usage for a wi-fi captive portal with RADIUS authentication backed on mysql.\nthe idea we store a new field in the table with the timestamp, and run a periodic \u0026ldquo;cleaner\u0026rdquo; job that deletes record older than X days.","title":"how to automatically expire mysql records after a fixed amount of time"},{"content":"introduzione Ho sempre avuto un debole per il software leggero e snello: sara\u0026rsquo; un retaggio di quando la memoria si misurava in Kb e lo storage era basato su\u0026hellip; audiocassette! Lua e\u0026rsquo; un linguaggio che incarna questa filosofia: occupa circa un centinaio di kbyte (meno di molte pagine web), ha una stupefacente rapidita\u0026rsquo; di esecuzione, una sintassi chiara e, come bonus, gira su qualsiasi CPU per cui sia disponibile un compilatore C.\n\u0026lsquo;Dalla terra alla luna\u0026rsquo;, ovvero breve storia di Lua Per capire da dove viene questo gioiellino, facciamo qualche passo indietro nel tempo\u0026hellip;\nNel 1992, all\u0026rsquo;universita\u0026rsquo; cattolica pontificia di Rio de Janeiro, un gruppo specializzato in computer graphics chiamato Tecgraf sta sviluppando interfacce interattive nel settore dell\u0026rsquo;elaborazione dati per l\u0026rsquo;industria petrolifera.\nTra il 1977 ed il 1992 il Brasile attraversa un difficile periodo di embargo politico e difficolta\u0026rsquo; economiche, percio\u0026rsquo; spesso per istituti ed enti non √® possibile comprare all\u0026rsquo;estero pacchetti software aggiornati o personalizzati, l\u0026rsquo;unica soluzione e\u0026rsquo; fabbricarsi gli strumenti \u0026ldquo;in casa\u0026rdquo;.\nAllo scopo di aggiungere un minimo di flessibilita\u0026rsquo; ad alcune procedure, nacquero quindi SOL (Simple Object Language) e DEL (Data Entry Language). Ebbero un discreto successo nel settore, ma dato che non avevano strutture di controllo e l\u0026rsquo;azienda committente richiedeva maggiore capacita\u0026rsquo; di intervento, nacque l\u0026rsquo;esigenza di utilizzare un linguaggio unificato e completo, ma abbastanza semplice da essere alla portata anche di tecnici senza grandi conoscenze di programmazione.\nAl tempo l\u0026rsquo;unico candidato era Tcl (Python era ancora immaturo), ma aveva una sintassi poco familiare e soprattutto girava solo sulle costose workstation UNIX. Roberto Lerusalimschy, Luiz Henrique de Figueiredo e Waldemar Celes avevano bisogno di un linguaggio portabile, semplice e facile da integrare: nel 1993 nasce Lua che, attraverso varie revisioni e aggiustamenti anche sostanziali, arriva ai giorni nostri.\nIl progetto ormai e\u0026rsquo; piuttosto stabile: Lua 4.0 fu rilasciato nel 2000 e presentava praticamente le stesse caratteristiche della versione che conosciamo ed installiamo oggi.\nEssendo nato come linguaggio ausiliario (o, meglio, satellite), Lua e\u0026rsquo; ideale per aggiungere capacita\u0026rsquo; di scripting in grossi progetti. Benche\u0026rsquo; sia nato in un\u0026rsquo;universita\u0026rsquo;, √® tutto fuorche\u0026rsquo; un linguaggio accademico, pieno di feature o utilizzato solo da chi scrive trattati teorici: Lua punta alla sostanza e lo si vede gi√† dalla licenza (MIT) con cui e\u0026rsquo; distribuito, la stessa di software diffusi come X Window System, Ruby on Rails e Mono.\n\u0026rsquo;lo stolto guarda il dito\u0026rsquo; Ovviamente la prima domanda che vi frullera\u0026rsquo; in testa sara\u0026rsquo;: perch√© dovrei usare Lua e non Perl o Ruby o Tcl o Python o Javascript o PHP? Ecco 7 motivi:\nLua e\u0026rsquo; molto piccolo: basta linkare al progetto una libreria di 150kb. Altri linguaggi hanno esigenze ben diverse;\ne\u0026rsquo; secure by default: l\u0026rsquo;interprete gira in una sandbox e gli unici punti di contatto con l\u0026rsquo;applicazione principale sono quelli che decidiamo noi. Persino le istruzioni di I/O (inclusa la print) sono opzionali;\n√® velocissimo: nei benchmark batte qualsiasi linguaggio interpretato e la versione Just-In-Time e\u0026rsquo; paragonabile a quelli compilati;\ne\u0026rsquo; semplice: la sintassi conta una ventina di operatori ed altrettante parole chiave, puo\u0026rsquo; impararlo facilmente anche chi non sviluppa per professione;\ne\u0026rsquo; flessibile: ha tipizzazione dinamica, e\u0026rsquo; facile da integrare con librerie esterne e, disponendo di un ampio parco di utilizzatori, troviamo disponibili sulla rete moduli per praticamente qualsiasi esigenza (per avere un\u0026rsquo;idea visitiamo http://luaforge.net;\ne\u0026rsquo; open source e, grazie alla permissiva licenza MIT, non c\u0026rsquo;e\u0026rsquo; nessun problema ad includerne versioni modificate nei vostri progetti senza dover per forza rilasciare i sorgenti;\ne\u0026rsquo; maturo e stabile (ha quasi vent\u0026rsquo;anni di storia), ma e\u0026rsquo; anche moderno, tecnicamente parlando: Lua ha un garbage collector mark-and-sweep, che funziona in modo incrementale. Ha caratteristiche dei linguaggi funzionali come closure lessicali e ottimizza le tail calls. Come vedremo, le funzioni sono tipi di prima classe.\nVi ho convinti? E allora andiamo avanti al passo successivo.\n\u0026lsquo;Fly me to the moon\u0026rsquo; ovvero: installazione Data la sua diffusione, ci sono grandi probabilita\u0026rsquo; che nel nostro PC Lua sia gia\u0026rsquo; installato, ma per levarci lo sfizio, sulla classica Debian/Ubuntu basta un:\n$ sudo apt-get install lua5.2 luajit luajit e\u0026rsquo; la versione turbo, che esegue gli stessi programmi, ma con una tecnica diversa: trasla le istruzioni in codice macchina nativo con risultati eccellenti. Per chi preferisse usare i sorgenti, e\u0026rsquo; sufficiente scaricare e scompattare un tarball:\n$ curl http://www.lua.org/ftp/lua-5.3.2.tar.gz | tar xz per poi compilare per piattaforma Linux ed installare come superuser i binari ottenuti:\n$ cd lua-5.3.2 ; make linux \u0026amp;\u0026amp; sudo make install Una volta installato il software, proviamo a scrivere il nostro primo programma Lua! Eseguiamo l\u0026rsquo;interprete interattivo a linea di comando, una specie di lua shell:\n$ lua subito dopo vedremo una riga con le informazioni di rito; al prompt che appare scriviamo:\n\u0026gt; print \u0026#34;Hello, World!\u0026#34; il risultato e\u0026rsquo; quello che ci aspettiamo. Non e\u0026rsquo; un granche\u0026rsquo; come programma\u0026hellip; Ma tutti i grandi hanno iniziato in questo modo! Per uscire, basta un CTRL-C o CTRL-D. Facciamo un passo avanti e scriviamo uno script vero e proprio. Apriamo un editor di testo e digitiamo queste righe:\nfor i=1,10 do print(\u0026#34;ciclo numero\u0026#34;,i) end salviamo come script1.lua e possiamo eseguirlo da shell:\n$ lua script1.lua Da questo esempio impariamo la sintassi del ciclo for \u0026rsquo;numerico\u0026rsquo; ed osserviamo che nelle chiamate a funzione (print e\u0026rsquo; una funzione della libreria di sistema) se ci sono piu\u0026rsquo; parametri dobbiamo usare le parentesi tonde per delimitare gli argomenti. A tal proposito possiamo consultare la FAQ.\nLua permette anche la precompilazione: se vogliamo evitare di distribuire i sorgenti, possiamo conservare sul disco solo la versione bytecode del nostro programma; invocando Lua Compiler:\n$ luac -o script1.luac script1.lua troveremo nella directory un nuovo file binario; lo possiamo eseguire allo stesso modo del precedente:\n$ lua script1.luac e ovviamente otteniamo gli stessi risultati. Potremmo anche usare l\u0026rsquo;opzione -s per rimuovere i simboli di debug dal compilato.\nOra che il linguaggio e\u0026rsquo; installato e funzionante, cominceremo ad approfondirne i dettagli; questo non potra\u0026rsquo; essere un \u0026ldquo;corso di programmazione Lua\u0026rdquo; completo, ma cercheremo di evidenziare gli aspetti principali, rimandando alla documentazione ufficiale per gli indispensabili approfondimenti.\n","permalink":"https://ilmanzo.github.io/post/il-linguaggio-lua-01/","summary":"introduzione Ho sempre avuto un debole per il software leggero e snello: sara\u0026rsquo; un retaggio di quando la memoria si misurava in Kb e lo storage era basato su\u0026hellip; audiocassette! Lua e\u0026rsquo; un linguaggio che incarna questa filosofia: occupa circa un centinaio di kbyte (meno di molte pagine web), ha una stupefacente rapidita\u0026rsquo; di esecuzione, una sintassi chiara e, come bonus, gira su qualsiasi CPU per cui sia disponibile un compilatore C.","title":"il linguaggio Lua: prima parte"},{"content":"I want to keep under control a system where each user has an amount of filesystem quota reserved; in particular I would like to get notified if and when a user exceeds some treshold. Since I already have Monit in place in the server, I took the chance to write a small Go utility in order to retrieve the quota percentage.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 // quotachecker.go package main import ( \u0026#34;os\u0026#34; \u0026#34;os/exec\u0026#34; \u0026#34;regexp\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;strings\u0026#34; ) func main() { //a fake implementation, just for testing purpose //cmd := exec.Command(\u0026#34;/bin/sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;cat fakequota.txt\u0026#34;) cmd := exec.Command(\u0026#34;/usr/bin/repquota\u0026#34;, \u0026#34;-a\u0026#34;) stdout, err := cmd.Output() if err != nil { panic(err.Error()) } re, err := regexp.Compile(\u0026#34;^[[:alnum:]]+\\\\s+--\\\\s+\\\\d+\\\\s+\\\\d+\u0026#34;) if err != nil { panic(err.Error()) } percent_max := 0 result := strings.Split(string(stdout), \u0026#34;\\n\u0026#34;) for _, line := range result { match := re.MatchString(line) if !match { continue } fields := strings.Fields(line) spaceused, err := strconv.ParseInt(fields[2], 10, 64) if err != nil { panic(err.Error()) } spacetotal, err := strconv.ParseInt(fields[4], 10, 64) if err != nil { panic(err.Error()) } if spacetotal == 0 { continue } //calculate max percent used percent := int(100 * spaceused / spacetotal) if percent \u0026gt; percent_max { percent_max = int(percent) } } os.Exit(percent_max) } This is also an example on how to run external programs in Go and filter the output using regular expressions.\nOnce compiled with go build , you can use this program (without any extra dependencies) in a Monit config file, like this:\ncheck program quota with path /usr/local/bin/quotachecker if status \u0026gt; 90 for 5 cycles then alert and you will be alerted if any user exceed 90% of his quota on disk.\n","permalink":"https://ilmanzo.github.io/post/golang-quota-monit-helper/","summary":"I want to keep under control a system where each user has an amount of filesystem quota reserved; in particular I would like to get notified if and when a user exceeds some treshold. Since I already have Monit in place in the server, I took the chance to write a small Go utility in order to retrieve the quota percentage.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 // quotachecker.","title":"monit helper for quota monitoring in go"},{"content":"Recently I have been in a situation where I needed a simple \u0026lsquo;batch\u0026rsquo; job scheduler, where I could submit some long-running tasks to a server and have a \u0026lsquo;system\u0026rsquo; that serialize access the execution with some basic job control facilities (remove a job from the queue, stop the processing, and so on).\nLinux printing subsystem is already designed to do this, and we can exploit the CUPS printing subsystem to run our \u0026ldquo;batch\u0026rdquo; jobs.\nIn practice we need to create a \u0026ldquo;fake\u0026rdquo; printer who outputs to /dev/null, but when invoked its real job is executed in an \u0026ldquo;interface script\u0026rdquo; that is the real data manager. An example could be a script like this:\n#!/bin/sh # save this as file script.txt # this script replaces every occurrence of \u0026#34;apple\u0026#34; with \u0026#34;banana\u0026#34; inside a text file job=\u0026#34;$1\u0026#34; user=\u0026#34;$2\u0026#34; title=\u0026#34;$3\u0026#34; numcopies=\u0026#34;$4\u0026#34; options=\u0026#34;$5\u0026#34; filename=\u0026#34;$6\u0026#34; /usr/bin/logger \u0026#34;starting script, got parameters: $1^$2^$3^$4^$5^$6\u0026#34; /bin/sed s/apple/banana/g $filename \u0026gt; /var/spool/lpd/fixed_$title /usr/bin/logger \u0026#34;ending script\u0026#34; to install this , we need to feed it to a new dummy definition:\nlpadmin -p converter -E -iscript.txt -vfile:/dev/null if we make some mistakes in the script, don\u0026rsquo;t forget to remove the printer before redefining it:\nlpadmin -x converter to test it, we prepare a simple text file:\n$ cat minion.txt I like apples I like apples very much More apples!! then we can \u0026ldquo;print\u0026rdquo; it with our new printer, making the script run doing it business\u0026hellip;\n$ lp -d converter minion.txt request id is converter-28 (1 file(s)) \u0026hellip;and inspect the output:\n$ cat /var/spool/lpd/fixed_minion.txt I like bananas I like bananas very much More bananas!! to inspect the queue, we can use the standard commands:\nlpstat -o # to check current running jobs lpstat -W completed # to check past jobs already finished to remove a job from the queue,\ncancel [id] converter cancel -a converter with this technique, you can easily prepare fake printers that manages AVI conversion, mp3 playing, ftp file upload\u0026hellip; And any kind of long running task you can think about\u0026hellip;\nEnjoy!\n","permalink":"https://ilmanzo.github.io/post/simple-easy-job-queue-linux/","summary":"Recently I have been in a situation where I needed a simple \u0026lsquo;batch\u0026rsquo; job scheduler, where I could submit some long-running tasks to a server and have a \u0026lsquo;system\u0026rsquo; that serialize access the execution with some basic job control facilities (remove a job from the queue, stop the processing, and so on).\nLinux printing subsystem is already designed to do this, and we can exploit the CUPS printing subsystem to run our \u0026ldquo;batch\u0026rdquo; jobs.","title":"simple and easy linux job queue"},{"content":"Pubblico qui le slide che ho usato durante la serata dedicata alla programmazione Python, svoltasi presso il FabLab Verona\nhttp://ilmanzo.github.io/files/slide_serata_python_fablab_2015.html\n","permalink":"https://ilmanzo.github.io/post/serata-fablab/","summary":"Pubblico qui le slide che ho usato durante la serata dedicata alla programmazione Python, svoltasi presso il FabLab Verona\nhttp://ilmanzo.github.io/files/slide_serata_python_fablab_2015.html","title":"serata introduttiva al FabLab sulla programmazione Python"},{"content":"Following with the GO standard library exploration, I\u0026rsquo;ve written a toy example for using the CGI features. Native GoLang CGI web applications are very fast and can be useful for example in embedded systems, or in cheap web hosting where is not possible to run custom HTTP servers. The solution has some weak points, starting from lock management, but is only presented as a proof of concept and not for real use cases.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 //save this as todoapp.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;html/template\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;net/http/cgi\u0026#34; \u0026#34;strings\u0026#34; ) const datafile = \u0026#34;/tmp/todos.txt\u0026#34; const templatefile = \u0026#34;/data/templates/page.gtpl\u0026#34; const htmlheader = \u0026#34;text/html; charset=utf-8\u0026#34; func CGIHandler(rw http.ResponseWriter, req *http.Request) { type ViewData struct { Todos []string DisplayTodos bool } viewdata := ViewData{} check(req.ParseForm(),\u0026#34;parsing form\u0026#34;) // load data from file to array string content, err := ioutil.ReadFile(datafile) check(err,\u0026#34;reading data file:\u0026#34;) viewdata.Todos = strings.Split(string(content), \u0026#34;\\n\u0026#34;) viewdata.DisplayTodos = (len(viewdata.Todos) \u0026gt; 0) if len(req.Form[\u0026#34;entry\u0026#34;]) \u0026gt; 0 { // request coming from submit: append to the stored list viewdata.Todos = append(viewdata.Todos, req.Form[\u0026#34;entry\u0026#34;][0]) data := strings.Join(viewdata.Todos, \u0026#34;\\n\u0026#34;) // save current array string to disk. TODO: locking!! err := ioutil.WriteFile(datafile, []byte(data), 0644) check(err,\u0026#34;writing data file\u0026#34;) } header := rw.Header() header.Set(\u0026#34;Content-Type\u0026#34;, htmlheader) t, err := template.ParseFiles(templatefile) check(err,\u0026#34;parsing template\u0026#34;) err = t.Execute(rw, viewdata) check(err,\u0026#34;executing template\u0026#34;) } func check(err error, msg string) { if err != nil { log.Fatal(msg,err) } } func main() { err := cgi.Serve(http.HandlerFunc(CGIHandler)) check(err,\u0026#34;cannot serve request\u0026#34;) } following, the template: a simple form that displays the data and send back a POST request to the CGI.\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;my todo list\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;my TODO list\u0026lt;/h1\u0026gt; {{ if .DisplayTodos }} \u0026lt;ul\u0026gt; {{ range $index,$item := .Todos }} \u0026lt;li\u0026gt; {{ $index }} {{ $item }} \u0026lt;/li\u0026gt; {{ end }} \u0026lt;/ul\u0026gt; {{ end }} \u0026lt;form action=\u0026#34;/todoapp\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;entry\u0026#34; size=\u0026#34;25\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; name=\u0026#34;submit\u0026#34; value=\u0026#34;New TODO\u0026#34;\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; the template should be saved in a folder reachable by the CGI app (see from the source: /data/templates/page.gtpl)\n","permalink":"https://ilmanzo.github.io/post/cgi-apps-in-go/","summary":"Following with the GO standard library exploration, I\u0026rsquo;ve written a toy example for using the CGI features. Native GoLang CGI web applications are very fast and can be useful for example in embedded systems, or in cheap web hosting where is not possible to run custom HTTP servers. The solution has some weak points, starting from lock management, but is only presented as a proof of concept and not for real use cases.","title":"CGI with the Go Programming Language"},{"content":"The GO programming language has a nice and useful standard library, which includes a powerful templating engine out of the box.\nHere I wrote an example, generating HTML output from a simple data structure.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 package main import ( \u0026#34;html/template\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; ) func main() { page := ` \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt;\u0026lt;head\u0026gt;\u0026lt;title\u0026gt;my todo list\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt;\u0026lt;h1\u0026gt;my TODO list\u0026lt;/h1\u0026gt; \u0026lt;ul\u0026gt; {{ range $item := . }} \u0026lt;li\u0026gt; {{ $item.Priority }} {{ $item.Topic }} \u0026lt;/li\u0026gt; {{ end }} \u0026lt;/ul\u0026gt; \u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt; ` type Todo struct { Priority int Topic string } var todos = []Todo{ {1, \u0026#34;Take out the dog\u0026#34;}, {2, \u0026#34;Feed the cat\u0026#34;}, {3, \u0026#34;Learn GO programming\u0026#34;}, } t := template.Must(template.New(\u0026#34;page\u0026#34;).Parse(page)) err := t.Execute(os.Stdout, todos) if err != nil { log.Println(\u0026#34;executing template:\u0026#34;, err) } } This program generates the following HTML output:\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt;\u0026lt;head\u0026gt;\u0026lt;title\u0026gt;my todo list\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt;\u0026lt;h1\u0026gt;my TODO list\u0026lt;/h1\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt; 1 Take out the dog \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; 2 Feed the cat \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; 3 Learn GO programming \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt; Next step: use the template to provide interactive web pages \u0026hellip;\n","permalink":"https://ilmanzo.github.io/post/templating-in-go/","summary":"The GO programming language has a nice and useful standard library, which includes a powerful templating engine out of the box.\nHere I wrote an example, generating HTML output from a simple data structure.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 package main import ( \u0026#34;html/template\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; ) func main() { page := ` \u0026lt;!","title":"sample template usage in the Go Programming Language"},{"content":"Long story short: you have launched your script/program but forgot to redirect the output to a file for later inspection.\n#!/usr/bin/python3 #sample endless running program that prints to stdout import time,datetime while True: print(datetime.datetime.now().time()) time.sleep(1) Using GNU Debugger you can re-attach to the process, then invoke the creation of a logfile and duplicate the file descriptor to make the system send the data to the new file, instead of the terminal:\nsudo gdb -p $(pidof python3) --batch -ex \u0026#39;call creat(\u0026#34;/tmp/stdout.log\u0026#34;, 0600)\u0026#39; -ex \u0026#39;call dup2(3, 1)\u0026#39; note that you need to pass with the option -p the Process ID (PID) of the program; you can get it also via ps -ef\nnow, simply\ntail -f /tmp/stdout.log to get the output of the program.\n","permalink":"https://ilmanzo.github.io/post/redirect-output-of-running-process/","summary":"Long story short: you have launched your script/program but forgot to redirect the output to a file for later inspection.\n#!/usr/bin/python3 #sample endless running program that prints to stdout import time,datetime while True: print(datetime.datetime.now().time()) time.sleep(1) Using GNU Debugger you can re-attach to the process, then invoke the creation of a logfile and duplicate the file descriptor to make the system send the data to the new file, instead of the terminal:","title":"redirect output of an already running process"},{"content":"Obiettivo vogliamo mantenere la stessa directory sincronizzata su due server linux.\nQuesto significa che ogni aggiunta/rimozione/modifica di file in questa directory verr√† automaticamente riportato sull\u0026rsquo;altro (salvo conflitti). Diamo per assunto che i due server siano raggiungibili via rete, ma per qualsiasi motivo non sia possibile collegare dello spazio disco condiviso.\nImplementazione Per raggiungere lo scopo, utilizzeremo il tool: csync2\nsu entrambi i server (che chiameremo nodo1 e nodo2), installiamo i pacchetti necessari:\n# apt-get install csync2 incron mentre sul primo creiamo la chiave di cifratura e il certificato che verra\u0026rsquo; usato nella connessione SSL. Notiamo che csync2 utilizza 30865/tcp per le proprie comunicazioni, per cui assicuriamoci di abilitare le connessioni in ingresso su tale porta.\nn1# csync2 -k /etc/csync2.key n1# openssl genrsa -out /etc/csync2_ssl_key.pem 2048 n1# openssl req -batch -new -key /etc/csync2_ssl_key.pem -out /etc/csync2_ssl_cert.csr n1# openssl x509 -req -days 3600 -in /etc/csync2_ssl_cert.csr -signkey /etc/csync2_ssl_key.pem -out /etc/csync2_ssl_cert.pem creiamo il file /etc/csync2.cfg che conterra\u0026rsquo; le definizioni per il gruppo di sincronizzazione\ncopiamo il tutto anche sul nodo2: n1# scp /etc/csync2* nodo2:/etc/\nper default, csync2 su debian utilizza inetd, ma e\u0026rsquo; semplice configurarlo per girare come standalone o xinetd. dopo aver fatto partire i servizi su entrambi i nodi, possiamo usare il comando n1# csync2 -xv per far s√¨ che tutte le modifiche fatte in /mnt/sync del nodo1 vengano riportate anche sul nodo2. Per rendere la cosa automatica, potremmo schedulare un job ogni 3 minuti con cron:\n*/3 * * * * /usr/sbin/csync2 -xv Questo e\u0026rsquo; indispensabile anche nel caso di temporaneo down o spegnimento di uno dei due sistemi; ma se preferissimo una sincronizzazione immediata , potremmo usare incron che usando l\u0026rsquo;interfaccia inotify, resta in ascolto di determinati eventi su una specifica directory e al verificarsi delle condizioni desiderate, esegue il comando configurato. Nel nostro caso, possiamo inserire nella incrontab una entry simile a questa:\novvero, controlla la directory /mnt/sync e ogni volta che vengono cambiati attributi, creati, cancellati, salvati o spostati file esegui la sincronizzazione.\n","permalink":"https://ilmanzo.github.io/post/simple-directory-sync/","summary":"Obiettivo vogliamo mantenere la stessa directory sincronizzata su due server linux.\nQuesto significa che ogni aggiunta/rimozione/modifica di file in questa directory verr√† automaticamente riportato sull\u0026rsquo;altro (salvo conflitti). Diamo per assunto che i due server siano raggiungibili via rete, ma per qualsiasi motivo non sia possibile collegare dello spazio disco condiviso.\nImplementazione Per raggiungere lo scopo, utilizzeremo il tool: csync2\nsu entrambi i server (che chiameremo nodo1 e nodo2), installiamo i pacchetti necessari:","title":"Sincronizzare una directory tra due server linux"},{"content":"I\u0026rsquo;ve started a new side project named D Lang Koans, it\u0026rsquo;s a simple series of exercises organized in a unit test suite.\nThe \u0026ldquo;koans\u0026rdquo; are heavily inspired by similar projects for other languages, but I didn\u0026rsquo;t found anything similar for D.\nI\u0026rsquo;ll try to maintain and evolve it in the spare time, I hope you\u0026rsquo;ll find it useful.\n","permalink":"https://ilmanzo.github.io/post/a-new-project-to-learn-the-d-programming-language/","summary":"I\u0026rsquo;ve started a new side project named D Lang Koans, it\u0026rsquo;s a simple series of exercises organized in a unit test suite.\nThe \u0026ldquo;koans\u0026rdquo; are heavily inspired by similar projects for other languages, but I didn\u0026rsquo;t found anything similar for D.\nI\u0026rsquo;ll try to maintain and evolve it in the spare time, I hope you\u0026rsquo;ll find it useful.","title":"A new project to learn the D Programming Language"},{"content":"the Apache module mod_status is very useful for inspecting your running webserver, but it gives you only realtime informations about workers, connections, and so on. I wanted a way to keep this data and then be able to do comparison, charts and more useful reports. The first step was configuring mod_status in order to be only accessible from localhost:\nandrea@myserver:~$ cat /etc/apache2/mods-enabled/status.conf \u0026lt;IfModule mod_status.c\u0026gt; # # Allow server status reports generated by mod_status, # with the URL of http://servername/server-status # Uncomment and change the \u0026#34;192.0.2.0/24\u0026#34; to allow access from other hosts. # \u0026lt;Location /server-status\u0026gt; SetHandler server-status Order deny,allow Deny from all Allow from 127.0.0.1 ::1 # Allow from 192.0.2.0/24 \u0026lt;/Location\u0026gt; # Keep track of extended status information for each request ExtendedStatus On # Determine if mod_status displays the first 63 characters of a request or # the last 63, assuming the request itself is greater than 63 chars. # Default: Off #SeeRequestTail On \u0026lt;IfModule mod_proxy.c\u0026gt; # Show Proxy LoadBalancer status in mod_status ProxyStatus On \u0026lt;/IfModule\u0026gt; \u0026lt;/IfModule\u0026gt; now a little shell script to grab the status page together with other useful informations\u0026hellip;\nandrea@myserver:~ $ cat apache_status_logger.sh #!/bin/sh (date +%Y%m%d_%H%M%S \u0026amp;\u0026amp; links2 -dump http://127.0.0.1/server-status \u0026amp;\u0026amp; top -n1 -b) \u0026gt;\u0026gt; /home/andrea/apache_status_$(date +%Y%m%d).log scheduled every 5 minutes with a cron entry like this:\n# m h dom mon dow command */5 * * * * /home/andrea/apache_status_logger.sh you will get for each day a separate file with date, time, apache status, and a list of running processes with their statistics. Now you can parse the data with any tool you want; i.e. want to know which was the busiest days?\nandrea@myserver:~$ grep \u0026#39;requests currently\u0026#39; apache_status_*.log | sort -k2 -nr | head -5 apache_status_20141024.log: 132 requests currently being processed, 0 idle workers apache_status_20141024.log: 78 requests currently being processed, 0 idle workers apache_status_20141103.log: 48 requests currently being processed, 3 idle workers apache_status_20141028.log: 47 requests currently being processed, 2 idle workers apache_status_20141030.log: 42 requests currently being processed, 0 idle workers ","permalink":"https://ilmanzo.github.io/post/logging-apache-performance-historical-statistics/","summary":"the Apache module mod_status is very useful for inspecting your running webserver, but it gives you only realtime informations about workers, connections, and so on. I wanted a way to keep this data and then be able to do comparison, charts and more useful reports. The first step was configuring mod_status in order to be only accessible from localhost:\nandrea@myserver:~$ cat /etc/apache2/mods-enabled/status.conf \u0026lt;IfModule mod_status.c\u0026gt; # # Allow server status reports generated by mod_status, # with the URL of http://servername/server-status # Uncomment and change the \u0026#34;192.","title":"monitor apache performance statistics"},{"content":"I had a trouble with a long process running and wish to know how much I/O this process is doing, so I wrote this quick and dirty python 2.x script:\nimport time,sys,datetime def read_stat(pid): f=open(\u0026#34;/proc/%s/io\u0026#34; % pid ,\u0026#34;r\u0026#34;) for line in f: if line.startswith(\u0026#39;rchar\u0026#39;): rchar=line.split(\u0026#39;:\u0026#39;)[1] continue if line.startswith(\u0026#39;wchar\u0026#39;): wchar=line.split(\u0026#39;:\u0026#39;)[1] continue f.close() return int(rchar),int(wchar) pid=sys.argv[1] r0,w0 = read_stat(pid) while 1: time.sleep(1) r1,w1 = read_stat(pid) print \u0026#34;%s\\t\\tr=%s\\t\\tw=%s\u0026#34; % (datetime.datetime.now().time(),r1-r0,w1-w0) r0,w0=r1,w1 You must give the process PID number as input to the script. In the output you get the read/write throughput of the process in bytes per second, for instance:\n# python /root/iostat.py 26148 15:59:57.272866 r=208 w=850 15:59:58.269857 r=0 w=871 15:59:59.269906 r=0 w=4194246 16:00:00.270497 r=165569 w=4194171 16:00:01.290003 r=48 w=30095 16:00:02.290123 r=165584 w=4197511 16:00:03.290320 r=0 w=7100 16:00:04.290075 r=0 w=4200859 16:00:05.291754 r=29264618 w=29270412 16:00:06.290484 r=32 w=4195722 16:00:07.360245 r=29264635 w=33459616 16:00:08.360573 r=8 w=0 16:00:09.360337 r=16 w=4101346 16:00:10.360292 r=0 w=4037 16:00:11.372133 r=16 w=0 16:00:12.370385 r=48 w=456 16:00:13.370890 r=0 w=0 16:00:14.370800 r=270 w=450 16:00:15.410800 r=908 w=540 16:00:16.410604 r=24 w=0 ","permalink":"https://ilmanzo.github.io/post/simple-io-statistics-per-process/","summary":"I had a trouble with a long process running and wish to know how much I/O this process is doing, so I wrote this quick and dirty python 2.x script:\nimport time,sys,datetime def read_stat(pid): f=open(\u0026#34;/proc/%s/io\u0026#34; % pid ,\u0026#34;r\u0026#34;) for line in f: if line.startswith(\u0026#39;rchar\u0026#39;): rchar=line.split(\u0026#39;:\u0026#39;)[1] continue if line.startswith(\u0026#39;wchar\u0026#39;): wchar=line.split(\u0026#39;:\u0026#39;)[1] continue f.close() return int(rchar),int(wchar) pid=sys.argv[1] r0,w0 = read_stat(pid) while 1: time.sleep(1) r1,w1 = read_stat(pid) print \u0026#34;%s\\t\\tr=%s\\t\\tw=%s\u0026#34; % (datetime.datetime.now().time(),r1-r0,w1-w0) r0,w0=r1,w1 You must give the process PID number as input to the script.","title":"Linux: get simple I/O statistics per process"},{"content":"Starting with a plain old one-disk configuration\u0026hellip;\n# df -h Filesystem Size Used Avail Use% Mounted on /dev/sda2 5.8G 590M 5.0G 11% /data thanks to the power of btrfs, let\u0026rsquo;s add a second hard disk, with mirrored data AND without unmounting/reformatting! :) also note the different size\u0026hellip;.\n# fdisk -l Disk /dev/sda: 6 GiB, 6442450944 bytes, 12582912 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0xea97ecdc Device Boot Start End Blocks Id System /dev/sda1 2048 526335 262144 82 Linux swap / Solaris /dev/sda2 * 526336 12582911 6028288 83 Linux Disk /dev/sdb: 4 GiB, 4294967296 bytes, 8388608 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes \u0026hellip; state of the filesystem before the change\u0026hellip;\n# btrfs filesystem show /data Label: none uuid: b9ba1a95-1aaf-4c18-96ba-e4512b6f030f Total devices 1 FS bytes used 544.04MiB devid 1 size 5.75GiB used 912.00MiB path /dev/sda2 now we tell the filesystem it has a new disk to use:\n# btrfs device add /dev/sdb /data now we need to rebalance the filesystem:\n# btrfs balance start -dconvert=raid1 -mconvert=raid1 /data \u0026hellip; after some time \u0026hellip; btrfs will store chunks of data in both disks, evenly distributing the capacity.\n# btrfs filesystem show /data Label: none uuid: b9ba1a95-1aaf-4c18-96ba-e4512b6f030f Total devices 2 FS bytes used 545.14MiB devid 1 size 5.75GiB used 1.27GiB path /dev/sda2 devid 2 size 4.00GiB used 1.27GiB path /dev/sdb # btrfs filesystem df /data Data, RAID1: total=1008.00MiB, used=499.81MiB System, RAID1: total=32.00MiB, used=16.00KiB Metadata, RAID1: total=256.00MiB, used=45.48MiB unknown, single: total=16.00MiB, used=0.00 now you\u0026rsquo;re using two disks (RAID1) to store data and metadata!\nfor a multi-volume filesystem, remember to specify ALL the devices in the fstab entry:\n/dev/sdb /data btrfs device=/dev/sdb,device=/dev/sda2 1 2 should one of the two disks fail, add a new one to the system and replace it:\n# btrfs replace start old_disk newdisk /data If you wish to restore the previous one-single-disk configuration:\n# btrfs balance start -f -dconvert=single -mconvert=single /data # btrfs device delete /dev/sdb /data ","permalink":"https://ilmanzo.github.io/post/btrfs-mirroring/","summary":"Starting with a plain old one-disk configuration\u0026hellip;\n# df -h Filesystem Size Used Avail Use% Mounted on /dev/sda2 5.8G 590M 5.0G 11% /data thanks to the power of btrfs, let\u0026rsquo;s add a second hard disk, with mirrored data AND without unmounting/reformatting! :) also note the different size\u0026hellip;.\n# fdisk -l Disk /dev/sda: 6 GiB, 6442450944 bytes, 12582912 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0xea97ecdc Device Boot Start End Blocks Id System /dev/sda1 2048 526335 262144 82 Linux swap / Solaris /dev/sda2 * 526336 12582911 6028288 83 Linux Disk /dev/sdb: 4 GiB, 4294967296 bytes, 8388608 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes \u0026hellip; state of the filesystem before the change\u0026hellip;","title":"how to setup disk redundancy with BTRFS filesystem"},{"content":"It\u0026rsquo;s always recommended to backup your data for safety, but for safety AND security let\u0026rsquo;s encrypt your backups!\nto compress and encrypt with \u0026lsquo;mypassword\u0026rsquo;: tar -Jcf - directory | openssl aes-256-cbc -salt -k mypassword -out backup.tar.xz.aes\nto decrypt and decompress: openssl aes-256-cbc -d -salt -k mypassword -in backup.tar.xz.aes | tar -xJ -f - Another trick with the tar command is useful for remote backups: tar -zcvfp - /wwwdata | ssh root@remote.server.com \u0026#34;cat \u0026gt; /backup/wwwdata.tar.gz\u0026#34;\n","permalink":"https://ilmanzo.github.io/post/compress-and-encrypt-your-remote-backups/","summary":"It\u0026rsquo;s always recommended to backup your data for safety, but for safety AND security let\u0026rsquo;s encrypt your backups!\nto compress and encrypt with \u0026lsquo;mypassword\u0026rsquo;: tar -Jcf - directory | openssl aes-256-cbc -salt -k mypassword -out backup.tar.xz.aes\nto decrypt and decompress: openssl aes-256-cbc -d -salt -k mypassword -in backup.tar.xz.aes | tar -xJ -f - Another trick with the tar command is useful for remote backups: tar -zcvfp - /wwwdata | ssh root@remote.","title":"Compress and encrypt your backups"},{"content":"For testing or development purposes, I do a wide use of small linux virtual machines.\nAfter spawning a new guest (Virtualbox, VMWare or any other), often you want to log on over ssh but you don\u0026rsquo;t yet know its ip address. You need to login as \u0026lsquo;root\u0026rsquo; in the console just to issue a quick \u0026lsquo;ifconfig\u0026rsquo;, and after writing down the address, you logout and connect with your comfortable terminal. In order to save some time and keystrokes, I put this in my rc.local of all my guest VMs:\n/sbin/ip addr show|awk \u0026#39;/inet / {print $2}\u0026#39; \u0026gt; /etc/issue echo \u0026gt;\u0026gt; /etc/issue In brief: since the file /etc/issue is displayed before login, you get a quick overview of all ipv4 addresses configured. Of course it can be expanded and adapted for your needs.\n","permalink":"https://ilmanzo.github.io/post/know-your-vm-address-before-logon/","summary":"For testing or development purposes, I do a wide use of small linux virtual machines.\nAfter spawning a new guest (Virtualbox, VMWare or any other), often you want to log on over ssh but you don\u0026rsquo;t yet know its ip address. You need to login as \u0026lsquo;root\u0026rsquo; in the console just to issue a quick \u0026lsquo;ifconfig\u0026rsquo;, and after writing down the address, you logout and connect with your comfortable terminal. In order to save some time and keystrokes, I put this in my rc.","title":"how to display the IP address of a virtual machine before logon"},{"content":"This script is useful to delete old messages in \u0026ldquo;Junk\u0026rdquo; mail folders (Spam, Trash) automatically after some days.\nadapted from these notes to work on debian/postfixadmin/dovecot\n#!/bin/bash # # itera sulle mailbox cancellando messaggi vecchi # per default, nel cestino 30gg e Spam 15 gg # # MySQL details HOST=\u0026#34;127.0.0.1\u0026#34;; USER=\u0026#34;put_here_your_mysql_user\u0026#34;; PWD=\u0026#34;put_here_your_mysql_password\u0026#34;; MYSQL=\u0026#34;/usr/bin/mysql\u0026#34;; # dovecot details DOVEADM=\u0026#34;/usr/bin/doveadm\u0026#34;; TEMPFILE=$(/bin/mktemp) # Output sql to a file that we want to run echo \u0026#34;use postfixadmin; select username from mailbox\u0026#34; \u0026gt; $TEMPFILE # Run the query and get the results (adjust the path to mysql) results=$($MYSQL -h $HOST -u $USER -p$PWD -N \u0026lt; $TEMPFILE); # Loop through each row for row in $results do echo \u0026#34;Purging $row Trash and Junk mailbox...\u0026#34; # Purge expired Trash $DOVEADM -v expunge mailbox Trash -u $row savedbefore 30d # Purge expired Spam $DOVEADM -v expunge mailbox Spam -u $row savedbefore 15d done rm $TEMPFILE ","permalink":"https://ilmanzo.github.io/post/postfix-dovecot-cleanup-virtual-folders/","summary":"This script is useful to delete old messages in \u0026ldquo;Junk\u0026rdquo; mail folders (Spam, Trash) automatically after some days.\nadapted from these notes to work on debian/postfixadmin/dovecot\n#!/bin/bash # # itera sulle mailbox cancellando messaggi vecchi # per default, nel cestino 30gg e Spam 15 gg # # MySQL details HOST=\u0026#34;127.0.0.1\u0026#34;; USER=\u0026#34;put_here_your_mysql_user\u0026#34;; PWD=\u0026#34;put_here_your_mysql_password\u0026#34;; MYSQL=\u0026#34;/usr/bin/mysql\u0026#34;; # dovecot details DOVEADM=\u0026#34;/usr/bin/doveadm\u0026#34;; TEMPFILE=$(/bin/mktemp) # Output sql to a file that we want to run echo \u0026#34;use postfixadmin; select username from mailbox\u0026#34; \u0026gt; $TEMPFILE # Run the query and get the results (adjust the path to mysql) results=$($MYSQL -h $HOST -u $USER -p$PWD -N \u0026lt; $TEMPFILE); # Loop through each row for row in $results do echo \u0026#34;Purging $row Trash and Junk mailbox.","title":"dovecot: cleaning old Spam and Trash messages after some days"},{"content":"a small script to check out the number of processors in your linux machine\nmandatory sample output:\n","permalink":"https://ilmanzo.github.io/post/sockets-and-cores/","summary":"a small script to check out the number of processors in your linux machine\nmandatory sample output:","title":"number of physical sockets and cpu cores"},{"content":"A quick and dirty way to send a bunch of commands to any ssh device (in my case, Cisco appliances)\u0026hellip;\ncreate a plain old batch file with commands echoed inside: execute the batch, piping its output to plink.exe (putty command link ssh client): c:\\\u0026gt; commands.bat | plink -ssh -l username -pw password 11.22.33.44 ","permalink":"https://ilmanzo.github.io/post/plink-automation/","summary":"A quick and dirty way to send a bunch of commands to any ssh device (in my case, Cisco appliances)\u0026hellip;\ncreate a plain old batch file with commands echoed inside: execute the batch, piping its output to plink.exe (putty command link ssh client): c:\\\u0026gt; commands.bat | plink -ssh -l username -pw password 11.22.33.44 ","title":"Automate Cisco ssh connections with plink in Windows"},{"content":"Giocando con Sinatra ho avuto l\u0026rsquo;esigenza di servire una determinata pagina solo con un certa frequenza (tecnicamente un rate-limit); la cosa si puo\u0026rsquo; fare installando il middleware Rack:Throttle ma non volevo aggiungere un\u0026rsquo;altra gemma alle dipendenze\u0026hellip;\nIn questo esempio se al server arriva piu\u0026rsquo; di una richiesta in un intervallo di cinque secondi, rispondiamo a tono\u0026hellip;\nSECONDS_BETWEEN_REQUEST=5 enable :sessions def ratelimit? now=Time.new.to_i session[\u0026#39;lastrequest\u0026#39;]||=0 #inizializza se non presente result=(now-session[\u0026#39;lastrequest\u0026#39;])\u0026lt;SECONDS_BETWEEN_REQUEST #passati dall\u0026#39;ultima richiesta ? session[\u0026#39;lastrequest\u0026#39;]=now # aggiorna return result end get \u0026#39;/\u0026#39; do if ratelimit? return \u0026#34;\u0026lt;h1\u0026gt;sorry, rate limit exceeded!\u0026lt;/h1\u0026gt;\u0026#34; end \u0026#34;\u0026lt;h1\u0026gt;hello!\u0026lt;/h1\u0026gt;\u0026#34; end ","permalink":"https://ilmanzo.github.io/post/semplice-rate-limit-in-sinatra/","summary":"Giocando con Sinatra ho avuto l\u0026rsquo;esigenza di servire una determinata pagina solo con un certa frequenza (tecnicamente un rate-limit); la cosa si puo\u0026rsquo; fare installando il middleware Rack:Throttle ma non volevo aggiungere un\u0026rsquo;altra gemma alle dipendenze\u0026hellip;\nIn questo esempio se al server arriva piu\u0026rsquo; di una richiesta in un intervallo di cinque secondi, rispondiamo a tono\u0026hellip;\nSECONDS_BETWEEN_REQUEST=5 enable :sessions def ratelimit? now=Time.new.to_i session[\u0026#39;lastrequest\u0026#39;]||=0 #inizializza se non presente result=(now-session[\u0026#39;lastrequest\u0026#39;])\u0026lt;SECONDS_BETWEEN_REQUEST #passati dall\u0026#39;ultima richiesta ?","title":"semplice rate limit in Sinatra"},{"content":"Mi e\u0026rsquo; capitato di inserire degli script nelle varie directory /etc/cron.daily, /etc/cron.weekly ma di scoprire che questi script non vengono eseguiti. Il motivo e\u0026rsquo; che il run-parts usato nelle Debian e derivate ignora i file che contengono un \u0026ldquo;.\u0026rdquo; (e quindi tutti quelli con l\u0026rsquo;estensione)\nQuesto comportamento e\u0026rsquo; documentato anche nella man page, e previene alcuni inconvenienti come l\u0026rsquo;esecuzione dei .bak ma lo scrivo anche qui per ricordarmelo \u0026hellip; E forse potra\u0026rsquo; essere utile a qualcun altro :)\n","permalink":"https://ilmanzo.github.io/post/run-parts-problemi-crontab/","summary":"Mi e\u0026rsquo; capitato di inserire degli script nelle varie directory /etc/cron.daily, /etc/cron.weekly ma di scoprire che questi script non vengono eseguiti. Il motivo e\u0026rsquo; che il run-parts usato nelle Debian e derivate ignora i file che contengono un \u0026ldquo;.\u0026rdquo; (e quindi tutti quelli con l\u0026rsquo;estensione)\nQuesto comportamento e\u0026rsquo; documentato anche nella man page, e previene alcuni inconvenienti come l\u0026rsquo;esecuzione dei .bak ma lo scrivo anche qui per ricordarmelo \u0026hellip; E forse potra\u0026rsquo; essere utile a qualcun altro :)","title":"run-parts e problemi di crontab"},{"content":"A volte e\u0026rsquo; necessario replicare le utenze con gli stessi parametri su piu\u0026rsquo; server linux diversi.\nPerche\u0026rsquo; farlo a mano ? Se sono tanti e\u0026rsquo; un lavoro noioso e potremmo anche commettere degli errori.\nEcco un semplice one-liner che fa il parsing di un file /etc/passwd e genera i corrispondenti comandi useradd\nawk -F: '{printf \u0026quot;useradd -m -u%s -g%s -d%s -s%s %s\\n\u0026quot; , $3,$4,$6,$7,$1}' /etc/passwd Ovviamente l\u0026rsquo;output puo\u0026rsquo; essere comodamente filtrato con grep, usato via copy\u0026amp;paste, inserito in uno script, eccetera\u0026hellip;\n","permalink":"https://ilmanzo.github.io/post/generare-comandi-di-creazione-utenze-a-partire-da-un-passwd/","summary":"A volte e\u0026rsquo; necessario replicare le utenze con gli stessi parametri su piu\u0026rsquo; server linux diversi.\nPerche\u0026rsquo; farlo a mano ? Se sono tanti e\u0026rsquo; un lavoro noioso e potremmo anche commettere degli errori.\nEcco un semplice one-liner che fa il parsing di un file /etc/passwd e genera i corrispondenti comandi useradd\nawk -F: '{printf \u0026quot;useradd -m -u%s -g%s -d%s -s%s %s\\n\u0026quot; , $3,$4,$6,$7,$1}' /etc/passwd Ovviamente l\u0026rsquo;output puo\u0026rsquo; essere comodamente filtrato con grep, usato via copy\u0026amp;paste, inserito in uno script, eccetera\u0026hellip;","title":"generare comandi di creazione utenze a partire da un passwd"},{"content":"Natale si avvicina: mentre smanettavo su queste ottime PC Engines ALIX su cui ho installato una Debian modificata, ho scritto una comoda interfaccia per accendere/spegnere e far lampeggiare i led alla velocita\u0026rsquo; desiderata\u0026hellip;\nclass Led #numero da 1 a 3 def initialize(ledno) ledno++ # passo 0 ma comando 1 ledno=1 if ledno\u0026lt;1 ledno=3 if ledno\u0026gt;3 @ledsyspath=\u0026#34;/sys/devices/platform/leds_alix2/leds/alix:#{ledno}/\u0026#34; end def blink(millisec) File.open(@ledsyspath+\u0026#39;trigger\u0026#39;,\u0026#39;w\u0026#39;) { |f| f.write(\u0026#39;timer\u0026#39;) } File.open(@ledsyspath+\u0026#39;delay_off\u0026#39;,\u0026#39;w\u0026#39;) do |f| f.write(millisec.to_s) end File.open(@ledsyspath+\u0026#39;delay_on\u0026#39;,\u0026#39;w\u0026#39;) do |f| f.write(millisec.to_s) end end def blink_slow! blink(500) end def blink_fast! blink(50) end def on! File.open(@ledsyspath+\u0026#39;trigger\u0026#39;,\u0026#39;w\u0026#39;) { |f| f.write(\u0026#39;default-on\u0026#39;) } File.open(@ledsyspath+\u0026#39;brightness\u0026#39;,\u0026#39;w\u0026#39;) do |f| f.write(\u0026#39;1\u0026#39;) end end def off! File.open(@ledsyspath+\u0026#39;trigger\u0026#39;,\u0026#39;w\u0026#39;) { |f| f.write(\u0026#34;none\u0026#34;) } File.open(@ledsyspath+\u0026#39;brightness\u0026#39;,\u0026#39;w\u0026#39;) do |f| f.write(\u0026#39;0\u0026#39;) end end end ","permalink":"https://ilmanzo.github.io/post/gestire-i-led-delle-schede-pc-engines-alix/","summary":"Natale si avvicina: mentre smanettavo su queste ottime PC Engines ALIX su cui ho installato una Debian modificata, ho scritto una comoda interfaccia per accendere/spegnere e far lampeggiare i led alla velocita\u0026rsquo; desiderata\u0026hellip;\nclass Led #numero da 1 a 3 def initialize(ledno) ledno++ # passo 0 ma comando 1 ledno=1 if ledno\u0026lt;1 ledno=3 if ledno\u0026gt;3 @ledsyspath=\u0026#34;/sys/devices/platform/leds_alix2/leds/alix:#{ledno}/\u0026#34; end def blink(millisec) File.open(@ledsyspath+\u0026#39;trigger\u0026#39;,\u0026#39;w\u0026#39;) { |f| f.write(\u0026#39;timer\u0026#39;) } File.open(@ledsyspath+\u0026#39;delay_off\u0026#39;,\u0026#39;w\u0026#39;) do |f| f.write(millisec.to_s) end File.open(@ledsyspath+\u0026#39;delay_on\u0026#39;,\u0026#39;w\u0026#39;) do |f| f.","title":"gestire i led delle schede PC Engines ALIX in Ruby"},{"content":"A volte negli script Ruby ho bisogno di controllare l\u0026rsquo;esecuzione di un comando eseguito in modalita\u0026rsquo; asincrona, ho creato pertanto una classe apposita:\nclass BackgroundJob def initialize(cmd) @pid = fork do # this code is run in the child process # you can do anything here, like changing current directory or reopening STDOUT exec cmd end end def stop! # kill it (other signals than TERM may be used, depending on the program you want # to kill. The signal KILL will always work but the process won\u0026#39;t be allowed # to cleanup anything) Process.kill \u0026#34;TERM\u0026#34;, @pid # you have to wait for its termination, otherwise it will become a zombie process # (or you can use Process.detach) Process.wait @pid end end come si usa ? Molto semplice:\nwg = BackgroundJob.new \u0026#39;wget http://www.google.it\u0026#39; sleep 10 wg.stop! ovviamente non bisogna abusarne ;-)\n","permalink":"https://ilmanzo.github.io/post/background-tasks-in-ruby-e-linux/","summary":"A volte negli script Ruby ho bisogno di controllare l\u0026rsquo;esecuzione di un comando eseguito in modalita\u0026rsquo; asincrona, ho creato pertanto una classe apposita:\nclass BackgroundJob def initialize(cmd) @pid = fork do # this code is run in the child process # you can do anything here, like changing current directory or reopening STDOUT exec cmd end end def stop! # kill it (other signals than TERM may be used, depending on the program you want # to kill.","title":"background tasks in Ruby e linux"},{"content":"Cos\u0026rsquo;e\u0026rsquo; Enerduino? Un progetto nato per controllare il consumo di energia nella mia casa. E perche\u0026rsquo; dovrei fare questo tipo di monitoraggio, chiederete voi? Per esempio per capire le mie abitudini di consumo, per valutare offerte biorarie. Oppure solo per capire dove consumo di piu\u0026rsquo; e magari risparmiare un po\u0026rsquo; di energia.\nEsistono molti strumenti per poter fare questo tipo di monitoraggio che si possono acquistare su internet. Questa e\u0026rsquo; la mia soluzione fai-da-te, basata sul controller hardware Arduino.\nQuesto progetto puo\u0026rsquo; essere realizzato da chiunque abbia un po\u0026rsquo; di manualita\u0026rsquo; e abbia voglia di divertisi a costruire qualcosa.\nhttp://enerduino.blogspot.it/\nscarica il sorgente aggiornato alla versione 1.0 dell\u0026rsquo;IDE\n","permalink":"https://ilmanzo.github.io/post/enerduino/","summary":"Cos\u0026rsquo;e\u0026rsquo; Enerduino? Un progetto nato per controllare il consumo di energia nella mia casa. E perche\u0026rsquo; dovrei fare questo tipo di monitoraggio, chiederete voi? Per esempio per capire le mie abitudini di consumo, per valutare offerte biorarie. Oppure solo per capire dove consumo di piu\u0026rsquo; e magari risparmiare un po\u0026rsquo; di energia.\nEsistono molti strumenti per poter fare questo tipo di monitoraggio che si possono acquistare su internet. Questa e\u0026rsquo; la mia soluzione fai-da-te, basata sul controller hardware Arduino.","title":"Enerduino"},{"content":"Anche quest\u0026rsquo;anno ho avuto il piacere di partecipare al Linux Day, organizzato per Verona presso la sede del LUG Verona in via dei Gelsi a Montorio; Ho tenuto una breve presentazione su un argomento che mi sta a cuore: partecipare attivamente alla comunita\u0026rsquo; del software libero, perche\u0026rsquo; anche se ormai Linux e Il free software hanno una discreta diffusione, la maggior parte degli utenti si limita all\u0026rsquo;utilizzo passivo e anzi spesso si lamenta per la scarsa qualita\u0026rsquo; del software open. Il software libero NON e\u0026rsquo; solo avere programmi gratis! Vorrei invitare chiunque a \u0026ldquo;passare dall\u0026rsquo;altra parte\u0026rdquo; e abbandonare il comodo stato di \u0026ldquo;spettatori\u0026rdquo; per cominciare a dare il proprio contributo, ognuno per quello che puo'.\nNelle slide elenco alcuni dei modi per entrare a far parte della comunita\u0026rsquo; del software libero.\nScarica\n","permalink":"https://ilmanzo.github.io/post/linux-day-2012/","summary":"Anche quest\u0026rsquo;anno ho avuto il piacere di partecipare al Linux Day, organizzato per Verona presso la sede del LUG Verona in via dei Gelsi a Montorio; Ho tenuto una breve presentazione su un argomento che mi sta a cuore: partecipare attivamente alla comunita\u0026rsquo; del software libero, perche\u0026rsquo; anche se ormai Linux e Il free software hanno una discreta diffusione, la maggior parte degli utenti si limita all\u0026rsquo;utilizzo passivo e anzi spesso si lamenta per la scarsa qualita\u0026rsquo; del software open.","title":"Linux Day 2012"}]